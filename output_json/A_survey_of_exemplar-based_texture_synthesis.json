[
    {
        "element_id": "08d3568042db298c72fae92451651f62",
        "text": "A survey of exemplar-based texture synthesis",
        "type": "Title",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 1,
            "languages": [
                "eng"
            ],
            "coordinates": [
                149.468994140625,
                163.16873168945312,
                461.75616455078125,
                180.38412475585938
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "8a5649deb057bf0b39d98f566965f8f3",
        "text": "Lara Raad∗1, Axel Davy†2, Agn`es Desolneux‡2, and Jean-Michel\nMorel§2",
        "type": "Title",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 1,
            "languages": [
                "eng"
            ],
            "coordinates": [
                141.3730010986328,
                194.82876586914062,
                469.8662109375,
                222.0587921142578
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "3a2eeb583c35229846445ca4ee3fd645",
        "text": "arXiv:1707.07184v2  [cs.CV]  24 Nov 2017",
        "type": "Title",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 1,
            "languages": [
                "eng"
            ],
            "coordinates": [
                10.940000534057617,
                206.70001220703125,
                37.619998931884766,
                560.0
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "24c2a3c535284243ccf4605523b2351a",
        "text": "1Dept. of Information & Communications Technologies, Universitat Pompeu Fabra\n2CMLA, ´Ecole normale sup´erieure Paris-Saclay",
        "type": "Title",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 1,
            "languages": [
                "eng"
            ],
            "coordinates": [
                150.81997680664062,
                232.7900390625,
                460.3285827636719,
                259.046142578125
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "043918e43425401e23aedf20cd757da8",
        "text": "October 17, 2018",
        "type": "Title",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 1,
            "languages": [
                "eng"
            ],
            "coordinates": [
                261.88897705078125,
                277.1805725097656,
                349.401123046875,
                289.1357727050781
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "1f2f1d7a92d158d7f61bd41dae067576",
        "text": "Abstract\nExemplar-based texture synthesis is the process of generating, from an\ninput sample, new texture images of arbitrary size and which are percep-\ntually equivalent to the sample. The two main approaches are statistics-\nbased methods and patch re-arrangement methods. In the ﬁrst class, a\ntexture is characterized by a statistical signature; then, a random sam-\npling conditioned to this signature produces genuinely diﬀerent texture\nimages. The second class boils down to a clever “copy-paste” procedure,\nwhich stitches together large regions of the sample. Hybrid methods try\nto combine ideas from both approaches to avoid their hurdles. The recent\napproaches using convolutional neural networks ﬁt to this classiﬁcation,\nsome being statistical and others performing patch re-arrangement in the\nfeature space.\nThey produce impressive synthesis on various kinds of\ntextures. Nevertheless, we found that most real textures are organized at\nmultiple scales, with global structures revealed at coarse scales and highly\nvarying details at ﬁner ones. Thus, when confronted with large natural\nimages of textures the results of state-of-the-art methods degrade rapidly,\nand the problem of modeling them remains wide open.",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 1,
            "languages": [
                "eng"
            ],
            "coordinates": [
                158.67498779296875,
                320.0213928222656,
                452.6205139160156,
                517.2855834960938
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "656e58ba9289c7d9ddb1575c0f47e9fd",
        "text": "1\nIntroduction",
        "type": "Title",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 1,
            "languages": [
                "eng"
            ],
            "coordinates": [
                133.7679901123047,
                552.9376831054688,
                246.84469604492188,
                567.283935546875
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "6c39e2adfea8b31860dab4bccfafd2ce",
        "text": "This paper proposes a review of exemplar-based texture theory, a topic that oc-\ncupied David Mumford at the end of the last century [97, 98], and again in",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 1,
            "languages": [
                "eng"
            ],
            "coordinates": [
                133.7679901123047,
                578.1846313476562,
                477.5573425292969,
                600.1022338867188
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "4e8a4616971bdb65af74d7467693d23c",
        "text": "∗lara.raad@upf.edu\n†axel.davy@cmla.ens-cachan.fr\n‡desolneux@cmla.ens-cachan.fr\n§morel@cmla.ens-cachan.fr\nThe images in this document are lossy compressed. To compare the zoomed-in images,\nplease refer to the uncompressed pdf, which can be found at http://desolneux.perso.math.\ncnrs.fr/papers/exemplar-based-texture-synthesis-v2-full-res.pdf",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 1,
            "languages": [
                "eng"
            ],
            "coordinates": [
                133.7679901123047,
                607.3818359375,
                477.4132995605469,
                674.87109375
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "25fd3ad252e8aca3e4480382c40eb3b7",
        "text": "1",
        "type": "Title",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 1,
            "languages": [
                "eng"
            ],
            "coordinates": [
                303.13299560546875,
                694.8489379882812,
                308.1142883300781,
                704.8115234375
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "3b3b568725b36c5f089c96c14d895ac3",
        "text": "his book on pattern theory [62]. Textures are ubiquitous in our visual envi-\nronment. In the past ﬁfty years their deﬁnition has occupied psychophysicists,\nmathematicians and computer scientists who have built increasingly sophisti-\ncated models. The main progress on the elusive topic of deﬁning textures has\ncome from computer graphics with the problem of reproducing other examples\nof the same texture given a sample. There is so far no complete mathematical\ntheory that would, ﬁrst, give a formal axiomatic of texture, and then prove\nthat some texture synthesis algorithm matches this deﬁnition.\nRather, each\nexemplar-based texture method formulates its own deﬁnition of texture and\nsometimes (but rarely) convergence or consistency proofs. The method to work\non texture modeling still relies on a visual exploration of synthesized textures,\ntheir defects and successes being linked to some improvement or shortcoming of\nthe mathematical model. All the more, texture modeling remains a valid chal-\nlenge for mathematicians, as textures represent arguably the vaster and most\ncommon class of observable functions. They indeed cover a majority of the area\nof most digital images. This article accounts for the very rapid and impressive\nrecent apparition of new texture synthesis methods with striking results. We\nshall retrace their theoretical roots. By performing objective experiments and\nnot hiding the failures of each method, this paper will uncover some ﬂaws in the\ncurrent deﬁnition of exemplar-based texture modeling. This will lead us to pro-\npose a slightly diﬀerent deﬁnition of the problem that seems to address better\nits challenges.\nThe Oxford Dictionary of English deﬁnes texture as the feel, appearance, or\nconsistency of a surface or a substance. Focusing on visual appearance, texture\nis analog to color, a perceived quality of a surface, where the RGB bands are\nreplaced by the output of a speciﬁc bank of ﬁlters [62, p.215]. Julesz deﬁned\ntextures as classes of pictures that cannot be discriminated in preattentive vi-\nsion and advanced two statistical hypotheses to characterize them [41, 38, 40].\nGrenander proposed to use the term “texture” for strictly stationary stochastic\nprocesses [31, p.398]. Giving a precise deﬁnition of textures is a slippery task;\nin a sense, each model implicitly proposes one and as we will see the jury is still\nout.\nExemplar-based texture synthesis is the process of generating, from an input\ntexture sample, new texture images of arbitrary size and which are perceptually\nequivalent to the input. It is common to classify them under the two classi-\ncal statistical estimation categories: parametric methods and non-parametric\nmethods. The parametric methods aim at characterizing a given texture sam-\nple by estimating a set of statistics which will deﬁne an underlying stochastic\nprocess. The new images will then be samples of this stochastic process, i.e.\nthey will have the same statistics as the input sample. The question here is:\nwhat would be the appropriate set of statistics to yield a correct synthesis for\nthe wide variety of texture images? The results of these methods are satisfying\nbut only on a small group of textures, and often fail when important structures\nare visible in the input. The non-parametric methods reorganize local neigh-\nbourhoods from the input sample in a consistent way to create new texture\nimages. These methods return impressive visual results. Nevertheless, they of-",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 2,
            "languages": [
                "eng"
            ],
            "coordinates": [
                133.7679901123047,
                126.97892761230469,
                477.5474853515625,
                674.9234619140625
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "71e42c8f336d5eda21b65106a1b18d38",
        "text": "2",
        "type": "Title",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 2,
            "languages": [
                "eng"
            ],
            "coordinates": [
                303.13299560546875,
                694.8488159179688,
                308.1142883300781,
                704.8114013671875
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "c7997cf042835081777b141b453a3270",
        "text": "ten yield verbatim copies of large parts of the input sample. Furthermore, they\ncan diverge, starting to reproduce iteratively one part of the input sample and\nneglecting the rest of it, thus growing what experts call “garbage”. Because\n“non-parametric” methods are not completely parameter-free, and “paramet-\nric” methods can have a reduced set of parameters, in this paper we will denote\nby patch re-arrangement methods the former and by statistics-based methods\nthe latter.\nWhat constitutes a texture? The answer depends of course on human per-\nception. But a mathematical formulation can be used to characterize patterns\nthat are perceived as textures. The statistical characterization of texture im-\nages was initiated by B´ela Julesz [38, 42].\nJulesz was the ﬁrst to point out\nthat texture images could be reliably organized according to their N-th order\nstatistics into groups of textures that are preattentively indistinguishable by\nhumans [38]. (Focusing on pre-attentive vision helps to reduce the subjective\nimpact of high level processing.) Julesz [42] demonstrated that many texture\npairs sharing the same second-order statistics would not be discerned by hu-\nman preattentive vision. This hypothesis constitutes the ﬁrst Julesz axiom for\ntexture perception. One consequence of this axiom is that two textures shar-\ning the same Fourier modulus but with diﬀerent phase should be perceptually\nequivalent. Indeed, the square Fourier modulus of an image corresponds to its\nspatial auto-correlation, thus the second-order statistics. This motivates a class\nof algorithms (the random phase methods) aiming at creating textures with a\ngiven second-order statistic. An example of such algorithms is [87]. In a more\nrecent extension [23], a texture is generated by randomizing the Fourier phase\nwhile maintaining the Fourier modulus. The Random Phase Noise method in\n[23] correctly synthesizes textures with no salient details, namely microtexture,\nwhich adapt well to a Gaussian distribution, but it fails for more structured\nones, macrotextures, as can be experimented in the executable paper [22]. In-\ndeed, textures may share the same second and even third order statistics while\nbeing visually diﬀerent [43, 11]. This led Julesz [40, 39] to propose a second\ntheory to explain texture preattentive discrimination by introducing the notion\nof textons. Textons are local conspicuous features like bars or corners. Giving a\nmathematical deﬁnition for textons is far from trivial and was studied in for ex-\nample [95, 17]. Julesz’ second theory states that only the ﬁrst order statistics of\nthese textons are relevant for texture perception: images having the same texton\ndensities (thus, just a ﬁrst order statistic) could not be discriminated. Texton\ntheory proposes the main axiom that texture perception is invariant to random\nshifts of the textons [40]. This axiom is extensively used in the stochastic dead\nleaves models [61, 77, 8].\nSeveral models of the early visual processing in mammals are based on a\nmultiscale analysis with Gabor kernels, and are used in particular for model-\ning the perception of texture [5, 82, 59]. Wavelet analysis provided a natural\nframe for these models and resulted in eﬀective methods for texture classiﬁca-\ntion and segmentation [12, 48, 84, 60]. Heeger and Bergen [33] extended Julesz’\napproach to multiscale statistics. They characterized a texture sample by the\nhistograms of its wavelet coeﬃcients. By enforcing the same histograms on a",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 3,
            "languages": [
                "eng"
            ],
            "coordinates": [
                133.76800537109375,
                126.97892761230469,
                477.5574645996094,
                674.9234619140625
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "efbb4f0a83da259405f75fee35077ad5",
        "text": "3",
        "type": "Title",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 3,
            "languages": [
                "eng"
            ],
            "coordinates": [
                303.13299560546875,
                694.8488159179688,
                308.1142883300781,
                704.8114013671875
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "40a5852dfc188330f34ccd45dcd80ad2",
        "text": "white noise image they obtained a new multiscale exemplar-based texture syn-\nthesis method. Yet this method only measures marginal statistics. It misses\nimportant correlations between pixels across scales and orientations which are\ncrucial to generate edges and conspicuous patterns. We refer to the on-line exe-\ncution of this method [9] where some successes but many failures are evident, as\nis also the case for RPN [22]. Within a similar range of results, the De Bonet [14]\nmethod randomizes the initial texture image and preserves only a few statistics,\nnamely the dependencies across scales of a multi-resolution ﬁlter bench response.\nOther methods are also based on statistics of wavelet coeﬃcients or more in-\nvolved multiscale image representations [69, 67, 72]. The Heeger-Bergen method\nwas extended by Portilla and Simoncelli [69] who proposed to evaluate on the\nsample some 700 cross-correlations, autocorrelations and statistical moments\nof the wavelet coeﬃcients. Enforcing the same statistics on synthetic images,\nstarting from white noise, achieves striking results for a wide range of texture\nexamples.\nThis method, which for a decade represented the state-of-the-art\nfor psychophysically and statistically founded algorithms is nevertheless com-\nputationally heavy, and its convergence is not guaranteed. Its results, though\ngenerally indiscernible from the original samples in a pre-attentive examina-\ntion, often present blur and phantoms. Earlier, Zhu, Wu and Mumford [98]\nproposed to model texture images by inferring a probability distribution on a\nset of images with the same texture appearances and then to sample from it. To\ninfer this probability distribution, the set of images is ﬁltered by a pre-selected\nset of ﬁlters (which capture the important features of a given texture image)\nand their histograms are extracted. These are estimates of the marginals of\nthe probability distribution sought for. Then the maximum entropy probability\ndistribution is constructed matching the previous marginals. To sample from\nthis probability distribution the Gibbs sampler is adopted, thus generating new\ntexture images. The resulting model is a Markov random ﬁeld. The limitation\nof this method is its practical aspect. Inferring the probability distribution and\nsampling from it are complex tasks. More recent work by Zhu et al. [96, 92]\nadvanced the Julesz ensembles texture model based on a common set of statis-\ntics; they proved that this model is equivalent to FRAME in the limit of an\ninﬁnite image grid. An eﬃcient MCMC sampling method was also proposed.\nThese two texture generators have been recently revisited with neural networks.\nGatys’ texture generator [27] and DeepFrame [58] can be seen respectively as\nextended versions of [69] and [98], and get signiﬁcantly better results. Some new\nneural network methods, based on generative neural networks, also get notable\nresults [36]. All these recent methods show that the Julesz program of seeking\nthe right statistics to characterize a texture is still well alive.\nIt is worth mentioning that texture models can be used to complete missing\nparts of an image or texture inpainting. These methods rely on the deﬁnition\nof texture images as the realization of a random ﬁeld. For inpainting this boils\ndown to the estimation of a random texture model on the masked input image\n(a set of valid pixels of the image) from which a new image is sampled condi-\ntioned to some of the known values of input image. The method presented in\n[26, 25, 24] is particularly well adapted for micro-textures. A Gaussian model",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 4,
            "languages": [
                "eng"
            ],
            "coordinates": [
                133.7679901123047,
                126.97892761230469,
                477.5773620605469,
                674.9234619140625
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "32aa471126993fd7ea264c9f1c55d708",
        "text": "4",
        "type": "Title",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 4,
            "languages": [
                "eng"
            ],
            "coordinates": [
                303.13299560546875,
                694.8488159179688,
                308.1142883300781,
                704.8114013671875
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "614c338d0b8fd49167e0cb6820bc72af",
        "text": "is estimated on the masked input image; then the result is generated by a\nconditional sampling from the estimated model using the kriging estimation\nframework.\nPatch re-arrangement methods constitute a totally diﬀerent category of tex-\nture synthesis algorithms. This category started by pixel re-arrangement using\nsquare patches as context. The initial Efros and Leung [19] method was in-\nspired by Shannon’s Markov random ﬁeld model for the English language [78].\nIn analogy with Shannon’s algorithm for synthesizing sentences, the texture is\nconstructed pixel by pixel. For each new pixel in the reconstructed image, a\npatch centered in the pixel is compared to all the patches of the input sample.\nThe patches in the sample that are similar help predict the pixel value in the\nsynthetic image. Several optimizations have been proposed to accelerate this\nalgorithm. Among them Wei and Levoy [90] managed to ﬁx the shape and size\nof the learning patch, and Ashikhmin [3] proposed to extend existing patches\nwhenever possible instead of searching in the entire sample texture. Yet, as al-\nready pointed out in the original paper [19], an iterative procedure may fail by\nproducing “garbage” when the neighborhood’s size is too small. On the other\nhand, it can lead to a trivial verbatim reproduction of big pieces of the sample\nwhen the neighborhood is too large. This can be experimented in the online\nexecutable paper [1]. Many extensions of [19] have been proposed that manage\nto accelerate the procedure and reduce the “garbage” problem by stitching en-\ntire patches instead of pixels. Among the ﬁrst methods proposing to re-arrange\nwhole patches, Xu et al. [32] proposed to synthesize a texture by picking ran-\ndom patches from the sample texture and placing them randomly in the output\ntexture image. A blending step is applied across the overlapping blocks to avoid\nedge artifacts.\nIn [54] the authors proposed to synthesize the image by quilt-\ning together patches that were taken from the input image among those who\nbest match the patch under construction. A blending step was also added to\novercome some edge artifacts. Efros and Freeman [20] proposed an extension\nof the latter introducing the quilting method (a blending step) that computes\na path with minimal contrast across overlapping patches, thus mitigating the\ntransition eﬀect from patch to patch.\nKwatra et al. [47] extended [20] by using a graph-cut algorithm to deﬁne the\nedges of the patch to quilt in the synthesis image. Another extension of [19]\nwas proposed by Kwatra et al. [46] where to synthesize a texture image they\nimprove the quality of the synthesis image sequentially by minimizing a patch-\nbased energy function. In the same spirit as [46], where texture optimization\nis performed, the authors in [50] proposed to synthesize textures in a multi-\nscale framework using the coordinate maps of the sample texture at diﬀerent\nscales. They introduced spatial randomness by applying a jitter function to the\ncoordinates at each level, combined to a correction step inspired by [3]. One\nof the key strengths of the method is that it is a parallel synthesis algorithm\nwhich makes it extremely fast. These patch-based approaches often present sat-\nisfactory visual results. In particular they have the ability to reproduce highly\nstructured textures (macrotextures). However, the risk remains of copying even\nseveral times verbatim large parts of the input sample. For practical applica-",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 5,
            "languages": [
                "eng"
            ],
            "coordinates": [
                133.76800537109375,
                126.97892761230469,
                477.5672302246094,
                674.9234619140625
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "ea5289c558e21a32bd98ed833ead6eac",
        "text": "5",
        "type": "Title",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 5,
            "languages": [
                "eng"
            ],
            "coordinates": [
                303.13299560546875,
                694.8488159179688,
                308.1142883300781,
                704.8114013671875
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "df93c3487b24e8930df5c61aecdc1074",
        "text": "tions this may result in the appearance of repeated patterns in the synthesized\nimage. Furthermore, a ﬁdelity to the global statistics of the initial sample is not\nguaranteed, in particular when the texture sample is not stationary. We refer\nto [89] for an extensive overview of the diﬀerent patch re-arrangement methods.\nRecent research tries to revisit the use of previous methods. Using neural\nnetworks has seen some success, as well as combining patch re-arrangement and\nstatistics-based methods to overcome the drawbacks mentioned previously [66,\n81]. These approaches will be called hybrid methods. Peyr´e [66] proposed to use\na patch-based approach where all the patches of the synthesized image are cre-\nated from a sparse dictionary learnt on the input sample. Tartavel et al. [81] ex-\ntended [66] by minimizing an energy that involves a sparse dictionary of patches\ncombined to constraints on the Fourier spectrum of the input sample in a mul-\ntiscale framework. Raad et al. [70] proposed to model the self-similarities of\na given input texture with conditional multivariate Gaussian distributions in\nthe patch space in a multiscale framework. A new image is generated patch\nby patch, where for each given patch a multivariate Gaussian model is inferred\nfrom its nearest neighbours in the patch space of the input sample, and hereafter\nsampled from this model.\nThe academic literature shows that current methods are able to produce\nimpressive texture synthesis on various kinds of textures. Our experiments will\nillustrate this, and the opposite. Indeed, this literature is still working, in a\nsense, on toy examples. Most textures are deﬁned by texture samples of rela-\ntively small size and the structures are present in a small range of scales. When\nconfronting the methods with more challenging data, the quality of the results\ndegrades rapidly. This can be seen for most natural images of textures, which\nare non-stationary, due for example to the presence of illumination changes and\nperspective. As a matter of fact large photographs of textures are non-stationary\nbecause even homogeneous material always shows an internal variation of struc-\nture. Thus the classic exemplar-based texture synthesis problem can be seen\nin this light as an almost impossible Fourier spectrum extrapolation, given a\nvery small texture example. Hence our exploration not only of the solutions,\nbut of the problem itself will illustrate the limitations of the current question,\nand introduce a more general question: how to emulate the real, non-stationary\ntextures, for which we dispose of large samples? Then the question is no longer\nto “extend” a small patch into a larger texture of the same kind, but rather to\nbe able to fabricate other examples of a given large and complex texture, given\nonly one sample of it.\nThis survey concentrates on the problem of texture synthesis on ﬂat 2D do-\nmains. There are several interesting extensions and applications of the basic\nproblem which are not discussed here. These include surface texture synthesis,\nin which a texture is to be placed onto a curved surface, dynamic texture syn-\nthesis, when the goal is to generate textures whose appearance evolves over time\nsuch as for videos of time-variant materials, or solid texture synthesis, where the\naim is to generate the color content of 3D blocks of synthesized materials from\nwhich, for example, computer graphics objects can be carved out. Other related\nproblems include image completion and resolution enhancement by texture syn-",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 6,
            "languages": [
                "eng"
            ],
            "coordinates": [
                133.76800537109375,
                126.97892761230469,
                477.55743408203125,
                674.9234619140625
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "07e9738b66ba9e612bd54aeebf7fcc71",
        "text": "6",
        "type": "Title",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 6,
            "languages": [
                "eng"
            ],
            "coordinates": [
                303.1330871582031,
                694.8488159179688,
                308.1143798828125,
                704.8114013671875
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "368e70d0ee2d2358fe6e109ea54cd71f",
        "text": "thesis. Also, the computational cost in real-time applications (e.g. games) or\nwhen the data volume is large (e.g. ﬁlm production) impose further restrictions\nleading to particular algorithms. For a discussion of these topics, we refer the\nreader to Wei et al. [89] and the references therein.\nWe now sketch our plan. We shall present the main trends in exemplar-\nbased texture synthesis by describing in detail several methods illustrating the\nthree main families. In each case, the strength and limitations will be com-\nmented as well as some relevant variations. Section 2 introduces the statistics-\nbased methods which perform statistical optimization and describes several al-\ngorithms. Then Section 3 focuses on patch re-arrangement methods, presenting\nthree works. The third main class of hybrid methods is discussed in Section 4.\nThe experimental Section 5 ﬁrst compares the main families of algorithms in a\nvaried set of textures; then, the limitations of all current methods are revealed\nwith high-resolution and non-stationary examples. Finally, Section 6 concludes\nthe paper. All the results displayed were generated for this paper, with the\noriginal code published with the methods [9, 22, 68, 28, 57, 37, 1, 71, 52] or\nwith the modiﬁcations mentioned in this paper.",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 7,
            "languages": [
                "eng"
            ],
            "coordinates": [
                133.76800537109375,
                126.97892761230469,
                477.5373840332031,
                328.2236328125
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "660e1c163ce2445003390bba07d7e00a",
        "text": "2\nStatistics-based methods",
        "type": "Title",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 7,
            "languages": [
                "eng"
            ],
            "coordinates": [
                133.76800537109375,
                347.7810974121094,
                332.7353820800781,
                362.1272888183594
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "887e8e41d9b64ca825436ef67b23bfd4",
        "text": "Statistics-based texture synthesis methods follow the general approach proposed\nby Julesz, illustrated in Figure 1. The synthesis is performed in two steps: ﬁrst,\na set of statistics is estimated from the sample texture; second, a random image\nis generated, subject to these statistical constraints. Methods in this class diﬀer\nin the set of statistics considered and in the optimization method used to impose\nthem on a random image. We will describe several algorithms of this class with\nincreasing sophistication. It will appear that the number of statistics enforced\nplays a key role in the success.",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 7,
            "languages": [
                "eng"
            ],
            "coordinates": [
                133.76800537109375,
                373.02801513671875,
                477.51763916015625,
                466.676513671875
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "43c63acdda176d4115099682f7522668",
        "text": "2.1\nMicro-texture synthesis by phase randomization",
        "type": "Title",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 7,
            "languages": [
                "eng"
            ],
            "coordinates": [
                133.76800537109375,
                483.045654296875,
                448.560302734375,
                495.0008544921875
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "0c4b46507015abfe025d2a6cfc984573",
        "text": "The Random Phase Noise (RPN) method synthesizes a new texture from a rect-\nangular sample by simply randomizing the phase of the Fourier coeﬃcients of\nthe input sample. The results are very satisfying for textures that are charac-\nterized by their Fourier modulus, a class called micro-texture by some authors.\nThis method is also able to create a random texture from any input image, not\nnecessarily a texture sample. It is in spirit quite close to the noise generators\nfrom computer graphics [65, 87]. The rest of this section describes the main\nideas of this method and we refer the reader to [22] for more details and a\ncatalog of several synthesis examples.\nThe RPN of an image u deﬁned on a domain Ωis obtained by adding a ran-\ndom phase θ to the Fourier phase of the input sample image. The random phase\nis a white noise image uniformly distributed over (−π, π] and is constrained to\nbe symmetric. In the case of an RGB color image u = (uR, uG, uB), the RPN\nimage is obtained by adding the same random phase to the Fourier transform",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 7,
            "languages": [
                "eng"
            ],
            "coordinates": [
                133.76800537109375,
                502.991943359375,
                477.5247497558594,
                668.3715209960938
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "6be98d863b7c43a9dc939da95912c2b8",
        "text": "7",
        "type": "Title",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 7,
            "languages": [
                "eng"
            ],
            "coordinates": [
                303.13299560546875,
                694.8489379882812,
                308.1142883300781,
                704.8115234375
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "2a246016beb9b53ad08fac72a08906a1",
        "text": "Input\nstatistics",
        "type": "Title",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 8,
            "languages": [
                "eng"
            ],
            "coordinates": [
                178.77700805664062,
                173.0015106201172,
                285.8089904785156,
                188.3955078125
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "e3829b49029d7bd56653f0c2f2365458",
        "text": "Noise\nOutput\noptimization",
        "type": "Title",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 8,
            "languages": [
                "eng"
            ],
            "coordinates": [
                179.46701049804688,
                306.51947021484375,
                435.1566162109375,
                322.9628601074219
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "9b9d865040808c7c789d4180c63dfc2e",
        "text": "Figure 1: Statistics-based methods.\nA set of statistics is extracted from an\ninput sample (analysis step). Then, starting with a noise image, an optimization\nprocedure is applied to enforce these statistics on the output image (synthesis\nstep).",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 8,
            "languages": [
                "eng"
            ],
            "coordinates": [
                133.76800537109375,
                356.7989196777344,
                477.5174560546875,
                402.62646484375
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "80304877a7d5ffb42c319abf09eba393",
        "text": "of each color channel. Adding the same random phase to the original phases of\neach color channel preserves the phase displacements between channels. This is\nimportant as it permits to create new textures without creating false colors [23].\nMore precisely, a uniform random phase is deﬁned as a random image θ ∈\nRM×N satisfying the following conditions:",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 8,
            "languages": [
                "eng"
            ],
            "coordinates": [
                133.76797485351562,
                424.8968811035156,
                477.51751708984375,
                482.680419921875
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "f10f22c55bef635cc8a54e569523161a",
        "text": "• θ is odd: ∀m, n ∈Ω, θ(−m, −n) = −θ(m, n);",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 8,
            "languages": [
                "eng"
            ],
            "coordinates": [
                148.71197509765625,
                491.271728515625,
                351.9949951171875,
                501.3634338378906
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "5aae8b77e7a583f32ef21fed843da94d",
        "text": "• θ(m, n) is uniform on the interval (−π, π] for (m, n) ̸∈{(0, 0), (M/2, 0), (0, N/2), (M/2, N/2)};",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 8,
            "languages": [
                "eng"
            ],
            "coordinates": [
                148.71194458007812,
                510.5767517089844,
                559.3575439453125,
                520.66845703125
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "ccc6760393197283e4944ea37cb2a0cf",
        "text": "• θ(m, n) is uniform on the set {0, π} for (m, n) ∈{(0, 0), (M/2, 0), (0, N/2), (M/2, N/2)};",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 8,
            "languages": [
                "eng"
            ],
            "coordinates": [
                148.71194458007812,
                529.8806762695312,
                533.4234619140625,
                539.972412109375
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "2b0e1f973161a9dd051d59a21a161573",
        "text": "• for every subset S of the Fourier domain which does not contain distinct\nsymmetric points, the family of random variables {θ(m, n)|(m, n) ∈S} is\nindependent.",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 8,
            "languages": [
                "eng"
            ],
            "coordinates": [
                148.71188354492188,
                549.1857299804688,
                477.5226745605469,
                583.1874389648438
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "dce7164543726d715367b319115f1054",
        "text": "The RPN of an image u ∈RM×N is deﬁned as the random image X where there\nexists a uniform random phase θ such that",
        "type": "Title",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 8,
            "languages": [
                "eng"
            ],
            "coordinates": [
                133.767822265625,
                588.2928466796875,
                477.4757995605469,
                613.826416015625
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "466fa03062ee067b2bf46a56d9196a97",
        "text": "ˆX(ξ, η) = ˆu(ξ, η)eiθ(ξ,η), (ξ, η) ∈Ω,\n(1)",
        "type": "Title",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 8,
            "languages": [
                "eng"
            ],
            "coordinates": [
                230.49481201171875,
                621.7108764648438,
                477.4810791015625,
                634.1924438476562
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "97ad5fdad8c5dc027ba87ce2e754c038",
        "text": "where ˆu denotes the Fourier transform of u. An equivalent deﬁnition is",
        "type": "Title",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 8,
            "languages": [
                "eng"
            ],
            "coordinates": [
                133.76788330078125,
                644.5958862304688,
                443.97552490234375,
                654.5584716796875
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "d2b4069b0e9d1952f49fc99a7282b381",
        "text": "ˆX(ξ, η) = |ˆu(ξ, η)|eiθ(ξ,η),\n(2)",
        "type": "Title",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 8,
            "languages": [
                "eng"
            ],
            "coordinates": [
                250.77590942382812,
                662.44287109375,
                477.4811706542969,
                674.9234619140625
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "684c8c8eb81f9bbdc3d5f7abcc240279",
        "text": "8",
        "type": "Title",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 8,
            "languages": [
                "eng"
            ],
            "coordinates": [
                303.1329650878906,
                694.848876953125,
                308.1142578125,
                704.8114624023438
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "fff2bb8c7716c201ecad4e6fc6386faa",
        "text": "output",
        "type": "Title",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 9,
            "languages": [
                "eng"
            ],
            "coordinates": [
                267.88702392578125,
                126.79608154296875,
                292.8095397949219,
                134.76617431640625
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "a787a7b9e18b1188178a74b9fad1974a",
        "text": "input",
        "type": "Title",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 9,
            "languages": [
                "eng"
            ],
            "coordinates": [
                162.24301147460938,
                178.7921142578125,
                181.99293518066406,
                186.76220703125
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "e1df88016d1bee09827df3060d2ecd91",
        "text": "Figure 2: Synthesis results of the RPN method [87, 23]. This method works\nextremely well for micro-textures including tissues and granular textures with\nno geometric structures [22]. For more structured texture images it fails. Two\nexamples are shown: a successful synthesis on the left and a failure case on the\nright.",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 9,
            "languages": [
                "eng"
            ],
            "coordinates": [
                133.76800537109375,
                238.4539031982422,
                477.5076904296875,
                296.23651123046875
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "340b4eccc457daf1571a206ed9c2bdfd",
        "text": "where θ is a uniform random phase. Given the phase φ of a real-valued image and\na uniform random phase θ, the random image (θ +φ) mod 2π is also a uniform\nrandom phase, which proves this equivalence. The ﬁrst deﬁnition (1) leads to a\nnatural extension of RPN to color images [23], while the second deﬁnition (2)\nhighlights the fact that the RPN depends only on the Fourier modulus of the\nsample image u.\nSimilarly, an Asymptotic Discrete Spot Noise (ADSN) associated with an\nimage u is deﬁned as the convolution of a normalized zero-mean copy of u\nwith a Gaussian white noise.\nA Gaussian white noise image has a uniform\nrandom phase and its Fourier modulus is a white Rayleigh noise; the phase\nand modulus are independent.\nThus, the phase of the ADSN is a uniform\nrandom phase whereas its Fourier modulus is the pointwise multiplication of\nthe Fourier modulus of u by a Rayleigh noise [23].\nBoth ADSN and RPN\nhave uniform random phases, but the modulus distributions are diﬀerent. RPN\nkeeps the Fourier modulus of the original image, while for ADSN the Fourier\nmodulus is degraded by a pointwise multiplication by a white Rayleigh noise.\nRegardless of their theoretical diﬀerences, ADSN and RPN produce results that\nare perceptually very similar [23].\nThe RPN method is the fastest method presented in this review since it\nbasically needs the computation of two FFTs. Nevertheless, this method is lim-\nited to micro-textures and it will fail synthesizing structured textures, namely\nmacro-textures. In Figure 2 two synthesis examples are shown. The ﬁrst syn-\nthesis (left example in Figure 2) shows outstanding results. This micro-texture\nis indeed well represented by its Fourier modulus. However this is not at all\nthe case for the second texture synthesis (right example in Figure 2). Clearly,\nthe knowledge of the modulus of the Fourier coeﬃcients of this texture is not\nsuﬃcient to recover the strong contrast of the input.",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 9,
            "languages": [
                "eng"
            ],
            "coordinates": [
                133.76797485351562,
                319.7489318847656,
                477.547607421875,
                640.5452880859375
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "75d4d9b0eb97187d30656dab84c0897d",
        "text": "9",
        "type": "Title",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 9,
            "languages": [
                "eng"
            ],
            "coordinates": [
                303.13299560546875,
                694.8487548828125,
                308.1142883300781,
                704.8113403320312
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "8993192b1987663f1b992c90047a9357",
        "text": "output",
        "type": "Title",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 9,
            "languages": [
                "eng"
            ],
            "coordinates": [
                452.13897705078125,
                132.16009521484375,
                477.0614929199219,
                140.13018798828125
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "b76a07a42f97c5bbf47eac398ced6366",
        "text": "input",
        "type": "Title",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 9,
            "languages": [
                "eng"
            ],
            "coordinates": [
                346.4949951171875,
                181.4791259765625,
                366.2449035644531,
                189.44921875
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "9be4659819ce690f0f372dfd9dfb50c2",
        "text": "2.2\nThe Heeger and Bergen pyramid based texture syn-\nthesis",
        "type": "Title",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 10,
            "languages": [
                "eng"
            ],
            "coordinates": [
                133.76800537109375,
                125.42164611816406,
                477.5517578125,
                151.32386779785156
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "3400a91b77595a6a822431612d99475d",
        "text": "Heeger and Bergen [33] proposed to characterize a texture by the ﬁrst order\nstatistics of both its color and its responses to multiscale and multi-orientation\nﬁlters organized in a steerable pyramid [21]. This proposition, motivated by the\nstudy of human texture perception, focuses on the synthesis of microtextures\ndeﬁned as images that don’t have conspicuous patterns (e.g., granite, bark,\nsand).\nLet us describe the input texture image u and the synthesized texture v\nusing the Heeger and Bergen method.\nFirst the image u is ﬁltered using a\nsteerable pyramid decomposition [21, 79] with S scales and Q orientations at\neach scale. The steerable pyramid is a linear multiscale and multi-orientation\nimage decomposition. Given an input image, it is ﬁrst ﬁltered to provide a high\nfrequency image and a low frequency image. Band-pass oriented ﬁlters are then\nsequentially applied to the low frequency image which is also down-sampled.\nThese band-pass oriented ﬁlters are applied S times to the corresponding low\nfrequency image. This decomposition yields images of diﬀerent sizes correspond-\ning to the diﬀerent scales and orientations on which the gray level histograms\nare extracted as well as the gray level histogram of u. These histograms deﬁne\nthe set of statistics that characterize u.\nThe second step consists in generating the output image v, which is initial-\nized with a noise image. Its pixel values are iteratively modiﬁed to match the\nhistograms of u and of its steerable decomposition. These histogram match-\nings are performed on v alternately in the image domain and in the multiscale\ntransform domain, until all the output histograms match the ones of u. A third\nparameter is introduced here and it is the number of iterations used to achieve\na stabilization of the histogram matching.\nTo the best of our knowledge, no theorem guarantees that this iteration will\nend with an image respecting all statistics; there is of course one solution to it,\nnamely the example image. But the goal is to create an image diﬀerent from\nthe example. Hence the random initialization, which is supposed to lead always\nto diﬀerent samples of the same texture. This remark applies to all texture\nsynthesis methods we will consider: their success will mainly be judged visually\nand experimentally.\nTo treat RGB color images, instead of applying the method to each color\nchannel of the input image which are highly correlated, the authors proposed\nto change the color space RGB to a more adapted color space. This new color\nspace is obtained by principal component analysis of the RGB values of the\ninput image u. In [9] a detailed explanation of the original method of Heeger\nand Bergen [33] is provided with a complete analysis of the steerable pyramid\ndecomposition and the histogram matching step.\nThe authors also provide\nin [9] a minor improvement in the edge handling of the convolutions as well\nas an experimental section illustrating the inﬂuence of the parameters, namely\nthe number of iterations, the number of scales and the number of orientations.\nAs we said, there is no theoretical proof of convergence of the method but",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 10,
            "languages": [
                "eng"
            ],
            "coordinates": [
                133.76800537109375,
                159.3159637451172,
                477.5376281738281,
                671.3954467773438
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "31cf161170aa469ef4b1f2bb373ee0ce",
        "text": "10",
        "type": "Title",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 10,
            "languages": [
                "eng"
            ],
            "coordinates": [
                300.6420593261719,
                694.848876953125,
                310.6046447753906,
                704.8114624023438
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "be90d5063546a361831133833af0a110",
        "text": "output",
        "type": "Title",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 11,
            "languages": [
                "eng"
            ],
            "coordinates": [
                267.8869934082031,
                126.796142578125,
                292.80950927734375,
                134.7662353515625
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "a99359621b038c8da13e0af8e81e58b4",
        "text": "input",
        "type": "Title",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 11,
            "languages": [
                "eng"
            ],
            "coordinates": [
                172.5540008544922,
                158.1761474609375,
                192.30392456054688,
                166.146240234375
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "17c76a1c6ea1d5fc93c90ae1ad0a33ef",
        "text": "Figure 3: Synthesis results of the Heeger and Bergen method [33]. This method\nworks for microtextures.\nFor more structured texture images it fails.\nTwo\nexamples are shown: a successful synthesis on the left and a failure case on the\nright.",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 11,
            "languages": [
                "eng"
            ],
            "coordinates": [
                133.76800537109375,
                228.14793395996094,
                477.4976806640625,
                273.9755859375
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "76246fc5fa7424a3832f3ac8d0937219",
        "text": "an experimental study shows that the results tend to stabilize after ﬁve to\nten iterations [9].\nIncreasing the number of orientations changes the results\nslightly, but four orientations are enough in general. The number of scales is\nvery important. Taking the highest number permits to take into account all the\nscales of the texture. When the input texture has no evident structure then this\nparameter has less inﬂuence in the result.\nAs our experiments here will show, the results yielded by this approach are\nconvincing for some stochastic textures, but the method fails for most com-\nplex texture images. In particular it generally fails (visually) for quasi-periodic\ntextures, random mosaic textures, textures having more than one dominant ori-\nentation, and textures having correlations of high frequency content over large\ndistances. This demonstrates experimentally that all the spatial information\ncharacterizing a texture is not captured by the ﬁrst order statistics of a set of\nlinear ﬁlter outputs. In Figure 3 two synthesis examples are shown: a successful\nsynthesis and a failure case.",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 11,
            "languages": [
                "eng"
            ],
            "coordinates": [
                133.76800537109375,
                297.4880065917969,
                477.5374755859375,
                474.8224182128906
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "dfd0dcbce1c41870099a29ee4d7c6da6",
        "text": "2.3\nFRAME: a mathematical model for textures",
        "type": "Title",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 11,
            "languages": [
                "eng"
            ],
            "coordinates": [
                133.76800537109375,
                491.1915588378906,
                427.0530090332031,
                503.1467590332031
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "365cd7e9f5e29b321b3c75b07d3c488f",
        "text": "FRAME, which stands for Filters, Random ﬁelds And Maximum Entropy, is\na mathematical model of textures developed by Zhu, Wu and Mumford in [97]\nand [98]. It is the most mathematical solid work among the stream of work on\ntexture modeling during that period. It puts the graphics method of Heeger\nand Bergen [33] in a mathematical sound setting, i.e., it has a formal statistical\nmodel, and it can match the marginal statistics. It also answers the Julesz quest\nby pursuing the minimum statistical constraint that are necessary.\nThe FRAME model is based on the maximum entropy principle. It starts\nwith a set of ﬁlters that are selected from a general ﬁlter bank to capture features\nof the texture. These ﬁlters are applied to observed texture images, and the\nhistograms of the ﬁltered images are extracted. Then, the maximum entropy\nprinciple is employed to derive a distribution f, which has in expectation the\nsame ﬁlter responses as the original image, while being of maximum entropy.",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 11,
            "languages": [
                "eng"
            ],
            "coordinates": [
                133.76800537109375,
                511.13787841796875,
                477.53753662109375,
                664.5624389648438
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "c76a4eda17608b65d931c337438d7129",
        "text": "11",
        "type": "Title",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 11,
            "languages": [
                "eng"
            ],
            "coordinates": [
                300.6430358886719,
                694.8488159179688,
                310.6056213378906,
                704.8114013671875
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "9925df7cbd31b44b98d7ec32357385b1",
        "text": "output",
        "type": "Title",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 11,
            "languages": [
                "eng"
            ],
            "coordinates": [
                452.13897705078125,
                126.796142578125,
                477.0614929199219,
                134.7662353515625
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "193920a14d566055cf514b0fd03262dd",
        "text": "input",
        "type": "Title",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 11,
            "languages": [
                "eng"
            ],
            "coordinates": [
                356.8059997558594,
                158.1761474609375,
                376.555908203125,
                166.146240234375
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "6485355c73fa423b36bdd22f84fe9f32",
        "text": "More precisely, let u be an observed texture image and let F k, k = 1, . . . , K\nbe a set of ﬁlters. Let Hk\nu be the (discrete) histograms of the ﬁlter responses\nF k ∗u, and for any image v, let Hk\nv be the histograms of the ﬁlter responses\nF k ∗v. Zhu, Wu and Mumford seek for a distribution f(v) on images v such\nthat\nEf(Hk\nv ) = Hk\nu,\n(3)",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 12,
            "languages": [
                "eng"
            ],
            "coordinates": [
                133.76800537109375,
                125.69874572753906,
                477.4812316894531,
                199.17950439453125
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "1f0377465ed38d6f4141aaa6602a36d5",
        "text": "while being of maximum entropy (i.e. while being “as random as possible”).\nBy Lagrange Multipliers (maximization under constraints), the solution has the\nform",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 12,
            "languages": [
                "eng"
            ],
            "coordinates": [
                133.76803588867188,
                204.6869354248047,
                477.52764892578125,
                238.560546875
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "7e966a7f271192715f6571f52d71c349",
        "text": "f(v; λ) =\n1\nZ(λ) exp",
        "type": "Title",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 12,
            "languages": [
                "eng"
            ],
            "coordinates": [
                214.5660400390625,
                241.06895446777344,
                297.3229064941406,
                264.60552978515625
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "842fe4c7c4629fec3d3b401942687d17",
        "text": "where L is the number of bins of the discrete histograms. To ﬁnd the value of\nthe parameters λ satisfying Equation (3), Zhu, Wu and Mumford use a gradient\ndescent to ﬁnd the right λ and the Gibbs sampler algorithm to sample random\nimages v from a distribution f(·; λ). The distribution f(·; λ) deﬁnes a Markov\nRandom Field (MRF).\nFinally, a stepwise algorithm is proposed to choose the ﬁlters from a gen-\neral ﬁlter bank. This “ﬁlter pursuit” step is achieved thanks to the minimax\nentropy principle: ﬁnd the set of ﬁlters such that the associated distribution f\nis of minimum entropy, since it is equivalent to be of minimal Kullback-Leibler\ndivergence from the “true” underlying distribution. A detailed explanation of\nthis fact can be found in [98].\nThe FRAME model was later extended, in particular with non linear ﬁl-\nters, using the output of some layers of a neural network.\nIt is then called\nDeepFrame [58], and we will talk again about it in Section 2.5.",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 12,
            "languages": [
                "eng"
            ],
            "coordinates": [
                133.76809692382812,
                274.6799011230469,
                477.55755615234375,
                440.0603332519531
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "2b0f36465f62470dad4eddae07241551",
        "text": "2.4\nThe Portilla and Simoncelli algorithm",
        "type": "Title",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 12,
            "languages": [
                "eng"
            ],
            "coordinates": [
                133.76815795898438,
                456.428466796875,
                387.72052001953125,
                468.3836669921875
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "c40e040271c62e789bebe4dbe4f455a0",
        "text": "The key issue in FRAME and in the method of Heeger and Bergen is to choose\nthe “right” ﬁlters and the statistics that will be matched.\nIn [69], Portilla\nand Simoncelli proposed an important improvement on Heeger and Bergen’s\nmethod [33]. The texture is again synthesized starting from a noise image and\ncoercing it to have the same statistics as the input image. As we have seen,\nmarginal statistics are not enough to capture the relations across scales and\norientations. Portilla and Simoncelli proposed to match a set of joint statistics\nmeasurements of the coeﬃcients of the steerable pyramid decomposition of the\ninput texture.\nThe statistics used to characterize the input texture are the\nautocorrelation and cross-correlation coeﬃcients (inner and intra scales), as well\nas the statistical moments of order one, two, three and four of the input sample’s\nvalues. To enforce these statistics on the result, the image under construction is\nprojected iteratively into the subspace of constraints using a gradient projection\napproach until stabilization. The ﬁnal output image may not have exactly the\nsame statistics as the input sample.\nIt merely represents a local minimum.\nAgain there is no proof of a convergence of the method anyway.",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 12,
            "languages": [
                "eng"
            ],
            "coordinates": [
                133.76815795898438,
                476.375732421875,
                477.5376892089844,
                665.665283203125
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "c7f444247474db258f11cc2514a43a1c",
        "text": "12",
        "type": "Title",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 12,
            "languages": [
                "eng"
            ],
            "coordinates": [
                300.64215087890625,
                694.8486938476562,
                310.604736328125,
                704.811279296875
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "0d1263ae5fb311c467580cac4b62904a",
        "text": "K\nX",
        "type": "Title",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 12,
            "languages": [
                "eng"
            ],
            "coordinates": [
                332.3780517578125,
                237.6917266845703,
                346.7740173339844,
                255.46987915039062
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "9246b115de4ec98e8951664a626420e6",
        "text": "L\nX",
        "type": "Title",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 12,
            "languages": [
                "eng"
            ],
            "coordinates": [
                316.27703857421875,
                237.69178771972656,
                330.6730041503906,
                255.46994018554688
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "d3d8d9b74cb913e44d5e5e6d4824a225",
        "text": "!",
        "type": "Title",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 12,
            "languages": [
                "eng"
            ],
            "coordinates": [
                384.3660888671875,
                237.93629455566406,
                392.2564697265625,
                247.89889526367188
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "f480e2bf1092c28a7f8d4e9415ee639f",
        "text": "k=1\nλk\ni Hk\nu(i)",
        "type": "Title",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 12,
            "languages": [
                "eng"
            ],
            "coordinates": [
                332.32806396484375,
                246.0307159423828,
                384.3675537109375,
                269.10150146484375
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "842ef8bdcb5f5d042d9534c4bc6d97fa",
        "text": "−",
        "type": "Title",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 12,
            "languages": [
                "eng"
            ],
            "coordinates": [
                306.8680419921875,
                247.67982482910156,
                314.61895751953125,
                257.6424255371094
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "affaef140b4217b457bcaea92933af2d",
        "text": ",",
        "type": "Title",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 12,
            "languages": [
                "eng"
            ],
            "coordinates": [
                393.9140930175781,
                247.8088836669922,
                396.6836853027344,
                257.771484375
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "348cf6a6730bcf93546213f36d68e336",
        "text": "i=1",
        "type": "Title",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 12,
            "languages": [
                "eng"
            ],
            "coordinates": [
                317.01904296875,
                261.89971923828125,
                329.92913818359375,
                268.87353515625
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "9909e336baff5a44a703f4e620793930",
        "text": "Portilla and Simoncelli’s technique is based on the theories of human visual\nperception, in particular Julesz’ hypothesis stating that two images are percep-\ntually equivalent if and only if they agree on a set of statistic measurements.\nThe goal is to establish the minimal set of measurements in a way that all types\nof textures are correctly synthesized using that set of measurements. In the\nsame way as Heeger and Bergen’s method, the input texture sample is decom-\nposed with a multiscale oriented linear basis: the steerable pyramid [21, 79].\nFor each pair of coeﬃcients at nearby positions, orientations and scales, the\naverage value of their product, of their magnitude product and their relative\nphase is measured. In addition to these parameters, some marginal statistics on\nthe input image pixels distribution are kept: the mean, the variance, the skew-\nness, the kurtosis and the range. The number of parameters will depend on the\nnumber of sub-band images and on the size of the neighbourhood considered to\nestimate the statistical constraints of the example texture.\nThe second part of the algorithm is the synthesis step coercing to a random\nnoise image, the measurements previously computed. The synthesized image is\ninitialized with a Gaussian white noise image and then iteratively the algorithm\nalternates between: 1) constructing the steerable pyramid and enforcing the\nsample statistics of each sub-band image matching those of the corresponding\nsub-bands of the target image; 2) reconstructing an image from the pyramid\nand then forcing it to have the same marginal statistics as the input texture.\nA texture is deﬁned as a two-dimensional stationary random ﬁeld X(m, n)\non a ﬁnite lattice (m, n) ∈Ω⊂Z2. Julesz’ hypothesis is the basis to connect\nthis statistical deﬁnition to perception: there exists a set of constraint functions\n{φk, k = 1, . . . , K} such as if two random ﬁelds, X and Y , are identical in\nexpectation over this set of functions then any two samples drawn from X\nand Y will be perceptually equivalent under some ﬁxed comparison conditions.\nThe importance of human perception as a fundamental criterion of equivalence\nbetween textures can be seen through this hypothesis, as well as the existence\nof such a set of statistical measurements capable of capturing this equivalence.\nTo choose the set of constraint functions Portilla and Simoncelli proceeded as\nfollows:",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 13,
            "languages": [
                "eng"
            ],
            "coordinates": [
                133.76800537109375,
                126.97892761230469,
                477.5474853515625,
                507.55145263671875
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "40cf66782b40f1bde22dabed44cd36a3",
        "text": "1. Set an initial set of constraints and synthesize a large library of texture\nexamples;",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 13,
            "languages": [
                "eng"
            ],
            "coordinates": [
                145.94500732421875,
                519.5068969726562,
                477.5202331542969,
                541.4244384765625
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "8300f8e7158d5f397a19d1fed8c45443",
        "text": "2. Group the synthesis failures classifying them according to visual features\nthat distinguish them from their original texture examples and keep the\ngroup with the poorest results;",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 13,
            "languages": [
                "eng"
            ],
            "coordinates": [
                145.94500732421875,
                551.3869018554688,
                477.5281066894531,
                585.2604370117188
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "c936bbdbed81e3d2b0470ff2e6ecc39a",
        "text": "3. Add a new statistical constraint to the set capturing the missing feature\nof the failure group;",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 13,
            "languages": [
                "eng"
            ],
            "coordinates": [
                145.94500732421875,
                595.2228393554688,
                477.50048828125,
                617.1404418945312
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "280d7d2a7b351c1c77bf7864377500d5",
        "text": "4. Re-synthesize the failure group and verify the wanted feature is captured;\notherwise go back to the previous point;",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 13,
            "languages": [
                "eng"
            ],
            "coordinates": [
                145.94500732421875,
                627.1028442382812,
                477.5204162597656,
                649.021484375
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "03f64ae33c44aa7def287a82f5da34bf",
        "text": "5. Verify that the original constraints are still needed; for each constraint,",
        "type": "Title",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 13,
            "languages": [
                "eng"
            ],
            "coordinates": [
                145.94500732421875,
                658.98388671875,
                477.5302734375,
                668.9464721679688
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "743f85e1a2553bb5a3d8c52a439a5566",
        "text": "13",
        "type": "Title",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 13,
            "languages": [
                "eng"
            ],
            "coordinates": [
                300.64300537109375,
                694.848876953125,
                310.6055908203125,
                704.8114624023438
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "5250afdbcdbe01f1f18c3157bce2db0c",
        "text": "ﬁnd a texture example that fails when the constraint is removed from the\nset;",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 14,
            "languages": [
                "eng"
            ],
            "coordinates": [
                158.6750030517578,
                126.97892761230469,
                477.50811767578125,
                148.89654541015625
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "b966661c65b1e5d407f6473e58a55d46",
        "text": "6. Delete the unnecessary constraint, re-synthesize the library and go back\nto the second point.",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 14,
            "languages": [
                "eng"
            ],
            "coordinates": [
                145.94500732421875,
                158.6859588623047,
                477.5003662109375,
                180.60357666015625
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "25c388594860f0389d4ade9dfa0475ae",
        "text": "Following this strategy, the constraint set is adapted to a reference set of\ntextures and not just to one texture, and it is driven by perceptual criteria.\nThe set of constraints is composed of:",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 14,
            "languages": [
                "eng"
            ],
            "coordinates": [
                133.76800537109375,
                192.12596130371094,
                477.5375061035156,
                225.99859619140625
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "9285f637b689d935005a21cac66ba110",
        "text": "1. Marginal statistics formed by: skewness and kurtosis of the low-pass im-\nages of each level of the pyramid, variance of the high-pass image of the\npyramid, skewness, kurtosis, variance, mean and range of the image. The\nmarginal statistics set the general degree of pixel intensity and their distri-\nbution. This is why they cannot be discarded from the statistics set [69].",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 14,
            "languages": [
                "eng"
            ],
            "coordinates": [
                145.94500732421875,
                237.52098083496094,
                477.5081787109375,
                295.3035888671875
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "1fdeb92b16f2136533c4a736336a1094",
        "text": "2. Autocorrelation of the low-band coeﬃcients. This allows to capture the\nperiodic structures of a texture as well as long-range correlation. Omitting\nthis constraint from the original set yields unsatisfying results for textures\nhaving periodic or long-range correlation patterns [69].",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 14,
            "languages": [
                "eng"
            ],
            "coordinates": [
                145.94500732421875,
                305.093017578125,
                477.5180358886719,
                350.92156982421875
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "fbe0978f776a471016b3e1cb110adf41",
        "text": "3. Autocorrelation and cross-correlation of the magnitude of the sub-bands.\nThese statistics appear to be relevant because observation reveals that\noriented bands have a particular behaviour concerning certain pattern\nand their periodicity whatever the orientation [69]. The cross-correlations\nkept are of each sub-band image with others of the same scale (inner\ncross-correlation) and of each sub-band with sub-bands at the coarser\nscale (intra cross-correlation).",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 14,
            "languages": [
                "eng"
            ],
            "coordinates": [
                145.94500732421875,
                360.71099853515625,
                477.53802490234375,
                442.4045104980469
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "8a4e20badbdd90cf45481a77a9503096",
        "text": "4. Cross-correlation of the real part of the sub-bands with the real and imag-\ninary parts of the coeﬃcients’ phase of the coarser scale. This statistic\nis important to capture the strong illumination eﬀects present in some\ntexture images.\nIn particular, the synthesized image looses its three-\ndimensional eﬀect and the shadows structure if they are not considered [69].",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 14,
            "languages": [
                "eng"
            ],
            "coordinates": [
                145.94500732421875,
                452.1939392089844,
                479.00250244140625,
                509.97747802734375
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "87ded152a65e81742fd35a29b42ffba0",
        "text": "The set of statistics is summarized in Table 1. As mentioned previously, the\nnumber of parameters used depends on the number of scales S and orientations\nQ of the steerable decomposition as well as the size of the neighbourhood Na\nused to compute the auto-correlations. The total number of parameters is 6+1+\n2(S+1)+(S+1)(N 2\na+1)/2+SQ(N 2\na+1)/2+SQ(Q−1)/2+(S−1)Q2+2(S−1)Q2,\nwhere the terms correspond (from left to right) to: the marginal statistics of\nu, the variance of high pass image, the skewness and kurtosis of the low band\nimages, the auto-correlation of the low band images, the auto-correlation of the\nsub band images, the inner cross-correlation of the sub band images, the intra\ncross-correlation of the low band images and the cross correlation of the real\npart of the sub band images with the real and imaginary part of the phase sub\nband images. In general S = 4, Q = 4 and Na = 7 are used, leading to a total\nof 710 parameters.",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 14,
            "languages": [
                "eng"
            ],
            "coordinates": [
                133.76792907714844,
                521.4989013671875,
                477.53753662109375,
                674.9234619140625
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "273e0ce06bd4b512760916745b0157fa",
        "text": "14",
        "type": "Title",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 14,
            "languages": [
                "eng"
            ],
            "coordinates": [
                300.6429443359375,
                694.8489379882812,
                310.60552978515625,
                704.8115234375
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "b802e0d1eea3196b3d1860a4b42be942",
        "text": "range of u\nmax(u) and min(u)",
        "type": "Title",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 15,
            "languages": [
                "eng"
            ],
            "coordinates": [
                142.95799255371094,
                182.3348846435547,
                333.1644287109375,
                192.2974853515625
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "70fb52a83e26982099579cacb3dce895",
        "text": "mean of u\nµ1(u)",
        "type": "Title",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 15,
            "languages": [
                "eng"
            ],
            "coordinates": [
                142.95799255371094,
                198.78990173339844,
                272.345458984375,
                209.59356689453125
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "b421ce5d577903196fd54f461e50b47f",
        "text": "variance of u\nµ2(u)",
        "type": "Title",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 15,
            "languages": [
                "eng"
            ],
            "coordinates": [
                142.95799255371094,
                215.2449188232422,
                272.345458984375,
                226.048583984375
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "8145d134c1ac4e29f76f72aa462d62e3",
        "text": "skewness of u\nµ3(u)/(µ2(u))1.5",
        "type": "Title",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 15,
            "languages": [
                "eng"
            ],
            "coordinates": [
                142.95799255371094,
                230.4197540283203,
                319.3120422363281,
                242.50360107421875
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "6ce06876431f8c7c199bc43a465b19d0",
        "text": "kurtosis of u\nµ4(u)/(µ2(u))2",
        "type": "Title",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 15,
            "languages": [
                "eng"
            ],
            "coordinates": [
                142.95799255371094,
                246.8747100830078,
                312.9740295410156,
                258.95855712890625
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "7aae496f1c789d932b39c539f2fd735c",
        "text": "lowband’s skewness\nµ3(ls)/(µ2(ls))1.5, 1 ≤s ≤S + 1",
        "type": "Title",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 15,
            "languages": [
                "eng"
            ],
            "coordinates": [
                142.95799255371094,
                263.3297119140625,
                390.6698303222656,
                275.41357421875
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "cfe998d8bb0e28a58d3916e546e5be6f",
        "text": "lowband’s kurtosis\nµ4(ls)/(µ2(ls))2, 1 ≤s ≤S + 1",
        "type": "Title",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 15,
            "languages": [
                "eng"
            ],
            "coordinates": [
                142.95799255371094,
                279.7847595214844,
                384.3318176269531,
                291.8685607910156
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "d8daabbdaeb7092511123cd9451267ee",
        "text": "highband’s variance\nµ2(h)",
        "type": "Title",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 15,
            "languages": [
                "eng"
            ],
            "coordinates": [
                142.95799255371094,
                297.5199279785156,
                272.3824462890625,
                308.32354736328125
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "dee1bc806b1fc5b2fd0f2fb1c7e8a161",
        "text": "ℜ{ls} auto-correlation\nΓℜ{ls} (m, n) , 1 ≤s ≤S + 1",
        "type": "Title",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 15,
            "languages": [
                "eng"
            ],
            "coordinates": [
                142.95799255371094,
                313.8457946777344,
                373.494873046875,
                325.7355041503906
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "ae0ab5bc500e0427402777b26ca79f64",
        "text": "|us,q| auto-correlation\nΓ|us,q| (m, n) , 1 ≤s ≤S, 0 ≤q ≤Q −1",
        "type": "Title",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 15,
            "languages": [
                "eng"
            ],
            "coordinates": [
                142.95799255371094,
                329.1497497558594,
                423.1391906738281,
                342.1905212402344
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "b4ef9eda92156ff27b11909e14fe47a5",
        "text": "inner cross-correlation C\n\u0010\n|us,q| ,\n\f\f\fus,q′\f\f\f\n\u0011\n, 1 ≤s ≤S, 0 ≤q, q′ ≤Q −1",
        "type": "Title",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 15,
            "languages": [
                "eng"
            ],
            "coordinates": [
                142.95799255371094,
                342.59033203125,
                454.1462707519531,
                364.5089111328125
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "f9fbb238efb450e3c616c3992638e665",
        "text": "intra cross-correlation\nC\n\u0010\n|us,q| ,\n\f\f\fus+1,q′\f\f\f\n\u0011\n, 1 ≤s ≤S −1, 0 ≤q, q′ ≤Q −1",
        "type": "Title",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 15,
            "languages": [
                "eng"
            ],
            "coordinates": [
                142.95799255371094,
                366.2243347167969,
                481.94427490234375,
                388.1419372558594
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "2113a6d558ac7791fb3c49ba788477b3",
        "text": "C\n\u0012\nℜ{us,q} ,\nℜ\nn\nus+1,q′o",
        "type": "Title",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 15,
            "languages": [
                "eng"
            ],
            "coordinates": [
                248.42098999023438,
                385.3423156738281,
                347.6048278808594,
                404.1144714355469
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "4bf46a17227511fd6c18bceb6f8c47f0",
        "text": "cross-correlation with\nthe\nreal\npart\nof\nthe\nphase",
        "type": "Title",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 15,
            "languages": [
                "eng"
            ],
            "coordinates": [
                139.63699340820312,
                394.15191650390625,
                242.75558471679688,
                428.02447509765625
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "84b0768264c2441cebe5a1c9d7e6c663",
        "text": "Q −1",
        "type": "Title",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 15,
            "languages": [
                "eng"
            ],
            "coordinates": [
                248.41993713378906,
                411.290771484375,
                273.4542541503906,
                421.3824768066406
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "989ee79ce6374affc651816c3e171766",
        "text": "C\n\u0012\nℜ{us,q} ,\nℑ\nn\nus+1,q′o",
        "type": "Title",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 15,
            "languages": [
                "eng"
            ],
            "coordinates": [
                248.42098999023438,
                429.996337890625,
                347.6048278808594,
                448.76947021484375
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "91e14e6b702422ae9cef70c42dabe04a",
        "text": "cross-correlation with\nthe imaginary part of\nthe phase",
        "type": "Title",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 15,
            "languages": [
                "eng"
            ],
            "coordinates": [
                139.63699340820312,
                438.8069152832031,
                242.75990295410156,
                472.6794738769531
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "4797c0b0c4ae11f5f2dfda5ff23e38ac",
        "text": "Q −1",
        "type": "Title",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 15,
            "languages": [
                "eng"
            ],
            "coordinates": [
                248.41993713378906,
                455.94580078125,
                273.4542541503906,
                466.0375061035156
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "d888ee06717731e3c5ea92bac88bbabe",
        "text": "(\n1\nMN\nPM−1\ni=0\nPN−1\nj=0 u(i, j)\nif n = 1\n1\nMN\nPM−1\ni=0\nPN−1\nj=0 (u(i, j) −µ1 (u))n\nif n > 1",
        "type": "Title",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 15,
            "languages": [
                "eng"
            ],
            "coordinates": [
                286.5820007324219,
                478.2763366699219,
                500.45379638671875,
                508.384521484375
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "f3c43a2e6e86cbbb036b3b3c068256fe",
        "text": "Central\nsample\nmo-\nment\nµn(u) =",
        "type": "Title",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 15,
            "languages": [
                "eng"
            ],
            "coordinates": [
                139.6370086669922,
                488.14892578125,
                283.8199768066406,
                510.0664978027344
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "a4b95225f608844c94f2ad8816b374f6",
        "text": "Translation operator\nτx,y (u)\n:\nu(m, n)\n7→\nu(⌊m −x⌋M, ⌊n −y⌋N)\n0 ≤m ≤M −1,\n0 ≤n ≤N −1,\n(x, y) ∈Ω",
        "type": "Title",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 15,
            "languages": [
                "eng"
            ],
            "coordinates": [
                142.95799255371094,
                520.7197875976562,
                489.0184631347656,
                542.7665405273438
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "8fbc940cf05abfd4f6023cafc0919da0",
        "text": "Correlation\nC(u, v) =\n1\nMN\nPM−1\ni=0\nPN−1\nj=0 (u(i, j) −m(u)) (v(i, j) −m(v))∗",
        "type": "Title",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 15,
            "languages": [
                "eng"
            ],
            "coordinates": [
                142.95799255371094,
                550.7843627929688,
                512.1266479492188,
                566.49951171875
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "1eeadeb0862ee4886dd7c843d287d559",
        "text": "Auto-correlation\nΓu (x, y) = C (u, τx,y (u))",
        "type": "Title",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 15,
            "languages": [
                "eng"
            ],
            "coordinates": [
                142.95799255371094,
                574.9218139648438,
                354.4208984375,
                586.5075073242188
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "9fa4faf4857a43299ae49f8f34d2baed",
        "text": "Table 1: Summary of the set of statistical constraints for the Portilla-Simoncelli\nmethod.",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 15,
            "languages": [
                "eng"
            ],
            "coordinates": [
                133.76800537109375,
                597.366943359375,
                477.5174865722656,
                619.2855224609375
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "b21357bf86f01f7103b4c9883d5b4930",
        "text": "15",
        "type": "Title",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 15,
            "languages": [
                "eng"
            ],
            "coordinates": [
                300.64300537109375,
                694.8489379882812,
                310.6055908203125,
                704.8115234375
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "eb48f04235e393fb18199fa006c9e307",
        "text": "\u0013\n, 1 ≤s ≤S −1, 0 ≤q, q′ ≤",
        "type": "Title",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 15,
            "languages": [
                "eng"
            ],
            "coordinates": [
                348.79901123046875,
                387.2673034667969,
                489.01885986328125,
                404.1144714355469
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "48a04e519adcdbf1a5fb8af73320c91b",
        "text": "|us+1,q′|",
        "type": "Title",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 15,
            "languages": [
                "eng"
            ],
            "coordinates": [
                311.072998046875,
                399.35235595703125,
                342.1055908203125,
                409.56439208984375
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "da25ce5e41d28bb1963114f908f017ae",
        "text": "\u0013\n, 1 ≤s ≤S −1, 0 ≤q, q′ ≤",
        "type": "Title",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 15,
            "languages": [
                "eng"
            ],
            "coordinates": [
                348.79901123046875,
                431.9223327636719,
                489.01885986328125,
                448.7695007324219
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "801be2eb0fa42ae74af03b0e7d7aef16",
        "text": "|us+1,q′|",
        "type": "Title",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 15,
            "languages": [
                "eng"
            ],
            "coordinates": [
                311.072998046875,
                444.00738525390625,
                342.1055908203125,
                454.2193908691406
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "4596af9b0ac2bfe13d1441283a4b066e",
        "text": "After setting the set of statistical constraints, a sample verifying them has\nto be generated. Let ck be the corresponding estimated values of the constraint\nfunctions for a particular texture image. Portilla and Simoncelli [69] “samples”\nan image from the set of images that yield the same estimated constraints val-\nues A⃗φ,⃗c = {u : φk(u) = ck, ∀k}. To pick at random from this set the authors\nproposed to select at random a sample u0 from R|Ω| and then project it sequen-\ntially onto subsets of A⃗φ,⃗c. To emulate this the authors proposed a gradient\nprojection. That is moving in the direction of the gradient of the constraint\nφk(v):\nv′ = v + λk\n−→\n∇φk(v)",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 16,
            "languages": [
                "eng"
            ],
            "coordinates": [
                133.76795959472656,
                126.97892761230469,
                477.5374450683594,
                250.0377197265625
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "bb45581f6d52dc9aafa0ea038d319b57",
        "text": "choosing λk such that\nφk(v′) = ck.\n(4)",
        "type": "Title",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 16,
            "languages": [
                "eng"
            ],
            "coordinates": [
                133.7679901123047,
                257.16607666015625,
                477.4812927246094,
                279.92572021484375
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "e4e633fcd643f88b3ec29e5ca6fb46ae",
        "text": "Computing −→\n∇φk(v) is usually simple, and it remains to ﬁnd the λk that solves (4).\nWhen there are multiple solutions for λk, the one with smaller amplitude is cho-\nsen, modifying as little as possible the image. In that way, we stay as close as\npossible to the already projected set. When there is no solution, the λk is the\none that comes closest to satisfying (4). Finally this method can be extended to\nthe adjustment of a subset of constraints. Once the set of statistical measure-\nments is deﬁned and a method to sample from the Julesz’ ensemble of textures,\nthe synthesis can be performed as explained previously.\nIn a pre-attentive examination, the results are in general indistinct from the\noriginal texture samples. Nevertheless, on attentive examination the synthesis\nof structured textures often present blurry and jammed results. Long range\nstructures are missed and the method tends to homogenize the output texture.\nFigure 4 shows two synthesis results. The ﬁrst example (left in Figure 4) repre-\nsents a quasi-periodic image where the method yields excellent results although\nit contains some global structures. In the second example (right in Figure 4),\neven though we recognize the nature of the input sample, one can observe that\nstrong structures are missing. It is impossible to recover the lined up tiles.\nIncreasing the number of orientations Q will improve the results since more\ninformation is captured. However for Q > 4 the improvement is hardly notice-\nable. The number of levels S of the steerable pyramid is the most inﬂuential\nparameter. Depending on the nature of the texture, it will need to be increased\nto capture the details at all scales. Once again, for microtextures this parameter\nis less inﬂuential. Finally, the size of the neighborhood Na used to compute the\nautocorrelation is important whenever the texture has periodic information.\nAs we will see in Section 5, even though imperfect, the results are very im-\npressive, as they succeed modeling most textures using a moderately large set\nof global statistics. This brings us to the following two questions. Is the set of\nstatistics considered enough to describe any kind of textures? Is the optimiza-\ntion step enough to enforce these statistics? Fifteen years later, Gatys et al. [27]\nproposed a texture synthesis method based on Convolutional Neural Networks\n(CNN) which can be seen as an extension of Portilla and Simoncelli’s work,",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 16,
            "languages": [
                "eng"
            ],
            "coordinates": [
                133.76808166503906,
                282.1119384765625,
                480.727783203125,
                657.6663818359375
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "1cc1b4c4ef3918fd1e846c291de322a0",
        "text": "16",
        "type": "Title",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 16,
            "languages": [
                "eng"
            ],
            "coordinates": [
                300.6430969238281,
                694.8488159179688,
                310.6056823730469,
                704.8114013671875
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "0ac6c1a2770bd13caebce362b7df6908",
        "text": "output",
        "type": "Title",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 17,
            "languages": [
                "eng"
            ],
            "coordinates": [
                267.88702392578125,
                126.798095703125,
                292.8095397949219,
                134.7681884765625
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "73167069f37f76393b8134d1d17f630b",
        "text": "input",
        "type": "Title",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 17,
            "languages": [
                "eng"
            ],
            "coordinates": [
                162.24301147460938,
                178.79412841796875,
                181.99293518066406,
                186.76422119140625
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "f112a8d481ad9dacbe59f19af6ee6a48",
        "text": "Figure 4: Synthesis results of the Portilla and Simoncelli method [69]. It is sat-\nisfactory for many small grain textures (left) but may miss the global structure\n(right).",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 17,
            "languages": [
                "eng"
            ],
            "coordinates": [
                133.76800537109375,
                238.45591735839844,
                477.52740478515625,
                272.32952880859375
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "751a4207cfeb9f26c7b309e96ece0dbe",
        "text": "where the set of statistics used is much larger and unknown; also, the optimiza-\ntion is performed by the backpropagation method.",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 17,
            "languages": [
                "eng"
            ],
            "coordinates": [
                133.76800537109375,
                295.8409423828125,
                477.4977111816406,
                317.7585144042969
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "0f2a3c1881f29b4c83ecf24745e7cda4",
        "text": "2.5\nTexture synthesis using CNN",
        "type": "Title",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 17,
            "languages": [
                "eng"
            ],
            "coordinates": [
                133.76800537109375,
                334.1276550292969,
                337.8671569824219,
                346.0828552246094
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "6df692dfcdee9e531cab4dda98adfaed",
        "text": "It is hard to deﬁne metrics to determine if two textures are similar or not ac-\ncording to human taste. Julesz’ conjecture that humans cannot distinguish two\ntextures with same second order statistics was invalidated. Yet this does not\nrule out a more general hypothesis, according to which there is a set of low-level\nﬁlters such that if two textures respect the same statistics for these ﬁlters, they\nare indistinguishable. Portilla and Simoncelli’s approach [69] and Zhu, Wu, and\nMumford’s FRAME (Filters, Random ﬁeld, And Maximum Entropy) [97, 98]\ncan be seen as ﬁxing a set of hand-picked ﬁlters and synthesing new textures by\nenforcing the response to the ﬁlters to have similar statistics. The set of ﬁlters is\nchosen to match human expectations about textures. However determining the\nexact set of ﬁlters equivalent to human vision is very hard, and both approaches\nuse only a subset of them. Portilla and Simoncelli achieve similar statistics by\niterating speciﬁc projections, starting from white noise, while FRAME achieves\nthat with a Gibbs Sampler and some simpliﬁcations (quantizing the image in-\ntensities, etc). Recently, Convolutional Neural Networks (CNNs) have given a\nbreath of fresh air to these approaches. CNNs are compositions of layers of con-\nvolutions, non-linearities and pooling. In the past few years, CNNs have been\nsuccessfully applied in a wide variety of domains, in particular in image related\ntasks. Arguably, the win by a large margin of CNNs [45] in the 2012 ILSVRC\nchallenge [75], an image classiﬁcation challenge, helped spark interest of the\nglobal community to these methods. We refer the reader to the corresponding\nliterature for more details on the working of CNNs.\nBy taking a fully trained CNN on some visual classiﬁcation task, and re-\nstricting to lower layers, one gets a set of low level ﬁlters which can directly\nbe used for synthesizing texture, as shown in several works. The topic is quite\nactive recently, and the question “how to best synthesize a texture with the\nhelp of neural networks” is far from being solved. In the following, we will focus",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 17,
            "languages": [
                "eng"
            ],
            "coordinates": [
                133.76800537109375,
                354.0739440917969,
                477.5773010253906,
                674.871337890625
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "07dde3aca1f740240eaf0e5bc30a7bd6",
        "text": "17",
        "type": "Title",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 17,
            "languages": [
                "eng"
            ],
            "coordinates": [
                300.64300537109375,
                694.8487548828125,
                310.6055908203125,
                704.8113403320312
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "1c4e64b62b28746ebc5ad2a580d51b78",
        "text": "output",
        "type": "Title",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 17,
            "languages": [
                "eng"
            ],
            "coordinates": [
                452.13897705078125,
                126.796142578125,
                477.0614929199219,
                134.7662353515625
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "28463a49ec271c273ff60151bc0df875",
        "text": "input",
        "type": "Title",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 17,
            "languages": [
                "eng"
            ],
            "coordinates": [
                346.4949951171875,
                178.7930908203125,
                366.2449035644531,
                186.76318359375
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "6857e367c7d9609d829b4c423f5a2106",
        "text": "on two diﬀerent approaches: Gatys’ texture generator [27] and DeepFrame [58].\nGatys’ approach is to minimize the distance between the Gram matrices deﬁned\nby the local ﬁlter responses of the network layers, while DeepFrame generates\ntextures by sampling from an exponential model. The use of CNNs by these new\napproaches solves the issues of their ancestors: ﬁrst the ﬁlters do not need to\nbe handpicked anymore, they are encoded directly by the CNN. A pre-trained\nCNN successful on some image-related tasks can be selected for the texture gen-\neration. The choice of the CNN and whether it is pre-trained or the weights are\nrandom, aﬀect the result. Second, the architecture of Neural Networks eases\nthe generation process. The statistics of all the ﬁlters can be handled at the\nsame time, via backpropagation for example. DeepFrame needs no quantization,\nunlike its predecessor, and synthesizes textures at a faster speed. Because the\nﬁlter responses at a given Neural Network layer also encode the image content,\ntexture transfer – also named style transfer – can be achieved by applying the\nstatistics of the ﬁlter responses of a source image to a target image while keeping\noverall the ﬁlter responses similar [29]. While initially both Gatys’ texture gen-\nerator and DeepFrame used the VGG network [80] trained on ImageNet [15],\nmore recent work obtained good results with networks with random weights\n[85] or by integrating the network training with the generation process [93].\nThe success of VGG for texture generation seems to stem from its training on\nan object classiﬁcation task. This implies that its trained features are valuable\n“textons” able to discriminate shape and object features. One could imagine\nusing a network trained to distinguish textures directly, instead of VGG. But,\nto the best of our knowledge, no network has been trained on an ImageNet\nequivalent to textures.\nWe now take a closer look at Gatys’ texture generator and at DeepFrame.\nGatys’ texture model is a generalization of Julesz’ model. It postulates that tex-\ntures are described by the correlations between the neural network activations\n(features). Thus, by starting from random noise and imposing the correlations\nbetween the features to be the same as for a given input texture, one should get\na new sample of this texture.\nMore precisely, Gatys’s texture generator seeks to minimize the cost",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 18,
            "languages": [
                "eng"
            ],
            "coordinates": [
                133.76800537109375,
                126.97892761230469,
                477.5375061035156,
                507.55145263671875
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "0837a103a6e8c733b791b99041253516",
        "text": "l\nwl||Gl −T l||2\nF",
        "type": "Title",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 18,
            "languages": [
                "eng"
            ],
            "coordinates": [
                283.51300048828125,
                516.7026977539062,
                353.2950439453125,
                542.238525390625
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "dd4cec957dbccfbbda1aef824aa9cbf6",
        "text": "E =\nX",
        "type": "Title",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 18,
            "languages": [
                "eng"
            ],
            "coordinates": [
                256.385009765625,
                518.644287109375,
                291.99298095703125,
                530.908447265625
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "fdcf5992969dd0ec0ba0a65e819af498",
        "text": "where ||.||F is the Frobenius norm, wl are weights and Gl, T l are the Gram\nmatrices, respectively for the image and the target texture, of the feature maps\nof a pretrained neural network at a layer l. In [27], a custom 19-layer VGG\nnetwork was used where max pooling was replaced by average pooling and the\nnetwork weights were rescaled. Let Nl be the number of feature maps at layer\nl (this usually corresponds to the number of “channels”), and Ml the size of\neach feature map at layer l (Ml × Nl is the number of outputs of layer l). If\nwe denote by F l\nij, i ∈{1 · · · , Nl}, j ∈{1 · · · , Ml}, the j-th output with the i-th",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 18,
            "languages": [
                "eng"
            ],
            "coordinates": [
                133.76805114746094,
                549.7268676757812,
                477.50762939453125,
                648.9314575195312
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "07ad9bd8521999b9c47bc6629ebc9297",
        "text": "18",
        "type": "Title",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 18,
            "languages": [
                "eng"
            ],
            "coordinates": [
                300.6421813964844,
                694.8488159179688,
                310.6047668457031,
                704.8114013671875
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "17e13bec24da382a045b7245d477b9fe",
        "text": "feature map at layer l, then",
        "type": "Title",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 19,
            "languages": [
                "eng"
            ],
            "coordinates": [
                133.76800537109375,
                126.97892761230469,
                254.33441162109375,
                136.9415283203125
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "5269fb3859bfe6a60bc1a6f8dfbea62d",
        "text": "ij = 1",
        "type": "Title",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 19,
            "languages": [
                "eng"
            ],
            "coordinates": [
                273.0719909667969,
                150.33995056152344,
                303.4192810058594,
                171.02752685546875
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "5c59fb59e6f6763cd3b63cbca870d33f",
        "text": "\u0000\nGl\u0001",
        "type": "Title",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 19,
            "languages": [
                "eng"
            ],
            "coordinates": [
                253.04798889160156,
                155.30177307128906,
                273.06787109375,
                167.04254150390625
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "bf8e42544eaa9db0d76bc43db5c5d78a",
        "text": "Ml",
        "type": "Title",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 19,
            "languages": [
                "eng"
            ],
            "coordinates": [
                294.5669860839844,
                163.91392517089844,
                306.7495422363281,
                174.71759033203125
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "9456240dd1b9432343a41749a62151e6",
        "text": "The texture generator minimizes the cost via backpropagation in the network,\nand thus falls into a local minimum. Starting from white noise, several thousand\niterations can be needed to reach visual convergence. While in [27] the features\nwere extracted from VGG [80], a Deep Convolutional Neural Network trained\non image classiﬁcation tasks, in [85] it is noted that taking a pre-trained network\nis not necessary and a network with random weights can give satisfying results.\nThe minimization of E is done with L-BFGS-B [94] and the bounds are set to\nthe minima and maxima of the source texture. After convergence, the histogram\nof the source is enforced.\nTo generate the results in this article, we made a few changes compared\nto [27].\nThe 19-layer VGG network used in [27] pads the outputs at every\nconvolution layer with zeros on each layer (to have the layer outputs be the\nsame size as the layer inputs). That, plus the fact that pixels on the border are\n“seen” by fewer features than the pixels in the center, means that all pixels on\nthe image are not imposed the same distribution. If we take the same layers\nthan in [27] (conv1_1, pool1, pool2, pool3, pool4) the top layer’s outputs\n(pool4) depend each on a 124 × 124 area of the source. Thus 123 pixels should\nbe removed on each border in order to have all remaining pixels seen by the same\nnumber of features. Removing 123 pixels on each border is not suﬃcient however\nto get the same constraints on the border and the center since the neighbouring\npixels aﬀect the features, and those neighbouring pixels are not aﬀected by\nthe same features. Thus to generate the results in this article, we decided to\nboth remove the padding and generate bigger images – 256 pixels more on each\nborder – which we then crop. The impact of this change can be seen on Figure 5.\nOther than that, we took the same parameters. In [2] the method solves the\nsame problem by removing the network padding and enforcing periodicity. With\nthe default network and parameters of Gatys’ texture generator, except for the\nboundaries, a pixel is seen by 37504 ﬁlters.\nIn Gatys’ method, textures are\nonly described by the Gram matrices. The number of elements in the Gram\nmatrices totals 352256, 176640 if we remove the redundant values (the matrices\nare symmetric). This number of parameters doesn’t depend on the image size,\nand once the Gram matrices of the source computed, the output texture can be\nany size.\nTo ﬁx some of the shortcomings of Gatys’ texture generator [27], several\nworks complete the objective function. The method in [55] incorporates spec-\ntrum constraints to signiﬁcantly improve the generation of textures with low\nfrequency patterns. In [6] the proposed method considers spatial co-occurences\nof features to help handling long-range consistency constraints.\nIn [91] it is\nnoticed that the Gram matrices have several particularities that decrease the\nquality of the texture obtained in several cases with instabilities, particularly\nvisible when generating a texture with a size diﬀerent from the source. In our",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 19,
            "languages": [
                "eng"
            ],
            "coordinates": [
                133.76791381835938,
                186.75498962402344,
                477.54736328125,
                674.9244384765625
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "17d0ee42ac196d4e319e1fca3f34edf7",
        "text": "19",
        "type": "Title",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 19,
            "languages": [
                "eng"
            ],
            "coordinates": [
                300.6429138183594,
                694.8488159179688,
                310.6054992675781,
                704.8114013671875
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "20b4cf3d02b7603502620e03b208a35a",
        "text": "Ml\nX",
        "type": "Title",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 19,
            "languages": [
                "eng"
            ],
            "coordinates": [
                310.19598388671875,
                146.79078674316406,
                324.5919494628906,
                164.74099731445312
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "b9b27cf12dfa6633b2494ec627518a94",
        "text": "k=0\nF l\nikF l\njk.",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 19,
            "languages": [
                "eng"
            ],
            "coordinates": [
                310.14599609375,
                155.3018341064453,
                358.2015686035156,
                178.37261962890625
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "d95ab7747e98a886e9a23ee15d590963",
        "text": "input\nno padding + crop\nno padding\npadding",
        "type": "Title",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 20,
            "languages": [
                "eng"
            ],
            "coordinates": [
                163.41500854492188,
                127.4281005859375,
                460.2258605957031,
                135.398193359375
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "730d4e1d27f20a415ece6d1e7aa34cde",
        "text": "Figure 5: This ﬁgure shows the impact of the padding in the neural network.\nThe second image shows the result of a 1024 × 1024 generated texture without\nthe network padding, cropped to 512 × 512, while the ﬁgures on the right show\n512 × 512 sized generated results without or with padding. The same random\ninitialization was used for all three results (and cropped for the last two results).\nThe diﬀerences are particularly visible on the border of the pictures, since it is\nwhere each variant imposes diﬀerent statistics.",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 20,
            "languages": [
                "eng"
            ],
            "coordinates": [
                133.76797485351562,
                228.51792907714844,
                477.5374450683594,
                310.2115478515625
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "2144da84ccd17871b235e53c3ab78fb6",
        "text": "experiments we didn’t notice such an instability problem, although we observed\nsome instabilities (see for example the fourth column of ﬁgure 20 and the ﬁrst\ncolumn of ﬁgure 22). It is possible that the instabilities are aﬀected by the\nparameter choice. To solve the instability problem, the authors added to the\nobjective function a term to force the feature maps histograms to be the same as\nfor the source. The authors of [63] also discussed some insuﬃciencies of Gram\nmatrices in the case of style transfer, and in particular proposed to shift the\nactivations to avoid sparsity. To accelerate the speed of the texture generation,\nthe method of [83] trains for a given texture a new CNN, which outputs new\nsamples of the texture. The CNN is trained with the same objective function\nas for Gatys’ texture generator. Once the CNN is trained, generation is fast.\nDeepFrame’s texture generator samples from an exponential model.\nThe\nmodel is deﬁned by the probability density function",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 20,
            "languages": [
                "eng"
            ],
            "coordinates": [
                133.76797485351562,
                333.7239685058594,
                477.527587890625,
                487.1484069824219
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "7bb20d82189ff8d864672de694bcb56b",
        "text": "\" K\nX",
        "type": "Title",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 20,
            "languages": [
                "eng"
            ],
            "coordinates": [
                290.5610046386719,
                493.5957336425781,
                310.8189697265625,
                515.9579467773438
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "db4a291d378173a09575fe54433e4282",
        "text": "f(u; w) =\n1\nZ(w) exp",
        "type": "Title",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 20,
            "languages": [
                "eng"
            ],
            "coordinates": [
                202.45196533203125,
                501.55682373046875,
                288.9028625488281,
                525.093505859375
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "849d0bf94da034517906cea45f2ccf84",
        "text": "k=1",
        "type": "Title",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 20,
            "languages": [
                "eng"
            ],
            "coordinates": [
                296.3730163574219,
                522.6157836914062,
                310.8670959472656,
                529.589599609375
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "0b0e92dde65474c266d1955d694808a4",
        "text": "where Fk corresponds to a ﬁlter map extracted from a CNN, Ωis the image\ndomain of u the image, Z(w) is a normalizing constant and g(u) is a reference\ndistribution, like",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 20,
            "languages": [
                "eng"
            ],
            "coordinates": [
                133.76797485351562,
                539.6029663085938,
                477.4830322265625,
                573.4765014648438
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "9e700acd442218f0524ae3393856b93e",
        "text": "g(u) =\n1\n(2πσ2)|Ω|/2 exp\n\u0014\n−1",
        "type": "Title",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 20,
            "languages": [
                "eng"
            ],
            "coordinates": [
                224.1939697265625,
                583.9713134765625,
                349.67132568359375,
                607.8305053710938
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "b17fcd1dbe93a233d7e0e0c6016319a5",
        "text": "In contrast, the FRAME model deﬁned the probability density function",
        "type": "Title",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 20,
            "languages": [
                "eng"
            ],
            "coordinates": [
                133.7679901123047,
                618.2359008789062,
                447.41064453125,
                628.198486328125
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "2b942dfdf12c3cf1ae297c20d7846b15",
        "text": "\" K\nX",
        "type": "Title",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 20,
            "languages": [
                "eng"
            ],
            "coordinates": [
                297.5299987792969,
                634.646728515625,
                317.7869567871094,
                657.0089721679688
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "3d8d15c27fbff1a28f0c2b19d696e3a9",
        "text": "f(u; λ) =\n1\nZ(λ) exp",
        "type": "Title",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 20,
            "languages": [
                "eng"
            ],
            "coordinates": [
                212.59799194335938,
                642.60791015625,
                295.8708801269531,
                666.1434936523438
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "56e72dff82b2c8813a3d65dbe807318a",
        "text": "k=1",
        "type": "Title",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 20,
            "languages": [
                "eng"
            ],
            "coordinates": [
                303.34100341796875,
                663.6657104492188,
                317.8360900878906,
                670.6395263671875
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "e549702c066d1a1d504cc457880aa838",
        "text": "20",
        "type": "Title",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 20,
            "languages": [
                "eng"
            ],
            "coordinates": [
                300.6429748535156,
                694.8489379882812,
                310.6055603027344,
                704.8115234375
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "468a91585e74c1bb401bf8d2ee968c84",
        "text": "#",
        "type": "Title",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 20,
            "languages": [
                "eng"
            ],
            "coordinates": [
                379.9949951171875,
                498.4233703613281,
                385.8031921386719,
                508.3859558105469
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "7587f3a421b6cb19034720d1678dafbc",
        "text": "X",
        "type": "Title",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 20,
            "languages": [
                "eng"
            ],
            "coordinates": [
                313.114990234375,
                505.995361328125,
                327.5109558105469,
                515.9579467773438
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "850b381547121b15762b7a618e8d4496",
        "text": "x∈Ω\nwkFk(u)(x)",
        "type": "Title",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 20,
            "languages": [
                "eng"
            ],
            "coordinates": [
                312.52398681640625,
                508.29693603515625,
                379.9964599609375,
                529.5115966796875
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "29b0babc4ffe476c5eb5e82a81530cfe",
        "text": "g(u),",
        "type": "Title",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 20,
            "languages": [
                "eng"
            ],
            "coordinates": [
                387.46697998046875,
                508.29693603515625,
                408.7975769042969,
                518.259521484375
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "a7588854ece4d092b91457a8da5db3f9",
        "text": "2σ2 ||u||2\n\u0015\n.",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 20,
            "languages": [
                "eng"
            ],
            "coordinates": [
                339.42999267578125,
                583.9713134765625,
                387.05657958984375,
                607.6525268554688
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "df69ffe9b785d4cf379820cb8c6756ac",
        "text": "#",
        "type": "Title",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 20,
            "languages": [
                "eng"
            ],
            "coordinates": [
                392.8379821777344,
                639.4743041992188,
                398.64617919921875,
                649.4369506835938
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "16f3bf4f6934e04b15af12ee822636ce",
        "text": "X",
        "type": "Title",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 20,
            "languages": [
                "eng"
            ],
            "coordinates": [
                320.083984375,
                647.0463256835938,
                334.4799499511719,
                657.0089721679688
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "c2093198298791e349e3910d0d480405",
        "text": "x∈Ω\nλk[Fk ∗u(x)]",
        "type": "Title",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 20,
            "languages": [
                "eng"
            ],
            "coordinates": [
                319.4919738769531,
                649.21875,
                392.8410339355469,
                670.5625610351562
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "b7cef01b49fce18b527f5d7522fca973",
        "text": "where the (Fk)k=1..K were kernels, such as Gabor ﬁlters, or Diﬀerence of Gaus-\nsian ﬁlters, and λk was a discretization function with ﬁnite number of possible\noutputs.\nIn a ﬁrst phase, the DeepFrame parameters w = (wk) are tuned for the\nsource texture, then in a second phase new samples of the texture are generated\nvia Langevin dynamics.\nWhile in [58] a pre-trained network is used, in the\nmethod of [93] its own network is trained on the source.\nWhile both Gatys’ texture generator and DeepFrame have a ﬁxed texture\nmodel used to generate new samples, for which they learn parameters, a third\nsuccessful CNN method to synthesize texture learns directly its model: in [36]\na generative CNN is trained to synthesize new images from one or several sam-\nples of a source. The training is based on the adversarial model: a discrimi-\nnator tries to distinguish the fake generated samples from true ones, while a\ngenerator creates new samples. Spatial invariance assumptions are encoded in\nthe networks, but else, the texture model is in some sense learned by the two\nnetworks. This method can still be considered as a statistics-based method,\nbecause in some sense the discriminator checks the statistics of the texture are\ncorrect. To generate samples with this method (“SGAN” for Spatial Generative\nAdversarial Networks), we took the default network parameters, and applied\nthe source histogram. We stopped after a few hundred epochs. The outputs\nsuﬀer from a sort of noise pattern, which changes after every epoch. When the\nnoise pattern was too important, we decided to select among the last twenty\nepochs the generator’s result with the less noise. SGAN is a recent method, and\nthere are certainly ways to better select the parameters and reduce this noise,\nbut this goes beyond our goals here. Recently a new extension called PSGAN\n(for Periodic Spatial Generative Adversarial Networks) [7] was introduced to ﬁx\nsome shortcomings of SGAN, in particular to improve the generation result for\ntextures with periodic patterns.\nCNNs are also successful in the synthesis of images more general than tex-\ntures [64, 86, 76, 18], in particular with methods relying on Generative Adver-\nsarial Networks (GAN) [30, 16, 73, 35, 88], but these methods are out of the\nscope of this study, which focuses on synthesizing new texture samples based on\na single reference sample. These methods generally need a database of images.",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 21,
            "languages": [
                "eng"
            ],
            "coordinates": [
                133.76797485351562,
                126.97892761230469,
                477.5374755859375,
                519.5064697265625
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "cda7f86584082b163267f38bfc9b93fa",
        "text": "3\nPatch re-arrangement methods",
        "type": "Title",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 21,
            "languages": [
                "eng"
            ],
            "coordinates": [
                133.76797485351562,
                539.0639038085938,
                377.32330322265625,
                553.41015625
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "30a86713d799695d5bfc71e040a26231",
        "text": "In contrast to the statistics-based methods, the patch re-arrangement methods\ndo not attempt to characterize textures by a statistical model. Spanning from\nthe groundbreaking work by Efros and Leung [19], this family of algorithms\nconsists of clever heuristics to re-arrange parts of the sample texture in a random\nway in order to create a new texture. By copying directly from the sample image,\nthese methods often are able to keep complex structures from the input. By the\nsame token, the process is frequently limited to copying and the results show\nlittle innovation relative to the sample. We will illustrate the family here by\nthe original Efros and Leung [19] algorithm, a further extension by Efros and",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 21,
            "languages": [
                "eng"
            ],
            "coordinates": [
                133.76797485351562,
                564.3108520507812,
                477.56719970703125,
                669.9144287109375
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "7ae82bb99b9022fec1983adf8d563fac",
        "text": "21",
        "type": "Title",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 21,
            "languages": [
                "eng"
            ],
            "coordinates": [
                300.6429748535156,
                694.848876953125,
                310.6055603027344,
                704.8114624023438
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "a3f88cbf9477f56130a4cf6492c10d74",
        "text": "input\nGatys\nDeepFrame\nSGAN",
        "type": "Title",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 22,
            "languages": [
                "eng"
            ],
            "coordinates": [
                189.74000549316406,
                127.24212646484375,
                481.6298522949219,
                135.314208984375
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "3d3fa4f53ab73914a20772389c5f621c",
        "text": "input\nGatys\nDeepFrame\nSGAN",
        "type": "Title",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 22,
            "languages": [
                "eng"
            ],
            "coordinates": [
                189.74000549316406,
                229.29010009765625,
                481.6298522949219,
                237.3612060546875
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "a8b3d2f8c055eefdd224f5960b33e699",
        "text": "Figure 6: Comparison between Gatys’ texture generator [27], DeepFrame [58]\nand SGAN [36]. For all three methods, we used the default parameters, except\nthat in the case of Gatys we used the method we described above where we\nremove the network padding and crop the result and in case of DeepFrame and\nSGAN, we speciﬁed the result’s histogram on the source histogram. Overall,\nSGAN looks the best when looking from far, but when zoomed in, Gatys seems\nto respect the best the local structures.",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 22,
            "languages": [
                "eng"
            ],
            "coordinates": [
                133.76800537109375,
                316.4449157714844,
                477.5176696777344,
                398.138427734375
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "44ea983dab09415369ce23aa0584a1d4",
        "text": "Freeman [20] which incorporate more recent techniques, and a more recent CNN\nbased method [53].",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 22,
            "languages": [
                "eng"
            ],
            "coordinates": [
                133.76800537109375,
                421.0528564453125,
                477.4878234863281,
                442.9704284667969
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "5ca1101445425adedaf2bcdf2a8c01f2",
        "text": "3.1\nThe Efros and Leung algorithm",
        "type": "Title",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 22,
            "languages": [
                "eng"
            ],
            "coordinates": [
                133.76800537109375,
                459.2105712890625,
                350.06146240234375,
                471.165771484375
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "33af48c2fcd9db52981f9b3bfff5f0b2",
        "text": "In his foundational paper of information theory [78], Claude E. Shannon pro-\nposed to approximate the information contents of natural languages by the\nentropy of generative stochastic processes. He used a Markov chain to generate\nEnglish text sequentially, letter by letter. Given a piece of already generated\ntext, the next letter is sampled from the probability distribution of English text\nconditioned to the previous n letters. The following sequence was generated by\nShannon using a third-order model:",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 22,
            "languages": [
                "eng"
            ],
            "coordinates": [
                133.76800537109375,
                479.1568603515625,
                477.587158203125,
                560.8504028320312
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "5199e446d04a7a663703a65fbc295d98",
        "text": "in no ist lat whey cratict froure birs grocid pondenome of demons-\ntures of the reptagin is regoactiona of cre",
        "type": "Title",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 22,
            "languages": [
                "eng"
            ],
            "coordinates": [
                158.6750030517578,
                572.058837890625,
                452.60162353515625,
                593.9774169921875
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "e64f5a2133933fb59b58f0bb0779c4f7",
        "text": "Although very few words are real English words, this simple model produces\nsurprisingly good English “textures”. Inspired by Shannon’s method, Efros and\nLeung [19] proposed to adapt the same ideas for image texture synthesis.\nEfros and Leung in [19] synthesize a new texture image by considering that\na pixel value depends on the values of its neighbouring pixels. The method\nis illustrated in Figure 7 and works as follows. For a given input texture, a",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 22,
            "languages": [
                "eng"
            ],
            "coordinates": [
                133.76800537109375,
                605.184814453125,
                477.5674133300781,
                674.9234008789062
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "368c65baa9bcbc8187dfa26a455c0bf3",
        "text": "22",
        "type": "Title",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 22,
            "languages": [
                "eng"
            ],
            "coordinates": [
                300.6419982910156,
                694.8488159179688,
                310.6045837402344,
                704.8114013671875
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "1571a14d38d41bb126cbb0f8b7818c20",
        "text": "input",
        "type": "Title",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 23,
            "languages": [
                "eng"
            ],
            "coordinates": [
                214.40899658203125,
                148.442138671875,
                234.15892028808594,
                156.4122314453125
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "fab28b41d093db8ae044ed60cb8b5e77",
        "text": "(1)\n(2)",
        "type": "Title",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 23,
            "languages": [
                "eng"
            ],
            "coordinates": [
                249.42599487304688,
                172.73789978027344,
                319.9452209472656,
                182.70050048828125
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "3edf2835020b3154f88422dcc63e75c8",
        "text": "Figure 7: Overview of the Efros and Leung algorithm [19]. Given a texture\nimage (left) a new image (right) is being synthesized a pixel at a time. For\na pixel (m, n) (red point in the output) being synthesized the method ﬁnds\nall neighbourhoods in the left image that match the neighbourhood of (m, n)\n(dashed squares) and then chooses randomly one of the neighbourhoods (yellow\nsquare) and assigns its central pixel value to (m, n).",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 23,
            "languages": [
                "eng"
            ],
            "coordinates": [
                133.76800537109375,
                259.2109375,
                477.5374755859375,
                328.948486328125
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "36234b3a75d11b9b259aeca43e71f93e",
        "text": "new image is synthesized sequentially, pixel by pixel. For a pixel (m, n) being\nsynthesized, the algorithm ﬁnds all the neighbourhoods in the input image that\nare similar to the neighbourhood of (m, n) up to a patch distance tolerance.\nThen one of these neighbourhoods is randomly chosen and its central pixel\nvalue is aﬀected to the pixel (m, n). The neighbourhood of (m, n) is a square\npatch but only the known pixels (coming from the seed or already synthetized)\nof this patch are considered when comparing to the neighbourhoods of the input.\nDenoting p1 and p2 two patches of size P × P, the comparison is made using a\nGaussian-weighted distance deﬁned as",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 23,
            "languages": [
                "eng"
            ],
            "coordinates": [
                133.76797485351562,
                352.4609069824219,
                477.5474853515625,
                458.06439208984375
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "7e84c7db5e8043c282f2ab2f7f569ae6",
        "text": "d\n\u0000\np1, p2\n\u0001\n=\n1\nP\ni,j Gσ(i, j)",
        "type": "Title",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 23,
            "languages": [
                "eng"
            ],
            "coordinates": [
                180.39697265625,
                467.746826171875,
                287.6254577636719,
                494.2715148925781
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "4cc11978c945e91717404b8ecb66b3a1",
        "text": "X",
        "type": "Title",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 23,
            "languages": [
                "eng"
            ],
            "coordinates": [
                290.4800109863281,
                472.1853332519531,
                304.8759765625,
                482.1479187011719
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "e7edaf3e5ddbfddb76961845270b5ffc",
        "text": "i,j",
        "type": "Title",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 23,
            "languages": [
                "eng"
            ],
            "coordinates": [
                293.2330017089844,
                488.57672119140625,
                301.713134765625,
                495.550537109375
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "4d3ff6a86346681d6bac9cbf378996b9",
        "text": "where Gσ is a Gaussian kernel with standard deviation σ.\nLevina and Bickel in [51] provided a theoretical justiﬁcation of Efros and\nLeung’s work. The Efros and Leung algorithm is based on resampling from\nthe random ﬁeld directly, without constructing an explicit model for the dis-\ntribution. The authors of [51] formalized this algorithm in the framework of\nresampling from random ﬁelds and proved that it provides consistent estimates\nof the joint distribution of pixels in a window of speciﬁed size.\nIn general the visual results are very impressive, especially for structured\ntextures. Nevertheless this algorithm suﬀers from two important drawbacks:\nverbatim copies of the input and garbage growing (the algorithm starts repro-\nducing iteratively one part of the example and neglects the rest). Figure 8 shows\ntwo synthesis examples. The ﬁrst synthesis result illustrates a failure case. In\nparticular one can observe the eﬀect of garbage growing, which reproduces inco-\nherently the right side of the wood sample texture. The second example shows",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 23,
            "languages": [
                "eng"
            ],
            "coordinates": [
                133.76800537109375,
                506.47088623046875,
                477.5475769042969,
                671.8504638671875
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "80932f1f82b130edd1b4333000807e82",
        "text": "23",
        "type": "Title",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 23,
            "languages": [
                "eng"
            ],
            "coordinates": [
                300.6419982910156,
                694.8489379882812,
                310.6045837402344,
                704.8115234375
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "2ef3b43a0db5dfe2a0d5da13c9636338",
        "text": "output",
        "type": "Title",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 23,
            "languages": [
                "eng"
            ],
            "coordinates": [
                431.43597412109375,
                127.39410400390625,
                456.3584899902344,
                135.36419677734375
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "a7723d1657b9d16975c7e9340e6fb8f1",
        "text": "\u0010\np1(i, j) −p2(i, j)\n\u00112\nGσ(i, j),\n(5)",
        "type": "Title",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 23,
            "languages": [
                "eng"
            ],
            "coordinates": [
                306.531005859375,
                467.8287353515625,
                477.481201171875,
                485.29052734375
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "4490d719f8607bd68b2f7cb43c278652",
        "text": "output",
        "type": "Title",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 24,
            "languages": [
                "eng"
            ],
            "coordinates": [
                206.65899658203125,
                126.796142578125,
                231.58151245117188,
                134.7662353515625
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "46f18ec10ee7ac4646035faf82ed756b",
        "text": "input",
        "type": "Title",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 24,
            "languages": [
                "eng"
            ],
            "coordinates": [
                137.08900451660156,
                177.62115478515625,
                156.83892822265625,
                185.59124755859375
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "cf8a8b532d993a85b500ad341fa3793f",
        "text": "Figure 8: Synthesis results of the Efros and Leung method [19]. Left: the exam-\nple shows the garbage growing eﬀect. Right: the example shows the strength of\nthis method to synthesize macrotextures. The patch size used for both synthesis\nis P = 40.",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 24,
            "languages": [
                "eng"
            ],
            "coordinates": [
                133.76800537109375,
                228.1519012451172,
                477.5175476074219,
                273.97955322265625
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "f2103223737d718b16e743a5613d631b",
        "text": "the strength of this method when it comes to synthesize textures with conspic-\nuous patterns as in this case the brick patterns. To illustrate the verbatim-copy\nregions, position and synthesis maps are used to visualize from which regions\nof the input texture each synthetized pixel comes from. A synthesis and the\ncorresponding map are shown in Figure 9 (obtained with the online demo [1]).\nLarge continuous zones are identiﬁed in the synthesis maps which corresponds\nto the verbatim copies produced by the method. This representation also shows\nthat the synthesized image is indeed a re-arrangement of pieces of the input\nsample.\nIncreasing the patch size P results in increasing the verbatim copied regions.\nHowever if the patch size is too small the local aspect of this method fails in\nrecovering the global conﬁguration of the input texture in particular for macro-\ntextures. A second parameter of the method is the tolerance parameter ε which\nis used to select the most similar patches in the input image. Large tolerance\nvalues increase the garbage growing eﬀect.\nThe Efros and Leung method also suﬀers from its high computational com-\nplexity. Several optimizations have been proposed to accelerate this algorithm.\nAmong them Wei and Levoy [90] managed to ﬁx the shape and size of the\nlearning patch and Ashikhmin [3] proposed to extend existing patches when-\never possible instead of searching in the entire sample texture. The following\nsection describes a particularly important extension of the method.",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 24,
            "languages": [
                "eng"
            ],
            "coordinates": [
                133.7680206298828,
                297.4919738769531,
                477.5474853515625,
                546.5573120117188
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "bf661a1138c3f84dcf7f650036d918e8",
        "text": "3.2\nThe Efros and Freeman algorithm",
        "type": "Title",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 24,
            "languages": [
                "eng"
            ],
            "coordinates": [
                133.76803588867188,
                562.9263916015625,
                364.491455078125,
                574.881591796875
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "f648d628fa9016fad1b41245070557d8",
        "text": "Efros and Freeman’s method [20] is an extension of Efros and Leung’s. It is\nbased on the same principle where the pixel values are conditioned to their\nneighbourhood values. Efros and Freeman proposed to generate a new image\nsequentially, patch by patch (instead of pixel by pixel) in a raster scan order as\nillustrated in Figure 10. At each step a patch that is only partially deﬁned on\na region called overlap region is completed. This overlap region is of width wo.\nThis is the patch under construction. To do so a patch of the input image among",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 24,
            "languages": [
                "eng"
            ],
            "coordinates": [
                133.76803588867188,
                582.8727416992188,
                477.5474548339844,
                664.5663452148438
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "9c5f068f625e2a82ea843740a99875de",
        "text": "24",
        "type": "Title",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 24,
            "languages": [
                "eng"
            ],
            "coordinates": [
                300.64202880859375,
                694.8487548828125,
                310.6046142578125,
                704.8113403320312
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "44d24c573b75eda1182c98bd77d8ce0b",
        "text": "output",
        "type": "Title",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 24,
            "languages": [
                "eng"
            ],
            "coordinates": [
                452.13897705078125,
                126.796142578125,
                477.0614929199219,
                134.7662353515625
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "99615a9bd593673506a7f6ddb10cf90b",
        "text": "input",
        "type": "Title",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 24,
            "languages": [
                "eng"
            ],
            "coordinates": [
                356.8059997558594,
                183.4691162109375,
                376.555908203125,
                191.439208984375
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "088b2cee28e21e3f495eaea2433522bb",
        "text": "Figure 9: From left to right: texture sample, position map, synthesized image\nand synthesis map. The synthesis map shows for each synthesized patch its\ninitial position in the texture sample.\nIt allows then to identify exactly the\nverbatim copy regions (they correspond to continuous color areas of the map).\nThis method reveals the verbatim copies of the input in the generated texture\nand the repetitions (garbage).",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 25,
            "languages": [
                "eng"
            ],
            "coordinates": [
                133.76800537109375,
                245.33091735839844,
                477.527587890625,
                315.0694885253906
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "ea9f4bdc5579d97815d5ab4bbe46766a",
        "text": "those who match the patch under construction on its overlap region is randomly\nselected (patch selection step). An optimal boundary cut between the chosen\npatch (pin) and the one under construction (pold) is then computed across the\noverlap region (stitching step). This optimal boundary cut is used to construct a\nnew patch (pnew) by blending the (pin) and (pold) along the cut. There are three\npossible overlap regions: vertical overlap for the ﬁrst row, horizontal overlap for\nthe ﬁrst column, and L-shaped overlap everywhere else (Figure 10).\nIn the patch selection step, to select a patch pin of an input image u one\ncomputes the square distance between the overlap region of the patch pold and\nthe corresponding regions of all the patches of u. The minimal distance Dmin\nis determined and pin is randomly picked among all patches whose distance to\npold is lower than (1 + ε)Dmin where ε is the tolerance parameter. The squared\ndistance image d contains at each position (m, n) the distance between pold\nand the patch from u according to some binary weight t that equals one in the\noverlap region and zero otherwise. More precisely, one has",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 25,
            "languages": [
                "eng"
            ],
            "coordinates": [
                133.76795959472656,
                338.4989013671875,
                477.53729248046875,
                515.8333129882812
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "95c31895c1f3fc5bd659ffec8c8071c3",
        "text": "d(m, n) =\nX",
        "type": "Title",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 25,
            "languages": [
                "eng"
            ],
            "coordinates": [
                198.64895629882812,
                526.8221435546875,
                258.41790771484375,
                539.0863037109375
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "bbdfe38466d967660d2820d1b0d2a1d5",
        "text": "i,j\nt(i, j)(pold(i, j) −u(m + i, n + j))2.\n(6)",
        "type": "Title",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 25,
            "languages": [
                "eng"
            ],
            "coordinates": [
                246.77496337890625,
                527.3455200195312,
                477.48114013671875,
                550.1883544921875
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "9096bf42cc3bfd08ca5de805b36ea51e",
        "text": "The patch pin of u having coordinates (m, n) is similar to the partially deﬁned\npatch pold on their overlap region. To get the ﬁnal patch pnew one must combine\nthe patches pold and pin. Denoting t the binary weight for the overlap regions\nas in (6), then, for any binary image r such that 0 ≤r(i, j) ≤t(i, j), (i, j) ∈\n{1, . . . , P}2, P can be deﬁned as the combination",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 25,
            "languages": [
                "eng"
            ],
            "coordinates": [
                133.767822265625,
                561.5576782226562,
                477.510498046875,
                619.34033203125
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "ed92cd2608928f94aea0721f1c5e2c54",
        "text": "pnew = t pold + (1 −t) pin.",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 25,
            "languages": [
                "eng"
            ],
            "coordinates": [
                250.0768280029297,
                631.0625610351562,
                361.17242431640625,
                642.6492919921875
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "abbab9cbc395ac332847f4137097d265",
        "text": "The main contribution of Efros and Freeman [20] is to look for a binary shape M\nwhere the transition between pold and pnew along the boundary of the shape is",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 25,
            "languages": [
                "eng"
            ],
            "coordinates": [
                133.76783752441406,
                653.0056762695312,
                477.5107116699219,
                676.4182739257812
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "61389d627d921e977143d8d67ce291b8",
        "text": "25",
        "type": "Title",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 25,
            "languages": [
                "eng"
            ],
            "coordinates": [
                300.64288330078125,
                694.8486938476562,
                310.60546875,
                704.811279296875
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "749ae0fc398a0749c10431cb1d172732",
        "text": "Vertical overlap",
        "type": "Title",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 26,
            "languages": [
                "eng"
            ],
            "coordinates": [
                154.63600158691406,
                123.93388366699219,
                222.89974975585938,
                133.896484375
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "2a9cc8da11a8ba5d3572271e4f2b5524",
        "text": "Horizontal overlap",
        "type": "Title",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 26,
            "languages": [
                "eng"
            ],
            "coordinates": [
                265.51300048828125,
                123.93388366699219,
                345.7417907714844,
                133.896484375
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "9bdd4882bed29801975390264107b1c9",
        "text": "Iteration 10",
        "type": "Title",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 26,
            "languages": [
                "eng"
            ],
            "coordinates": [
                159.08999633789062,
                237.7869110107422,
                218.42724609375,
                247.74951171875
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "57e1d7d1d5e25184abe2de242fc69fca",
        "text": "Iteration 115",
        "type": "Title",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 26,
            "languages": [
                "eng"
            ],
            "coordinates": [
                273.08599853515625,
                237.7869110107422,
                338.15167236328125,
                247.74951171875
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "39101b97a69cc47f6b10697ab60ff973",
        "text": "Figure 10: Three diﬀerent iterations of the synthesis process are shown. At each\niteration a patch is being synthesized. This patch is represented by the pink\nsquare in the three iterations shown. From left to right the three overlap cases\nare represented: vertical, horizontal and L-shape.",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 26,
            "languages": [
                "eng"
            ],
            "coordinates": [
                133.76800537109375,
                256.117919921875,
                477.51763916015625,
                301.94549560546875
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "fe89e8a593cf67dc280da218de8bf833",
        "text": "minimal. For simplicity, and to be able to use linear programming, the authors\ndo not allow for any shape, but only for the ones whose boundaries are simple\nforward paths from one end to the other of the overlap region. This results\nin two pieces of image being sewn together along some general boundary path,\nhence the algorithm’s name “quilting”.\nThis method yields very impressive visual results, in particular for highly\nstructured textures. In terms of speed the gain is truly signiﬁcant with respect\nto the methods which synthesize an image pixel by pixel. The patch size being\nlarger, the risk of garbage growing is reduced compared to the Efros-Leung al-\ngorithm. Nevertheless the risk of verbatim copies remains and is even ampliﬁed.\nMoreover, the respect of the global statistics of the input is not guaranteed and\nthis is quite visible when the input texture is not stationary (for example if there\nis a change of illumination across the image). Figure 11 shows two synthesis ex-\namples. The ﬁrst one (left) shows an excellent synthesis result where the strong\nstructures of the input are perfectly recovered. The second one (right) puts in\nevidence the verbatim copy of parts of the input and the garbage growing eﬀect.\nTo illustrate this the synthesis map of the second example is shown in Figure 12.\nThe parameters P and ε play the same role as in Efros and Leung’s method.\nA third parameter, the overlap size O is used. Increasing this value tends to\nincrease the verbatim copies of large regions. However if this value is too small\nthen garbage growing increases. The value O = 0.25P is generally satisfactory.",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 26,
            "languages": [
                "eng"
            ],
            "coordinates": [
                133.76800537109375,
                325.4579162597656,
                477.5376281738281,
                574.5233154296875
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "7970775a8aababa0ff15ebd1cbe32623",
        "text": "3.3\nHigh level patch re-arrangement with Convolutional\nNeural Networks",
        "type": "Title",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 26,
            "languages": [
                "eng"
            ],
            "coordinates": [
                133.76805114746094,
                590.8924560546875,
                477.6235046386719,
                616.795654296875
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "b47c824ef85a5dc3d316135568055c7b",
        "text": "The CNNs texture synthesis methods presented in Section 2.5 typically gener-\nated new texture samples by enforcing similar statistics on the feature maps of a\npre-trained CNN. At the crossroad of patch re-arrangement methods and CNNs,\nlies CNNMRF [53]. What distinguishes this method to those of Section 2.5 is",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 26,
            "languages": [
                "eng"
            ],
            "coordinates": [
                133.76805114746094,
                624.7867431640625,
                477.5076904296875,
                670.6143188476562
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "fe7f13577eb7d5c969e0352fd9cb1e22",
        "text": "26",
        "type": "Title",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 26,
            "languages": [
                "eng"
            ],
            "coordinates": [
                300.64306640625,
                694.8487548828125,
                310.60565185546875,
                704.8113403320312
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "328ae26aa0174cd6fe62b9593ab5b7f0",
        "text": "L-shape overlap",
        "type": "Title",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 26,
            "languages": [
                "eng"
            ],
            "coordinates": [
                388.489990234375,
                124.05790710449219,
                456.4847106933594,
                134.0205078125
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "dfe1866e7963fe6c883506d8e4340199",
        "text": "Iteration 239",
        "type": "Title",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 26,
            "languages": [
                "eng"
            ],
            "coordinates": [
                389.9469909667969,
                237.6628875732422,
                455.0126647949219,
                247.62548828125
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "20cc2d981a9ed74312508d4d66730808",
        "text": "output",
        "type": "Title",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 27,
            "languages": [
                "eng"
            ],
            "coordinates": [
                267.88702392578125,
                126.796142578125,
                292.8095397949219,
                134.7662353515625
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "ee6b54c90308bdfd28a8d4046c493bb1",
        "text": "input",
        "type": "Title",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 27,
            "languages": [
                "eng"
            ],
            "coordinates": [
                162.24301147460938,
                174.76513671875,
                181.99293518066406,
                182.7352294921875
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "309be0adec66b0dc2c32e79740456650",
        "text": "Figure 11: Synthesis results of the Efros and Freeman method [20]. It works\nfor microtextures but risks losing the example’s global statistics. It works for\nmacrotextures too, but risks verbatim copies.\nTwo examples are shown: a\nsuccess (left) and a failure (right). The parameters used for are P = 80 and\nO = P/4.",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 27,
            "languages": [
                "eng"
            ],
            "coordinates": [
                133.76800537109375,
                230.4009246826172,
                477.5176086425781,
                288.1845703125
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "19a01dd7728fd6fef2bfc136dd2b2b1c",
        "text": "Figure 12: From left to right: texture sample, position map, synthesized image\nand synthesis map. The synthesis map shows for each synthesized patch its\ninitial position in the texture sample. It puts in evidence the verbatim copy re-\ngions (they correspond to continuous color areas of the map) and the repetitions\n(corresponding to repeated continuous patches of the same color).",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 27,
            "languages": [
                "eng"
            ],
            "coordinates": [
                133.76800537109375,
                385.40692138671875,
                477.5176086425781,
                443.1904602050781
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "f9571f2a7031344f9afff84f2772dd7e",
        "text": "that the texture samples are generated by enforcing similar patches of feature\nmaps on selected upper layers of a pre-trained CNN. The image is then obtained\nwith backpropagation and a smoothness constraint.\nMore precisely, starting from random noise, an image is generated by mini-\nmizing the energy:",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 27,
            "languages": [
                "eng"
            ],
            "coordinates": [
                133.76800537109375,
                466.7018737792969,
                477.5077819824219,
                524.4854125976562
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "315ffbaeec5307d62d5038c26c000c4a",
        "text": "i\n||ψi(F l) −ψNN(i)(F l\ns)||2 + R",
        "type": "Title",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 27,
            "languages": [
                "eng"
            ],
            "coordinates": [
                259.67401123046875,
                533.7658081054688,
                394.542724609375,
                558.9434814453125
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "1856769e1dea2b3029d6378b9020aad8",
        "text": "E =\nX",
        "type": "Title",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 27,
            "languages": [
                "eng"
            ],
            "coordinates": [
                216.625,
                535.5782470703125,
                252.2329559326172,
                547.8424072265625
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "db87fb110f6dff23be041fced3ded0c9",
        "text": "X",
        "type": "Title",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 27,
            "languages": [
                "eng"
            ],
            "coordinates": [
                253.88800048828125,
                535.5782470703125,
                268.2839660644531,
                545.5408935546875
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "81c43609a401c7454767e9ab647ddafe",
        "text": "l",
        "type": "Title",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 27,
            "languages": [
                "eng"
            ],
            "coordinates": [
                243.7530059814453,
                552.1986694335938,
                246.2705535888672,
                559.1724853515625
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "23cc692ddda65914f422d3da94dc485d",
        "text": "where l goes among the selected layers (relu3_1 and relu4_1 of the VGG\nnetwork [80]), i goes among all the positions in the layer, ψi(F l) represents the\npatch at the i-th position and ψNN(i)(F l\ns) is its best matching patch in the source\naccording to the normalized cross-correlation. The default patch size is 3 × 3\ntimes the number of feature maps (often referred as the number of “channels” of\nthe layer). R is a regularizer term to impose smoothness of the resulting image.\nIn [53], the energy also contains a term to enforce the content of the source if\ndoing texture transfer. This term isn’t used for texture synthesis.\nAs noted by the author, a natural seamless patch blending is obtained by",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 27,
            "languages": [
                "eng"
            ],
            "coordinates": [
                133.76809692382812,
                569.2898559570312,
                477.5277099609375,
                674.8934326171875
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "3a3b00ce7b99843a20fd14ddb4278ea6",
        "text": "27",
        "type": "Title",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 27,
            "languages": [
                "eng"
            ],
            "coordinates": [
                300.64208984375,
                694.8488159179688,
                310.60467529296875,
                704.8114013671875
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "d6c59760bca5ca80539511591c20a044",
        "text": "output",
        "type": "Title",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 27,
            "languages": [
                "eng"
            ],
            "coordinates": [
                452.13897705078125,
                153.1151123046875,
                477.0614929199219,
                161.085205078125
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "1666c50798055f2f27c20ab5d3961f2e",
        "text": "input",
        "type": "Title",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 27,
            "languages": [
                "eng"
            ],
            "coordinates": [
                346.4949951171875,
                187.92510986328125,
                366.2449035644531,
                195.89520263671875
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "a3044becaf2ff9dcf93f752f54797138",
        "text": "input\nno padding + crop\nno padding\npadding",
        "type": "Title",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 28,
            "languages": [
                "eng"
            ],
            "coordinates": [
                163.41500854492188,
                127.4281005859375,
                460.2258605957031,
                135.398193359375
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "a3947dee273426c039cfe711f96e2dc1",
        "text": "Figure 13: This ﬁgure shows the impact of the padding in the neural network\nwhen generating images with CNNMRF [53]. The second image shows the result\nof a 1024 × 1024 generated texture without the network padding, cropped to\n512 × 512, while the ﬁgures on the right show 512 × 512 sized generated results\nwithout or with padding. The same random initialization was used for all three\nresults (and cropped for the last two results).",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 28,
            "languages": [
                "eng"
            ],
            "coordinates": [
                133.76800537109375,
                228.51792907714844,
                477.5374755859375,
                298.2565612792969
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "b4efc9b79f92f68f30fedf54fd81c2af",
        "text": "performing a patch re-arrangement on the levels of the CNN instead of doing it\ndirectly on the image, like in the other methods of this section.\nSimilarly to what was done in Section 2.5, we removed the padding of the\nVGG network to generate the results of this method. Indeed if the padding\nis kept, the spatial invariance assumption is violated. Moreover pixels on the\nborder of the generated images are seen by fewer features, which reinforces the\nviolation of the spatial invariance. Thus in addition to removing the network\npadding, we generated bigger images and then cropped the result. On ﬁgure 13,\nthe generated texture with the network padding and no border crop kept tends\nto reproduce exactly signiﬁcant parts of the input on the borders. This problem\ndoesn’t appear on the image with the padding removed and the border cropped.\nTo generate the ﬁgures in Section 5 which features images of size 1024 × 1024,\nwe couldn’t add 256 pixels more on each border, as was done in Section 2.5, due\nto memory constraints. Instead we generated images of size 1280 × 1280, which\nwere then cropped.",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 28,
            "languages": [
                "eng"
            ],
            "coordinates": [
                133.76800537109375,
                321.7679748535156,
                477.5473937988281,
                499.1033935546875
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "9ba3727f338409f62122cdd14f078620",
        "text": "4\nHybrid methods",
        "type": "Title",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 28,
            "languages": [
                "eng"
            ],
            "coordinates": [
                133.76800537109375,
                518.6608276367188,
                273.4569396972656,
                533.007080078125
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "0516d3b3adb24688437392727c381036",
        "text": "The two main approaches to texture synthesis are the statistics-based methods\nand the patch re-arrangement methods. In the ﬁrst class, a texture is char-\nacterized by a statistical signature; then, a random sampling conditioned to\nthis signature produces genuinely diﬀerent texture images. Nevertheless, these\nmethods often fail for macrotextures. The second class boils down to a clever\n“copy-paste” procedure, which stitches together verbatim copies of large regions\nof the example. A third kind of hybrid methods combines ideas from both ap-\nproaches, leading to synthesized textures that are everywhere diﬀerent from the\noriginal but with better quality than the purely statistics-based methods. We\nwill describe one such method, its multiscale extension and the explicit combi-\nnation of complementary algorithms.",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 28,
            "languages": [
                "eng"
            ],
            "coordinates": [
                133.7679901123047,
                543.9077758789062,
                477.5275573730469,
                673.42138671875
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "7793dbdece5abf98b43bd579a02c5a7b",
        "text": "28",
        "type": "Title",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 28,
            "languages": [
                "eng"
            ],
            "coordinates": [
                300.6419677734375,
                694.8488159179688,
                310.60455322265625,
                704.8114013671875
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "2190211d794dd7e007e65be98340813f",
        "text": "4.1\nLocal Gaussian models for texture synthesis",
        "type": "Title",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 29,
            "languages": [
                "eng"
            ],
            "coordinates": [
                133.76800537109375,
                125.42164611816406,
                424.076171875,
                137.37684631347656
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "2bbba5c198b8d891df30aae58f00060b",
        "text": "Raad et al.’s method [70] uses locally Gaussian (LG) texture model in the patch\nspace. Each texture patch is modeled by a multivariate Gaussian distribution\nlearned from its similar patches.\nInspired by [20], the idea of searching for\npatches to stitch together in the original sample is maintained. However, instead\nof using the exact patch taken in the input texture, the stitched patch is sampled\nfrom its Gaussian model. Locally Gaussian patch models have been proved very\nuseful in image denoising [10]. This approach permits to maintain the coherence\nbetween patches with respect to the input sample, while creating new patches\nthat do not exist in the sample texture but are still perceptually equivalent to\nit.\nThe multivariate Gaussian models involved are deﬁned by their mean vector\nµ and their covariance matrix Σ. For a given patch p, of size P ×P pixels, these\nparameters are estimated from the set of the R nearest patches Uu\np (nearest\nneighbours of p taken in u) as deﬁned",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 29,
            "languages": [
                "eng"
            ],
            "coordinates": [
                133.76800537109375,
                145.36790466308594,
                477.52764892578125,
                310.7475891113281
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "ad23e01afa9645cdf86efcc7aee0f374",
        "text": "µ\n=\n1\nR\nP\nρ∈Uu\np ρ,",
        "type": "Title",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 29,
            "languages": [
                "eng"
            ],
            "coordinates": [
                225.8699951171875,
                321.0648193359375,
                311.34625244140625,
                337.595458984375
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "df47b9807be0140cdf129d3b06420119",
        "text": "ρ∈Uu\np (ρ −µ) (ρ −µ)t .\n(7)",
        "type": "Title",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 29,
            "languages": [
                "eng"
            ],
            "coordinates": [
                291.5419616699219,
                337.51092529296875,
                477.4811706542969,
                364.79949951171875
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "9ff82c92e7f53c3b9d25bf896393ef69",
        "text": "Σ\n=\n1\nR−1\nP",
        "type": "Title",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 29,
            "languages": [
                "eng"
            ],
            "coordinates": [
                225.8699951171875,
                348.2687072753906,
                291.5464782714844,
                362.6005554199219
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "49086bc560ecd4e75631cd42cef2439d",
        "text": "The sampled vector p′ is deﬁned as",
        "type": "Title",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 29,
            "languages": [
                "eng"
            ],
            "coordinates": [
                133.76797485351562,
                370.637939453125,
                287.340087890625,
                384.2165222167969
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "19603e9e7e677bcec85c45229fe03550",
        "text": "p′ =\n1\n√",
        "type": "Title",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 29,
            "languages": [
                "eng"
            ],
            "coordinates": [
                195.0899658203125,
                393.5699462890625,
                236.4182586669922,
                410.27252197265625
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "fc5b2170ae582d6dda0034a2be24a10d",
        "text": "X",
        "type": "Title",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 29,
            "languages": [
                "eng"
            ],
            "coordinates": [
                256.1009826660156,
                398.0083312988281,
                270.4969482421875,
                407.9709167480469
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "c10d58f4ad29a5601357e6b8602815d6",
        "text": "ρ∈Uu\np\naρ(ρ −µ) + µ,\naρ ∼N(0, 1),\n(8)",
        "type": "Title",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 29,
            "languages": [
                "eng"
            ],
            "coordinates": [
                253.333984375,
                400.1807556152344,
                477.4811096191406,
                423.08221435546875
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "972f8a10b548436a70f2fb81044260a3",
        "text": "R −1",
        "type": "Title",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 29,
            "languages": [
                "eng"
            ],
            "coordinates": [
                225.6790008544922,
                407.90179443359375,
                250.47828674316406,
                417.9934997558594
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "305786bd757f50a720fed697f3486232",
        "text": "where aρ are scalar random variables associated to each patch and following a\nnormal distribution. Note that p′ follows the distribution N(µ, Σ). These mod-\nels have reasonable variances, conﬁrming that eﬀectively the patches simulated\nhave an acceptable degree of innovation [70].\nThe new texture image is synthesized by stitching together patches sampled\nfrom multivariate Gaussian distributions (8) in the input sample patch space.\nThe method is iterative: the patches are synthesized in a raster-scan order (top\nto bottom and left to right). The goal of each iteration is to generate a new\npatch pm,n\nv\n(patch in v placed at (m, n)) that is partially deﬁned on a region\ncalled the overlap area (see Figure 10). The known part of the patch deﬁnes the\nset of patches Uu\npm,n\nv\nfrom which its Gaussian model is inferred. The generated\npatch pm,n\nv\nis then sampled as deﬁned in (8). The last step consists in stitching\nthe patch into the output texture using the quilting method of [20].\nThis synthesis algorithm generates a texture that is perceptually equivalent\nto the sample texture yet not composed of patches existing in the input texture.\nThus, this method reduces some of the drawbacks of the statistics-based and\nthe patch-based methods. Indeed the method yields satisfying results for micro-\nand macro-textures, and reduces the verbatim copies of the input. However,\nthis method remains local and is (like all patch based approaches) not forced to\nrespect the global statistics of the texture sample.",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 29,
            "languages": [
                "eng"
            ],
            "coordinates": [
                133.76788330078125,
                434.04986572265625,
                477.5375671386719,
                672.5243530273438
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "f08093ad22c67a141cb5a993c6d52ce6",
        "text": "29",
        "type": "Title",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 29,
            "languages": [
                "eng"
            ],
            "coordinates": [
                300.64288330078125,
                694.8487548828125,
                310.60546875,
                704.8113403320312
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "566d7d1be993710efdeef0e8bd679d2e",
        "text": "output",
        "type": "Title",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 30,
            "languages": [
                "eng"
            ],
            "coordinates": [
                267.88702392578125,
                126.796142578125,
                292.8095397949219,
                134.7662353515625
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "2da990159a3cf602de65d82f666db324",
        "text": "input",
        "type": "Title",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 30,
            "languages": [
                "eng"
            ],
            "coordinates": [
                162.24301147460938,
                178.7930908203125,
                181.99293518066406,
                186.76318359375
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "b57c727477be2acc3a5d7aa6dbff9729",
        "text": "Figure 14: Synthesis results of the locally Gaussian method [70]. It works well\nfor macrotextures. As one can observe in both examples the result is slightly\nblurry, a characteristics of the Gaussian model. The parameters used for are\nP = 40, R = 30 and O = P/2.",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 30,
            "languages": [
                "eng"
            ],
            "coordinates": [
                133.76800537109375,
                238.45591735839844,
                477.507568359375,
                284.2845153808594
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "545998de64d71618bd807003f1d19c25",
        "text": "Figure 14 shows two results of the method. The algorithm remains depen-\ndent on the choice of the patch size P and of the number of nearest neighbours\nR as illustrated in Figure 15. These values may have to be adjusted for each\ntexture sample.\nAs for the overlap size a convenient value is O = P/2.\nIf\nthis value is too small then the region used to infer the Gaussian models is not\nenough. The patches used to infer the model can be very diﬀerent on a high\nportion of the patch. The algorithm has a low computational complexity, com-\npared for instance with classic patch-based denoising algorithms [49, 13]. An\nalternative to reduce the dependency of the method to the patch size is to work\nin a multiscale approach.",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 30,
            "languages": [
                "eng"
            ],
            "coordinates": [
                133.7680206298828,
                307.7959289550781,
                477.5176696777344,
                425.35540771484375
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "b0be8f665fa4a1572f4eb1f5ac4023cf",
        "text": "4.2\nMultiscale texture synthesis methods",
        "type": "Title",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 30,
            "languages": [
                "eng"
            ],
            "coordinates": [
                133.76803588867188,
                441.7235412597656,
                383.9783935546875,
                453.6787414550781
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "b57ca9c4ce1c3c0f1b7d535e762cd36b",
        "text": "Most real textures are organized at multiple scales: the global structure is re-\nvealed at coarse scales but important detail are present at ﬁner ones. As we\nhave seen, the results of patch-based methods depend strongly on the patch size.\nSmall patch sizes may capture the ﬁner details of the input but the resulting tex-\nture will lack global coherence. On the other hand, using large patches will main-\ntain the global structures at the risk of a “copy-paste” eﬀect. Furthermore, with\nlarge patches it becomes impossible to model the patch variability due to the\nlack of suﬃcient samples. This is apparent in the examples of Figure 14, where\nmodeling patches as multivariate Gaussian vectors leads to a slightly blurry\ntexture. A natural solution is to use a multiscale approach [46, 81, 50, 34, 70]\nusing several patch sizes for a single texture synthesis, capturing diﬀerent levels\nof details.\nThis section illustrates the ideas and diﬃculties of a multiscale extension\nusing as example the local Gaussian models for texture synthesis presented in\nthe previous section [70]. The Multi-Scale Locally Gaussian (MSLG) method\nworks at S scales and can be summarized in a few sentences. The synthesis\nbegins at the coarsest scale (s = S −1) using the local Gaussian method where\nthe quilting step is replaced by a simple average of the overlapping patches. For",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 30,
            "languages": [
                "eng"
            ],
            "coordinates": [
                133.7680206298828,
                461.67083740234375,
                477.51776123046875,
                674.8713989257812
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "a6419dd744447164d639e31611cfa7c2",
        "text": "30",
        "type": "Title",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 30,
            "languages": [
                "eng"
            ],
            "coordinates": [
                300.64300537109375,
                694.8488159179688,
                310.6055908203125,
                704.8114013671875
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "26ded12215dc0cea243f24362a5a7831",
        "text": "output",
        "type": "Title",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 30,
            "languages": [
                "eng"
            ],
            "coordinates": [
                452.13897705078125,
                161.171142578125,
                477.0614929199219,
                169.1412353515625
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "10b1acffb6b960b2153706f441672465",
        "text": "input",
        "type": "Title",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 30,
            "languages": [
                "eng"
            ],
            "coordinates": [
                346.4949951171875,
                195.98114013671875,
                366.2449035644531,
                203.95123291015625
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "91914a3b08aa75a6d3b1a9854716bdfd",
        "text": "input\nR = 10, P = 20\nR = 10, P = 30",
        "type": "Title",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 31,
            "languages": [
                "eng"
            ],
            "coordinates": [
                204.7519989013672,
                305.27392578125,
                428.047119140625,
                315.3135070800781
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "713cf5467f1e08a3e1d3315ea1d72da5",
        "text": "R = 20, P = 10\nR = 20, P = 20\nR = 20, P = 30",
        "type": "Title",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 31,
            "languages": [
                "eng"
            ],
            "coordinates": [
                183.2050018310547,
                402.0179138183594,
                428.047119140625,
                411.9804992675781
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "d303b813af4ad6c20491fe67b67a4f00",
        "text": "R = 30, P = 10\nR = 30, P = 20\nR = 30, P = 30",
        "type": "Title",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 31,
            "languages": [
                "eng"
            ],
            "coordinates": [
                183.2050018310547,
                498.6849365234375,
                428.047119140625,
                508.64752197265625
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "ccfa3e6a92a2361cb2dc1f4acf3dd060",
        "text": "Figure 15: Texture synthesis result for the left top corner texture image. We\nshow the results obtained for diﬀerent values of R (the number of similar\npatches) and P (the side patch size). From left to right P = 10, 20, 30. From top\nto bottom, the number of nearest neighbours is R = 10, 20, 30. All the results\nare obtained for an overlap of a half patch size O = P/2.",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 31,
            "languages": [
                "eng"
            ],
            "coordinates": [
                133.7680206298828,
                518.9529418945312,
                477.5077209472656,
                576.7365112304688
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "a2541715146ae606800ce9dbacd74b75",
        "text": "31",
        "type": "Title",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 31,
            "languages": [
                "eng"
            ],
            "coordinates": [
                300.64306640625,
                694.8489379882812,
                310.60565185546875,
                704.8115234375
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "dcf8c15f55723c3351be62a89b4845c0",
        "text": "the remaining scales (s = S −2, . . . , 0), a synthesis is performed by using the\nresult of the previous scale (s + 1) and the sample image at the corresponding\nresolution. At each scale the synthesis is done patch by patch in a raster-scan\norder. Each new patch, added to the synthesized image, overlaps part of the\npreviously synthesized patch and it is the combination of a low resolution patch\nand a high resolution one sampled from a multivariate Gaussian distribution.\nThe Gaussian distribution of the high frequencies of a given patch is estimated\nfrom the high frequencies of its m nearest neighbours in the corresponding scale\ninput image. The synthesis result of the ﬁner scale is the desired output image.\nLet us denote the sample texture by u and us, s = 1, . . . , S −1 are the\nzoomed out versions by a factor 2s, s = 1, . . . , S −1.\nThe synthesis result\nat each scale is denoted by vs, s = 1, . . . , S −1 and v is the synthesis result\nreturned by the multiscale algorithm. An additional image ˜vs is needed at each\nscale, corresponding to a low resolution version of vs obtained by interpolating\nvs+1.\nTo estimate the parameters of the Gaussian distribution of the patch\npm′,n′\nvs\nbeing processed, the set Uus\npm′,n′\nvs\nof R nearest patches in us is considered.",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 32,
            "languages": [
                "eng"
            ],
            "coordinates": [
                133.7679901123047,
                126.84981536865234,
                477.5474548339844,
                323.0413818359375
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "abfcda76adf3b2c5b534d4302247dbdf",
        "text": "The R nearest neighbours in us to the current patch are those minimizing the\nL2 distance restricted to the overlap area:",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 32,
            "languages": [
                "eng"
            ],
            "coordinates": [
                133.76800537109375,
                322.0820617675781,
                477.4912414550781,
                343.9996337890625
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "6d276f316b1cb879003048f224a40da8",
        "text": "d(pm,n\nus , pm′,n′\nvs\n)2 =\n1\n|O|",
        "type": "Title",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 32,
            "languages": [
                "eng"
            ],
            "coordinates": [
                158.38800048828125,
                352.5539855957031,
                253.5793914794922,
                375.9613952636719
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "b95e0526bbd88db86b2c679f109bf50b",
        "text": "(i,j)∈O\n(us(m + i, n + j) −vs(m′ + i, n′ + j))2",
        "type": "Title",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 32,
            "languages": [
                "eng"
            ],
            "coordinates": [
                256.42999267578125,
                355.1799011230469,
                452.36517333984375,
                380.9735412597656
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "20a745f5596ccaf3f7903648f57818c1",
        "text": "X",
        "type": "Title",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 32,
            "languages": [
                "eng"
            ],
            "coordinates": [
                262.739990234375,
                356.9923400878906,
                277.1359558105469,
                366.9549255371094
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "da92ec7fe5a222610e5e55548dada2db",
        "text": "P −1\nX",
        "type": "Title",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 32,
            "languages": [
                "eng"
            ],
            "coordinates": [
                255.14300537109375,
                386.3963928222656,
                271.49005126953125,
                404.2659606933594
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "92817cedb5afa9ee7657d4535c243c2d",
        "text": "+ 1",
        "type": "Title",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 32,
            "languages": [
                "eng"
            ],
            "coordinates": [
                227.56610107421875,
                389.8639221191406,
                247.33938598632812,
                406.5664978027344
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "ee3e131dabe05890a6bb8bdad668c450",
        "text": "i,j=0\n(˜us(m + i, n + j) −˜vs(m′ + i, n′ + j))2,\n(9)",
        "type": "Title",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 32,
            "languages": [
                "eng"
            ],
            "coordinates": [
                253.82899475097656,
                392.4909362792969,
                477.481201171875,
                417.6685791015625
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "6aadbbc24f62739308e2d4f9f8a7b719",
        "text": "P 2",
        "type": "Title",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 32,
            "languages": [
                "eng"
            ],
            "coordinates": [
                238.7239990234375,
                402.895751953125,
                250.47906494140625,
                413.4005126953125
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "335a95881d547b5c117764db42f78ac1",
        "text": "where ˜us denotes the low resolution of the image us, ˜us = us ∗Gσ and ˜vS−1 =\nuS−1∗Gσ. In (9), the overlap area is denoted as O and the size of patch overlap is\nﬁxed to P/2. On the set Uus\npm′,n′\nvs\nonly the high frequency of the patches pi,j\nus −pi,j\n˜us\nis considered to infer the multivariate Gaussian distribution N(µH, ΣH). The\npatch pm,n\nvs\nis synthesized as the combination of a low resolution patch pm,n\n˜vs\nyield from the previous scale with a high resolution one p ∼N(µH, ΣH), thus\npm,n\nvs\n= pm,n\n˜vs\n+ p. For more details please refer to [70].\nFigure 16 shows two synthesis examples. In both cases the result is satis-\nfyingly recovering the details of the diﬀerent scales for reasonable values of the\npatch size P = 20. However one can notice that the results are blurry with\nrespect to the input and this eﬀect is increased with respect to the single scale\napproach.",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 32,
            "languages": [
                "eng"
            ],
            "coordinates": [
                133.76800537109375,
                427.6598205566406,
                477.5086669921875,
                573.6324462890625
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "90b387ed67a0252f42cd18d25d3ab67d",
        "text": "4.3\nCombination of methods",
        "type": "Title",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 32,
            "languages": [
                "eng"
            ],
            "coordinates": [
                133.76904296875,
                589.8635864257812,
                309.869140625,
                601.8187866210938
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "c210272e83deddecc8a9b7a7919f5f12",
        "text": "A smart combination of complementary methods may keep the advantages of\neach one. We will illustrate the methodology by combining a multiscale ap-\nproach with three other methods:",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 32,
            "languages": [
                "eng"
            ],
            "coordinates": [
                133.76904296875,
                609.8098754882812,
                477.5086364746094,
                643.6824951171875
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "7a7e80126d3bcea6463c644eb03bc36e",
        "text": "MSLG+EF The Multi-Scale Locally Gaussian method combined with the\nEfros and Freeman method.",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 32,
            "languages": [
                "eng"
            ],
            "coordinates": [
                133.76904296875,
                653.0059204101562,
                477.4986572265625,
                674.9234619140625
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "4370c0eaef63d1a34ad6e64580c49054",
        "text": "32",
        "type": "Title",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 32,
            "languages": [
                "eng"
            ],
            "coordinates": [
                300.64306640625,
                694.8489379882812,
                310.60565185546875,
                704.8115234375
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "d518a3d7329db76dce6efbac2a6633be",
        "text": "output",
        "type": "Title",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 33,
            "languages": [
                "eng"
            ],
            "coordinates": [
                282.9700012207031,
                133.130126953125,
                307.89251708984375,
                141.1002197265625
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "051aeb82b9fd359499cbe28dd213dafb",
        "text": "input",
        "type": "Title",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 33,
            "languages": [
                "eng"
            ],
            "coordinates": [
                169.93899536132812,
                170.2291259765625,
                189.6889190673828,
                178.19921875
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "61147c2093edc279b00d13083df62a71",
        "text": "Figure 16: Synthesis results of the multiscale locally Gaussian method [70].\nBoth examples show that the details of diﬀerent scales are correctly synthesized\nwhen using a patch size P = 20. However the results are slightly blurred with\nrespect to the input. The number of scales is S = 3 for the ﬁrst example (left)\nand S = 2 for the second example (right).",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 33,
            "languages": [
                "eng"
            ],
            "coordinates": [
                133.7679901123047,
                214.9939422607422,
                477.50830078125,
                272.777587890625
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "8fb998d4b6bc751ca9b09e94b619bcac",
        "text": "MSLG+PS The Multi-Scale Locally Gaussian method combined with the Por-\ntilla and Simoncelli method.",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 33,
            "languages": [
                "eng"
            ],
            "coordinates": [
                133.76800537109375,
                296.28900146484375,
                477.5065002441406,
                318.20758056640625
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "07f9fb70609914d2357d814a69532b21",
        "text": "MSLG+Gatys The Multi-Scale Locally Gaussian method combined with the\nGatys et al. method.",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 33,
            "languages": [
                "eng"
            ],
            "coordinates": [
                133.7680206298828,
                328.16998291015625,
                477.5062561035156,
                350.0875549316406
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "cf78fc4456a6ae568f5a0fe5aaec25c8",
        "text": "The combination of the Multi-Scale Locally Gaussian method with the Efros\nand Freeman method (MSLG+EF) consists of two steps. The ﬁrst step synthe-\nsizes the given input u with the Multi-Scale Locally Gaussian method generating\na new texture image that we denote umslg. The second step consists in apply-\ning the Efros and Freeman algorithm to the given input sample, initializing the\noutput image that we denote uef with the image umslg. The method is basically\nthe same as the one described in section 3.2. The only step of the algorithm\nthat is modiﬁed is the patch selection step. In the method described in [20] at\neach iteration the added patch was chosen among those (in the input sample)\nwhose overlap region was similar to the one of the patch under construction.\nWhen combining the methods, instead of only comparing the overlap areas, the\nentire patches are compared. Initializing the output with a ﬁrst synthesis umslg\nenables the method to use the whole patch under construction to ﬁnd a candi-\ndate in the input sample u. The candidate patch taken from u is then quilted\nin uef at the corresponding position with the same stitching step as in [20].\nThis combination allows to recover the lost resolution of the MSLG synthesis\nas illustrated in Figure 17. However it is not capable of masking the garbage\ngrowing eﬀects as eﬀectively MSLG+PS combination does.\nThe combination of the Multi-Scale Locally Gaussian method with the Por-\ntilla and Simoncelli method (MSLG+PS) consists of two steps.\nIn the ﬁrst\nstep, given the input image u, a new texture umslg is generated using MSLG.\nThe second step uses PS where the initialization “noise image” is replaced by\numslg generating the output image that we denote ups. As explained in section\n2.4, the statistics to impose are learnt on the input u. What follows is a syn-\nthesis step where the output image is projected on the subspaces of constraints.\nThere exist several local solutions to this projection step. When initializing PS",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 33,
            "languages": [
                "eng"
            ],
            "coordinates": [
                133.76797485351562,
                360.0499572753906,
                477.5473937988281,
                668.8923950195312
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "4930d8365971fad82bbcf1f7739609bf",
        "text": "33",
        "type": "Title",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 33,
            "languages": [
                "eng"
            ],
            "coordinates": [
                300.6419982910156,
                694.8488159179688,
                310.6045837402344,
                704.8114013671875
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "914a76781d5a59f26a10af701d139ad3",
        "text": "output",
        "type": "Title",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 33,
            "languages": [
                "eng"
            ],
            "coordinates": [
                444.968994140625,
                126.796142578125,
                469.8915100097656,
                134.7662353515625
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "0a95a64d0e5c9403b9a03946515fc930",
        "text": "input",
        "type": "Title",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 33,
            "languages": [
                "eng"
            ],
            "coordinates": [
                359.8599853515625,
                154.7601318359375,
                379.6098937988281,
                162.730224609375
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "48de7bdc8dde77ce9913ede7c8a790e1",
        "text": "input",
        "type": "Title",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 34,
            "languages": [
                "eng"
            ],
            "coordinates": [
                172.5540008544922,
                189.11309814453125,
                192.30392456054688,
                197.08319091796875
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "63a427c827631570d19ebb79bc81ade6",
        "text": "Figure 17: Synthesis results of the combination of the Multi-Scale Locally Gaus-\nsian method with the Efros and Freeman (MSLG+EF).",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 34,
            "languages": [
                "eng"
            ],
            "coordinates": [
                133.76800537109375,
                259.0799560546875,
                477.517578125,
                280.99853515625
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "579ecf2db752f3ed3dfbb2cc9dcc054d",
        "text": "input",
        "type": "Title",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 34,
            "languages": [
                "eng"
            ],
            "coordinates": [
                172.5540008544922,
                358.67510986328125,
                192.30392456054688,
                366.64520263671875
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "57acf41ca902b7a6fccdcc98edc315b5",
        "text": "Figure 18: Synthesis results of the combination of the Multi-Scale Locally Gaus-\nsian method with the Portilla and Simoncelli methods (MSLG+PS).",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 34,
            "languages": [
                "eng"
            ],
            "coordinates": [
                133.76800537109375,
                428.6429138183594,
                477.517578125,
                450.56048583984375
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "f643db7ab74ee40ec73ab04550906e80",
        "text": "with the result of MSLG, the initialization image is generally quite close to the\nimages living in the sub-space of the whole set of constraints. Thus the result ob-\ntained is improved compared to PS images starting from a random noise image.\nNaturally ﬁxing the initialization of the PS algorithm removes the randomness\nof the generated texture. But this is not the case since the initialization is itself\nrandom as it is generated from another random process. This combination is\nillustrated in Figure 18.\nThe combination of the Multi-Scale Locally Gaussian method with Gatys’\ntexture generator (MSLG+Gatys) is very similar to its combination with the\nPortilla and Simoncelli method. The texture generator is initialized with the\nresult of MSLG umslg, and the statistics of the target image are enforced via\nseveral iterations of backpropagation generating the output image denoted as\nugatys. This combination is illustrated in Figure 19.",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 34,
            "languages": [
                "eng"
            ],
            "coordinates": [
                133.76800537109375,
                474.0718994140625,
                477.5375671386719,
                627.4964599609375
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "9d1cb74f4b7d0597d84cf6ac49bce909",
        "text": "34",
        "type": "Title",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 34,
            "languages": [
                "eng"
            ],
            "coordinates": [
                300.64300537109375,
                694.848876953125,
                310.6055908203125,
                704.8114624023438
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "f9c3f00034caa8edbb39a1d8bc6e5028",
        "text": "MSLG\nMSLG+EF",
        "type": "Title",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 34,
            "languages": [
                "eng"
            ],
            "coordinates": [
                312.2440185546875,
                127.340087890625,
                478.3714904785156,
                135.3101806640625
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "67f2538660122f2f1d9e9529c81debc6",
        "text": "MSLG\nMSLG+PS",
        "type": "Title",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 34,
            "languages": [
                "eng"
            ],
            "coordinates": [
                312.2440185546875,
                296.901123046875,
                478.3705749511719,
                304.8712158203125
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "4491653f97697ef15a8b697e03dd00a7",
        "text": "input",
        "type": "Title",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 35,
            "languages": [
                "eng"
            ],
            "coordinates": [
                172.5540008544922,
                189.11309814453125,
                192.30392456054688,
                197.08319091796875
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "08d85b8f276e7e5c53ec9658ba01faf8",
        "text": "Figure 19: Synthesis results of the combination of the Multi-Scale Locally Gaus-\nsian method with Gatys’ texture generator (MSLG+Gatys).",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 35,
            "languages": [
                "eng"
            ],
            "coordinates": [
                133.76800537109375,
                259.0809326171875,
                477.517578125,
                280.99853515625
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "67c47d1821ab095644ce56c518f383a8",
        "text": "5\nExperiments",
        "type": "Title",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 35,
            "languages": [
                "eng"
            ],
            "coordinates": [
                133.76800537109375,
                301.08502197265625,
                246.94517517089844,
                315.43121337890625
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "4855a3b2449fb868dd55d1ac847b744d",
        "text": "The ﬁrst part of this section compares the exemplar-based texture synthesis\nmethods described before on a set of standard textures. These results illustrate\nthe advantages and limitations of each one. Then, the second part attempts at\nthe synthesis of real life and more complex textured images, revealing the short-\ncomings still present in all the methods when confronted with such a demanding\ntask.",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 35,
            "languages": [
                "eng"
            ],
            "coordinates": [
                133.76800537109375,
                326.33197021484375,
                477.51776123046875,
                396.07049560546875
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "801e6581e045fb90eb04c3585142c88b",
        "text": "5.1\nComparative evaluation",
        "type": "Title",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 35,
            "languages": [
                "eng"
            ],
            "coordinates": [
                133.76800537109375,
                412.4386291503906,
                304.41650390625,
                424.3938293457031
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "3de1a32a7395d77d1ab0746b67f74372",
        "text": "We will compare the results of the following texture synthesis methods: Random\nPhase Noise (RPN) [87, 23], Heeger and Bergen (HB) [33], Portilla and Simon-\ncelli (PS) [69], Gatys (Gatys) [27], SGAN [36], Efros and Leung (EL) [19], Efros\nand Freeman (EF) [20], CNNMRF [53] and MSLG [70]. Figures 20 to 23 show\nresults for various texture samples, one per column; in each ﬁgure, the ﬁrst row\nshows the sample image and the following rows correspond, as indicated, to one\nof the algorithms. We focus on these original texture synthesis algorithms, and\ndo not show the numerous variants. For several of our sample textures, these\nvariants could get better results, but we think that showing the results of the\noriginal algorithms better underlines their intrinsic strengths and weaknesses.\nSimilarly we won’t present the results of all the combinations of the diﬀerent\nmethods.\nThe second to sixth rows correspond to statistics-based methods described\nin Section 2, namely Random Phase Noise, Heeger-Bergen, Portilla-Simoncellli,\nGatys and SGAN. Early statistics-based methods: Heeger and Bergen (1995),\nPortilla and Simoncelli (2000) and Random Phase Noise (1991) yield good re-\nsults for microtextures, i.e. textures with no conspicuous structures, as can be\nseen in the ﬁrst texture example of Figure 20 and to a lesser extent for the\nsecond and third example. The Heeger and Bergen’s method is inspired on a\nmodel of the early visual cortex; it provides satisfying results in some cases but",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 35,
            "languages": [
                "eng"
            ],
            "coordinates": [
                133.76800537109375,
                432.3849182128906,
                477.55743408203125,
                669.4963989257812
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "6497c7a016b46a0b694f5f330f19f527",
        "text": "35",
        "type": "Title",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 35,
            "languages": [
                "eng"
            ],
            "coordinates": [
                300.64300537109375,
                694.8488159179688,
                310.6055908203125,
                704.8114013671875
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "079675f2f903ad163af090bfdd3dff6a",
        "text": "MSLG\nMSLG+Gatys",
        "type": "Title",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 35,
            "languages": [
                "eng"
            ],
            "coordinates": [
                312.2440185546875,
                127.340087890625,
                478.3662109375,
                135.3101806640625
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "9158d33ed0cee9b3afb9d86f66443745",
        "text": "input",
        "type": "Title",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 36,
            "languages": [
                "eng"
            ],
            "coordinates": [
                160.75900268554688,
                204.6089324951172,
                184.02166748046875,
                214.571533203125
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "1426bcdb9d501ddbbda240104d3168e3",
        "text": "RPN [23]",
        "type": "Title",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 36,
            "languages": [
                "eng"
            ],
            "coordinates": [
                143.8000030517578,
                255.60594177246094,
                184.20831298828125,
                265.56854248046875
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "f0ff9a18d66abdc3b37a4569a52f49e3",
        "text": "HB [33]",
        "type": "Title",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 36,
            "languages": [
                "eng"
            ],
            "coordinates": [
                150.85699462890625,
                321.9349365234375,
                184.2018280029297,
                331.89752197265625
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "9c8866dd18be280fda756ea76ec80815",
        "text": "PS [69]",
        "type": "Title",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 36,
            "languages": [
                "eng"
            ],
            "coordinates": [
                153.0709991455078,
                388.2649230957031,
                184.21408081054688,
                398.2275085449219
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "ae2619fc201ba19bbd39f4c6c7b3ada7",
        "text": "Gatys [27]",
        "type": "Title",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 36,
            "languages": [
                "eng"
            ],
            "coordinates": [
                139.80099487304688,
                454.5959167480469,
                184.2142791748047,
                464.5585021972656
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "c4e3d6137601fbb1bde9cfc337267c93",
        "text": "SGAN [36]",
        "type": "Title",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 36,
            "languages": [
                "eng"
            ],
            "coordinates": [
                137.08900451660156,
                520.9249267578125,
                184.2121124267578,
                530.8875122070312
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "35698ca158db0b0a15ddd87da1e03262",
        "text": "Figure 20: Comparison of texture synthesis methods. From top to bottom: input\nsample, Random Phase Noise (RPN) [23], Heeger and Bergen (HB) [33], Portilla\nand Simoncelli (PS) [69], Gatys (Gatys) [27] and SGAN [36].",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 36,
            "languages": [
                "eng"
            ],
            "coordinates": [
                133.7689971923828,
                567.6969604492188,
                477.50567626953125,
                601.5704956054688
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "808343db3ffe7f36378497c9cb3b2a86",
        "text": "36",
        "type": "Title",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 36,
            "languages": [
                "eng"
            ],
            "coordinates": [
                300.64300537109375,
                694.8489379882812,
                310.6055908203125,
                704.8115234375
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "7c97bfa659e973adb78fc1e1eccca393",
        "text": "input",
        "type": "Title",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 37,
            "languages": [
                "eng"
            ],
            "coordinates": [
                177.5709991455078,
                237.77293395996094,
                200.8336639404297,
                247.73553466796875
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "495a7af290c2b515fc07cfb32599d2a7",
        "text": "EL [19]",
        "type": "Title",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 37,
            "languages": [
                "eng"
            ],
            "coordinates": [
                169.19100952148438,
                288.7719421386719,
                201.02151489257812,
                298.7345275878906
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "8ffb79956d0323523d0a46b91be7f7b9",
        "text": "EF [20]",
        "type": "Title",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 37,
            "languages": [
                "eng"
            ],
            "coordinates": [
                168.91400146484375,
                355.1019287109375,
                201.02346801757812,
                365.06451416015625
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "f9ff4c369ddceca63638fa272056ff9b",
        "text": "CNNMRF [53]",
        "type": "Title",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 37,
            "languages": [
                "eng"
            ],
            "coordinates": [
                137.0889892578125,
                421.4289245605469,
                201.01901245117188,
                431.3915100097656
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "986c43fecd69016eb8001d4d95c1ed7f",
        "text": "MSLG [70]",
        "type": "Title",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 37,
            "languages": [
                "eng"
            ],
            "coordinates": [
                153.48599243164062,
                487.7589416503906,
                201.02752685546875,
                497.7215270996094
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "b98bff3cd49a5b0b1996522da407a610",
        "text": "Figure 21: Comparison of texture synthesis methods. From top to bottom: input\nsample, Efros and Leung (EL) [19], Efros and Freeman (EF) [20], CNNMRF [53]\nand MSLG [70].",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 37,
            "languages": [
                "eng"
            ],
            "coordinates": [
                133.7689971923828,
                534.5319213867188,
                477.53839111328125,
                568.405517578125
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "78a34914c3497b172d076253d56a14b8",
        "text": "37",
        "type": "Title",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 37,
            "languages": [
                "eng"
            ],
            "coordinates": [
                300.64300537109375,
                694.8489379882812,
                310.6055908203125,
                704.8115234375
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "8961e824d8a342eab8d60eb28cb015b1",
        "text": "input",
        "type": "Title",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 38,
            "languages": [
                "eng"
            ],
            "coordinates": [
                160.75900268554688,
                204.6089324951172,
                184.02166748046875,
                214.571533203125
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "11d3b1484ab8a2f97e39d4bd408b01b8",
        "text": "RPN [23]",
        "type": "Title",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 38,
            "languages": [
                "eng"
            ],
            "coordinates": [
                143.8000030517578,
                255.60691833496094,
                184.20831298828125,
                265.56951904296875
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "8cf40a319d75eef7102f6285ac21ddb3",
        "text": "HB [33]",
        "type": "Title",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 38,
            "languages": [
                "eng"
            ],
            "coordinates": [
                150.85699462890625,
                321.9369201660156,
                184.2018280029297,
                331.8995056152344
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "5b0d336a0c9bbb40f45a7131dbe5b7df",
        "text": "PS [69]",
        "type": "Title",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 38,
            "languages": [
                "eng"
            ],
            "coordinates": [
                153.0709991455078,
                388.2669372558594,
                184.21408081054688,
                398.2295227050781
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "b804bdcf7bed73116718902c0855a2a9",
        "text": "Gatys [27]",
        "type": "Title",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 38,
            "languages": [
                "eng"
            ],
            "coordinates": [
                139.80099487304688,
                454.596923828125,
                184.2142791748047,
                464.55950927734375
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "48cae7c097388751ceec45442d5dd732",
        "text": "SGAN [36]",
        "type": "Title",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 38,
            "languages": [
                "eng"
            ],
            "coordinates": [
                137.08900451660156,
                520.9269409179688,
                184.2121124267578,
                530.8895263671875
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "010091c044b38b608afab4b90321bd2f",
        "text": "Figure 22: Comparison of texture synthesis methods. From top to bottom: input\nsample, Random Phase Noise (RPN) [23], Heeger and Bergen (HB) [33], Portilla\nand Simoncelli (PS) [69], Gatys (Gatys) [27] and SGAN [36].",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 38,
            "languages": [
                "eng"
            ],
            "coordinates": [
                133.7689971923828,
                567.6959228515625,
                477.50567626953125,
                601.5695190429688
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "620dd04a2bf27fbe782ba12f6cb3d96f",
        "text": "38",
        "type": "Title",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 38,
            "languages": [
                "eng"
            ],
            "coordinates": [
                300.64300537109375,
                694.8489379882812,
                310.6055908203125,
                704.8115234375
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "d9cae1fb65861e15e297f1829ad97d50",
        "text": "input",
        "type": "Title",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 39,
            "languages": [
                "eng"
            ],
            "coordinates": [
                177.5709991455078,
                237.7718963623047,
                200.8336639404297,
                247.7344970703125
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "38fc984566e5af5bcae9c4e65771c3d2",
        "text": "EL [19]",
        "type": "Title",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 39,
            "languages": [
                "eng"
            ],
            "coordinates": [
                169.19100952148438,
                288.7699279785156,
                201.02151489257812,
                298.7325134277344
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "f4a99d118e25b938b6ca4b48565ea493",
        "text": "EF [20]",
        "type": "Title",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 39,
            "languages": [
                "eng"
            ],
            "coordinates": [
                168.91400146484375,
                355.09991455078125,
                201.02346801757812,
                365.0625
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "6c6a8e162fbf77727940ab2e635a0626",
        "text": "CNNMRF [53]",
        "type": "Title",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 39,
            "languages": [
                "eng"
            ],
            "coordinates": [
                137.0889892578125,
                421.429931640625,
                201.01901245117188,
                431.39251708984375
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "def6d34eba474c9d2d741beaaa8d6bcd",
        "text": "MSLG [70]",
        "type": "Title",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 39,
            "languages": [
                "eng"
            ],
            "coordinates": [
                153.48599243164062,
                487.7599182128906,
                201.02752685546875,
                497.7225036621094
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "fc7d23fcd679048a28744c9b67c2ca6b",
        "text": "Figure 23: Comparison of texture synthesis methods. From top to bottom: input\nsample Efros and Leung (EL) [19], Efros and Freeman (EF) [20], CNNMRF [53]\nand MSLG [70].",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 39,
            "languages": [
                "eng"
            ],
            "coordinates": [
                133.7689971923828,
                534.5309448242188,
                477.5384216308594,
                568.4035034179688
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "b6d99d292b3eb4842bfe3d3a4f35f068",
        "text": "39",
        "type": "Title",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 39,
            "languages": [
                "eng"
            ],
            "coordinates": [
                300.64300537109375,
                694.8489379882812,
                310.6055908203125,
                704.8115234375
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "8e03df872469d4b40cd18772d1ae6429",
        "text": "there is no theoretical proof of the convergence of the method. On the other\nhand, the RPN method yields a simple and elegant theory with no convergence\nissue. The visual results yield by both methods are in general satisfying for mi-\ncrotextures. However, for textures with local structures, the results are blurry\nand unsatisfying. Among these three methods, the results obtained by Portilla\nand Simoncelli are by far the most remarkable. These results contain recogniz-\nable conﬁgurations from the sample. This can be observed for the last texture\nexample in Figure 20 and the ﬁrst two examples in Figure 22. Notice that the\nHeeger and Bergen and RPN methods yield unsatisfying results for these three\nexamples.\nClearly the global statistics considered by these methods are not\nenough to characterize these highly structured textures.\nThe second and third rows of the Figures 21 and 23 correspond to the\npatch re-arrangement methods Efros-Leung (1999) and Efros-Freeman (2001)\ndescribed in Sections 3. The ﬁrst three textures in Figure 21 have no conspic-\nuous structures but are not stationary (for example, there are small changes of\nillumination). The Efros and Leung method, being too local, fails to recover\nthe global characteristics of these textures. A similar and attenuated behavior\nis observed in Efros-Freeman’s results.\nThe methods are signiﬁcantly better\nthan their predecessors in the presence of local structure, but have their speciﬁc\nproblems. Efros and Leung’s results for the third and fourth texture in Fig-\nure 21 show two clear examples of garbage growing. The method has repeated\na very small part of the input in an inconsistent way creating “garbage”. In\ngeneral this phenomenon is more evident in Efros and Leung’s results, compared\nto those of Efros and Freeman. The results of Efros-Leung and Efros-Freeman\nfor the ﬁrst texture in Figure 23 show that the global organization is sometimes\nmissed, mostly due to the fact that these methods work at a single scale. The\nsecond texture example in Figure 23 yields impressive results in the case of Efros-\nFreeman’s method. Nevertheless, looking carefully one can notice the verbatim\ncopies of the piece of chalks in the input image. The hybrid method MSLG\n(2016) described in Section 4, whose results are on the ﬁfth row of Figures 21\nand 23, faces the same issues for the three ﬁrst examples in Figure 21. This is\nless visible though, since the Gaussian models tend to smooth slightly the result.\nHowever, the original granularity of the input sample is lost in MSLG. As men-\ntioned in Section 3, Efros and Leung’s and Efros and Freeman’s results depend\non the patch size, while the multiscale approach (MSLG) is more robust to that\nparameter. When the former two methods fail to preserve global organization,\nMSLG, working at multiple scales, manages to preserve this organization. In\nthe second texture example in Figure 23, MSLG avoids the verbatim copy since\nthe patches are being sampled from their Gaussian model and therefore are dif-\nferent from their original patches. Nevertheless, the Gaussian model strongly\nsmooths the output. The synthesis of the ﬂower texture (Figure 23 third row)\nis very satisfying for the three methods. Finally, the pumpkin texture shows a\nclear example of the verbatim copy eﬀect in the Efros-Leung and Efros-Freeman\nmethods. The fourth row of the Figures 21 and 23 corresponds to the CNN patch\nre-arrangement method CNNMRF (2016) described in Section 3. By bringing\nthe patch re-arrangement to CNN features, the blending between the patches",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 40,
            "languages": [
                "eng"
            ],
            "coordinates": [
                133.76800537109375,
                126.97892761230469,
                477.55743408203125,
                674.9234619140625
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "5dbfa99f1fbc703c43b8f4a61d60be6d",
        "text": "40",
        "type": "Title",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 40,
            "languages": [
                "eng"
            ],
            "coordinates": [
                300.64300537109375,
                694.8488159179688,
                310.6055908203125,
                704.8114013671875
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "94bf19699c022229b907838f6e02ef5f",
        "text": "is improved. For example on the fourth texture of Figure 23, the separation\nbetween the patches are visible on the results of Efros-Freeman, which is not\nthe case for CNNMRF. However CNNMRF suﬀers particularly from verbatim\ncopies and fails to recover the global statistics of the image. Efros-Leung and\nEfros-Freeman do suﬀer less from these problems because the patch selection\nstep for these methods picks randomly among a selection of patches, whereas\nCNNMRF takes the most likely patch.\nThe recent statistics-based CNN methods, discussed in Section 2.5, show sig-\nniﬁcant improvement over their predecessors. Gatys (2015) is the best statistics-\nbased method at respecting the ﬁne details for all the textures of Figures 20\nand 22, which can be well noticed with a zoom-in.\nHowever, some low fre-\nquencies or structure organizations are missed, as seen on the fourth texture of\nFigure 20, and some contrast instabilities can be noticed, for example on the\nﬁrst texture of Figure 22. As discussed in Section 2.5, some variants were pro-\nposed to ﬁx these problems. SGAN (2016), on the other hand, better respects\nthe low frequencies, and the results often look better than Gatys when zoomed-\nout. However on the ﬁne scale, the results are incomplete and noisy, as seen on\nall the textures of the Figures 20 and 22. SGAN fails to generate correctly the\nﬁrst texture of Figure 20, possibly because this texture has no structure and is\na microtexture. It is likely that better results can be obtained by tuning the\nparameters, but as said in Section 2.5, the default parameters were used.\nAmong all these methods, the CNN based methods are the most expensive in\ncomputational time. Pixel based methods, like Efros-Leung, are more expensive\nthan patch based methods like Efros-Freeman or MSLG. The speed of statistics-\nbased methods depends on how global the optimization is, and on the number\nof iterations needed. Portilla-Simoncelli’s and Heeger-Bergen’s speeds are com-\nparable to patch based methods, while Random Phase Noise is the cheapest of\nthe methods reviewed here.\nThese comparative evaluations show the strengths and weaknesses of the\ndiﬀerent original methods described in this survey. As said previously, some\nvariants of these methods can get better results on some pictures. For example,\na better result for the fourth texture of the Figure 20 can be seen on Figure 19.\nFor this texture, ﬁrst generating with MSLG, then reﬁning with Gatys’ texture\ngenerator, enables to combine the best of both algorithms: The fabric elements\nare well aligned, and look good at a ﬁne scale.\nOverall, over the last three\ndecades, tremendous progress was made to generate convincing new texture\nsamples from a small and stationary texture sample. However one could argue\nthat the samples used in this comparison are toy examples. Indeed, except for\nthe third texture of Figure 20, and fourth texture of Figure 22, the samples\ndo not suﬀer much of illumination changes or perspective, and are essentially\nstationary. Nevertheless, most textures are not stationary. Think for example\nof a wood texture. This leads us to wonder whether the presented algorithms\nget acceptable results on these complex scenarios.",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 41,
            "languages": [
                "eng"
            ],
            "coordinates": [
                133.76800537109375,
                126.97892761230469,
                477.54754638671875,
                639.0584106445312
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "8896242d848bd9f48b9c889d0cf70f96",
        "text": "41",
        "type": "Title",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 41,
            "languages": [
                "eng"
            ],
            "coordinates": [
                300.64300537109375,
                694.8488159179688,
                310.6055908203125,
                704.8114013671875
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "982d77f66239c966fe0f548a761c68fb",
        "text": "crop 1\ncrop 2",
        "type": "Title",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 42,
            "languages": [
                "eng"
            ],
            "coordinates": [
                264.50299072265625,
                250.2114715576172,
                452.4479064941406,
                259.1778564453125
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "6431bc16d54060739bdc5fcb31cf70b5",
        "text": "Figure 24: Two crops of diﬀerent parts of a larger wood texture. The cropped\nimages are of size 500 × 500 pixels.\nEach one represents a diﬀerent texture\nbelonging to a single “big texture”.",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 42,
            "languages": [
                "eng"
            ],
            "coordinates": [
                133.76800537109375,
                272.82891845703125,
                477.517578125,
                306.70147705078125
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "060d37ff0bde1b49ed0ca26c8fa4a933",
        "text": "5.2\nGetting out of toy examples",
        "type": "Title",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 42,
            "languages": [
                "eng"
            ],
            "coordinates": [
                133.76800537109375,
                328.6556091308594,
                330.0963134765625,
                340.6108093261719
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "ab841a6de036afbfebdb2ac705567752",
        "text": "The previous examples present some quite impressive texture synthesis results\nby several algorithms. The texture synthesis problem seems to be almost solved\nfor “academic” textures. Still, those results were obtained for pictures of rel-\natively small size and taken in almost ideal conditions, in order to get almost\nstationary textures. In this section, we discuss the situation for more complex\ntextures: When the same methods are applied to sample images of real and\nnon-stationary textures, where long-range structure is present as well as vary-\ning detail at every scale. Figures 24 and 25 show some realistic examples of real\nworld images that nobody would hesitate calling textures. Nevertheless on sec-\nond thoughts they do have a complex, non-stationary structures, because every\nlarge enough image has it. But these are precisely the examples that need being\nemulated! In this endeavor, we can relax the requirement that the synthesis\nmust make a larger image. Let’s just ask if a method is able to reproduce a\nperceptually similar texture at the very same size.\nEach of textures in Figures 24 and 25 show diﬀerent salient sub-textures\nwithin the same image. Since the methods in Section 5.1 usually assume that\nthe texture is stationary, it is not completely fair to use these methods on\nthese samples. Several works have investigated ways to handle these complex\ncases [74, 4, 44, 56]. In this section we show the results of the state of the art\nalgorithms presented in this paper, and will show that they are still far from\nemulating to real world textures, even without the requirement of building a\nlarger texture patch from the sample.\nFigures 26 and 27 show the results of the presented statistics-based, patch re-\narrangement and hybrid methods on some of these more complex examples. The\nbest results are Gatys’ texture generator on the second texture and MSLG+PS\nand MSLG+Gatys on the ﬁrst texture and fourth texture.\nWhen applying\nRPN or PS to them the results obtained are often too blurry. Gatys’ texture",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 42,
            "languages": [
                "eng"
            ],
            "coordinates": [
                133.76800537109375,
                348.6029052734375,
                477.56744384765625,
                669.3992919921875
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "d93ff3f6eda3587b129812104b6992a7",
        "text": "42",
        "type": "Title",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 42,
            "languages": [
                "eng"
            ],
            "coordinates": [
                300.64300537109375,
                694.8486938476562,
                310.6055908203125,
                704.811279296875
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "c57e11a7c4a6f5c435f298e565e1d14a",
        "text": "crop 1\ncrop 2",
        "type": "Title",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 43,
            "languages": [
                "eng"
            ],
            "coordinates": [
                264.50299072265625,
                250.21446228027344,
                452.4479064941406,
                259.18084716796875
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "a083b2824436b0a880e9b719fe64e8c4",
        "text": "Figure 25: Two crops of diﬀerent parts of a larger stone texture. The cropped\nimages are of size 512 × 512 pixels.\nEach one represents a diﬀerent texture\nbelonging to a single “big texture”.",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 43,
            "languages": [
                "eng"
            ],
            "coordinates": [
                133.76800537109375,
                272.8309326171875,
                477.5076599121094,
                306.7044982910156
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "e76037ab87074a02f774062414ec2ff1",
        "text": "generator fails to catch the low frequency structures for the last two textures.\nEF, CNNMRF and MSLG suﬀer from garbage growing and verbatim copies on\nthe ﬁrst three textures. This is true especially when the input is not stationary.\nSGAN fails to generate properly on the ﬁrst two textures, and while the global\norganization of the third and fourth pictures is good, it suﬀers from the noise at\nsmall scale mentioned previously. As noticed in the previous section, the MSLG\nresults are slightly blurry.\nThese results show that while some methods can get good results on some of\nthese challenging texture samples, no method manages to get satisfying results\nfor all four textures.",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 43,
            "languages": [
                "eng"
            ],
            "coordinates": [
                133.76800537109375,
                330.2159118652344,
                477.5375061035156,
                447.775390625
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "c671289df7189ec2103197971251023a",
        "text": "6\nConclusion",
        "type": "Title",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 43,
            "languages": [
                "eng"
            ],
            "coordinates": [
                133.76800537109375,
                467.3318786621094,
                235.22430419921875,
                481.6780700683594
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "ac33eb94f9eb04e0f3bbe0e775de52c7",
        "text": "With the multiplication of applications in computer graphics to the entertain-\nment industry, the interest in the generation of synthetic objects with realistic\ntexture has grown rapidly.\nHigh budget ﬁlm sets, computer games, and in\nsome cases digital art, spend intensive human eﬀorts to imitate the appearance\nand feel of real world items. For this reason, exemplar-based texture synthesis\nhas been the focus of intensive work for three decades. And as the available\ncomputational power increased, so has the sophistication of these methods.\nIn the end of the last millennium, statistics-based methods, such as RPN,\nHeeger-Bergen and Portilla-Simoncelli focused on a reduced set of statistics. The\nresults were quite satisfactory on micro-textures, but could be blurry and far\nfrom the originals for more complex structures. Patch re-arrangement methods,\nsuch as Efros-Leung and Efros-Freeman, managed to respect signiﬁcantly bet-\nter the feel and the low level structures of these textures, but could have issues,\nsuch as discontinuities, verbatim copy, garbage growing or simply not respecting\nsome essential statistics of the textures, such as the average intensity. Hybrid",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 43,
            "languages": [
                "eng"
            ],
            "coordinates": [
                133.76800537109375,
                492.57879638671875,
                477.53753662109375,
                669.9143676757812
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "a573748c27c70fd1bd7c46d170aead22",
        "text": "43",
        "type": "Title",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 43,
            "languages": [
                "eng"
            ],
            "coordinates": [
                300.64300537109375,
                694.8488159179688,
                310.6055908203125,
                704.8114013671875
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "89df831d9f55722fd08618f6aa6df071",
        "text": "input",
        "type": "Title",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 44,
            "languages": [
                "eng"
            ],
            "coordinates": [
                177.77000427246094,
                150.3069305419922,
                201.0326690673828,
                160.26953125
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "00c3977aaa88e27ccdb0936be7778370",
        "text": "RPN [23]",
        "type": "Title",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 44,
            "languages": [
                "eng"
            ],
            "coordinates": [
                160.61199951171875,
                221.87193298339844,
                201.0203094482422,
                231.83453369140625
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "e1f97c8c5e0b392110223c21321b781d",
        "text": "PS [69]",
        "type": "Title",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 44,
            "languages": [
                "eng"
            ],
            "coordinates": [
                169.88299560546875,
                293.3039245605469,
                201.0260772705078,
                303.2665100097656
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "745ad1ba7635719ff06448f9af7cd6e8",
        "text": "Gatys [27]",
        "type": "Title",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 44,
            "languages": [
                "eng"
            ],
            "coordinates": [
                156.61300659179688,
                364.7359313964844,
                201.0262908935547,
                374.6985168457031
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "9fd520c97c38dbb3cd2086d338ab2731",
        "text": "SGAN [36]",
        "type": "Title",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 44,
            "languages": [
                "eng"
            ],
            "coordinates": [
                153.9010009765625,
                436.1679382324219,
                201.02410888671875,
                446.1305236816406
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "8f323f699dd2e352c879812a4921b281",
        "text": "EF [20]",
        "type": "Title",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 44,
            "languages": [
                "eng"
            ],
            "coordinates": [
                168.91400146484375,
                507.60089111328125,
                201.02346801757812,
                517.5634765625
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "7c5aa18253f375b96e170c02cdd30a71",
        "text": "CNNMRF [53]",
        "type": "Title",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 44,
            "languages": [
                "eng"
            ],
            "coordinates": [
                137.0889892578125,
                579.0328979492188,
                201.01901245117188,
                588.9954833984375
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "58745538c100aeb7b19720e782e042ce",
        "text": "Figure 26:\nSynthesis results for statistical based and patch re-arrangement\nmethods on complex texture.\nThey show the current limitations of all best\nmethods. RPN scrambles the textures. PS loses long range coherence of the\nwood veins. EF and CNNMRF’s copy paste is quite visible for all textures and\nincurs in garbage growing. PS and Gatys have satisfying results on the left hand\ntwo textures, but miss to emulate long range interactions on the wood textures.\nSGAN grows periodic noise patterns. 44",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 44,
            "languages": [
                "eng"
            ],
            "coordinates": [
                133.7689971923828,
                625.8029174804688,
                477.54852294921875,
                707.4965209960938
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "cbee0ac9ce960b951f2ad1650d0eede8",
        "text": "input",
        "type": "Title",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 45,
            "languages": [
                "eng"
            ],
            "coordinates": [
                175.88800048828125,
                209.63694763183594,
                199.15066528320312,
                219.59954833984375
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "022da42517c025728bb3cfe449564db7",
        "text": "MSLG",
        "type": "Title",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 45,
            "languages": [
                "eng"
            ],
            "coordinates": [
                170.4219970703125,
                282.1159362792969,
                199.14418029785156,
                292.0785217285156
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "c67a25d6af6ab640f44c4363a38be40b",
        "text": "MSLG+EF",
        "type": "Title",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 45,
            "languages": [
                "eng"
            ],
            "coordinates": [
                149.38998413085938,
                353.1329345703125,
                199.15318298339844,
                363.09552001953125
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "5fae416261de07c9d79e7494e945e8b6",
        "text": "MSLG+PS",
        "type": "Title",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 45,
            "languages": [
                "eng"
            ],
            "coordinates": [
                150.35899353027344,
                424.56494140625,
                199.1558074951172,
                434.52752685546875
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "bac1f40b42c70844c69b3ad49c9f3d51",
        "text": "MSLG+Gatys",
        "type": "Title",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 45,
            "languages": [
                "eng"
            ],
            "coordinates": [
                137.0889892578125,
                495.4439392089844,
                199.1460418701172,
                505.4065246582031
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "3d34a902133ab1d7c4877ab6fb75d42b",
        "text": "Figure 27: Synthesis results for the hybrid methods. In columns 2) and 3),\nMSLG has repetitions and garbage growing; thus all the generated results based\non the MSLG outputs keep this defect. In columns 1) and 4), MSLG respects\nwell the global statistics of the textures, and the combination with other meth-\nods indeed improves the result. MSLG+PS and MSLG+Gatys perform better\non these examples than MSLG+EF.",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 45,
            "languages": [
                "eng"
            ],
            "coordinates": [
                133.76800537109375,
                542.2679443359375,
                477.53765869140625,
                612.0065307617188
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "09e432249d8290994d2daac7438859b4",
        "text": "45",
        "type": "Title",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 45,
            "languages": [
                "eng"
            ],
            "coordinates": [
                300.64300537109375,
                694.8489379882812,
                310.6055908203125,
                704.8115234375
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "03a559b87a5c3e4152d29fa6baf25e89",
        "text": "methods, such as MSLG, ﬁx some of the issues of patch re-arrangement meth-\nods, but still share some of their issues. Very recently, statistics-based methods\nhave been revisited with Convolutional Neural Networks (CNNs). CNN based\nmethods signiﬁcantly increase the number of texture statistics involved in their\nmodel, for example by a factor of 25 approximately in the case of Gatys’ tex-\nture generator compared to Portilla-Simoncelli. The results show a spectacu-\nlar progress over their predecessors, but no method is perfect yet. Patch re-\narrangement methods were revisited as well by CNNs. CNNMRF improves the\nblending between the image patches, but the results still suﬀer from the prob-\nlems mentioned above for patch re-arrangement methods. In this review, we\npresented three statistics-based neural methods with diﬀerent models: Gatys’\ntexture generator, DeepFrame and SGAN. When zoomed-in, the outputs of\nGatys’ texture generator are the best among the statistics-based methods, but\nmiss some important low frequency constraints of the texture when zoomed-out.\nSome variants aim at ﬁxing this shortcoming. SGAN succeeds better on several\nexamples to respect the global structure of the texture, but the details of the\ntexture are poor. While all the other statistics-based methods have an explicit\ntexture model, the SGAN model is more implicit.\nOur experimental results look no doubt sometimes worse than in the original\npapers, but precisely we did not select the best examples. Our examination of\nthe history of the method leads to the following conclusions.\n- The exemplar-based texture synthesis problem is implicitly ill-posed, as it re-\nquires to extrapolate a Fourier spectrum by enlarging the image given a very\nsmall sample of it. Having very small samples may have been historically in-\nteresting in computer graphics, but is no longer a technical issue, given the\navailable memories and computational power in all computers.\n- By working on small texture examples the literature has somehow unrealisti-\ncally restricted the problem. Indeed it is simply not true that textures are as\nstationary as those examples suggest.\n- When trying to work on larger examples, we have seen that no texture sample\nis really stationary. A realistically large texture sample in fact contains smaller\npatches of very diﬀerent textures.\n- This explains ﬁrst why patch based copy-paste methods are doomed in spite\nof some apparent success in some quasi-periodic texture with no conspicuous\ndetail. On more involved samples, they cannot but reproduce recognizable de-\ntails.\n- This also explains why progress in this topic is linked to the design of methods\nenforcing more and more statistical parameters. The number of statistics en-\nforced by statistical models is growing fast: 710 for Portilla-Simoncelli, 176640\nfor the default model in Gatys’ texture generator. With some results showing\nthat the ﬁlters can be chosen with random weights [85], one can wonder if the\nsolution is not to just use the highest number of statistics possible to emulate a\ntexture. One may also wonder where to draw a reasonable limit between syn-\nthesizing complex textures and rendering scenes containing textured objects.\n- Thus, the Portilla-Simoncelli method, of enforcing a high number of statistics,\nwins, but it is somewhat a Pyrrhic victory. Indeed, the more random statis-",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 46,
            "languages": [
                "eng"
            ],
            "coordinates": [
                133.76800537109375,
                126.97892761230469,
                477.5274963378906,
                674.9234619140625
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "2a2819b4814e25cb9666f21204b03edd",
        "text": "46",
        "type": "Title",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 46,
            "languages": [
                "eng"
            ],
            "coordinates": [
                300.64300537109375,
                694.8488159179688,
                310.6055908203125,
                704.8114013671875
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "a8dc921289e36f5f4f335542d5ce8e65",
        "text": "tics we pile up, the better the exemplar-based results. But it remains to ﬁnd\nnumerical tools applying automatically an Occam’s razor as Portilla and Simon-\ncelli did manually. This is still needed to realize the goal of Julesz’ program,\nwhich was to ﬁnd the minimal suﬃcient set of statistics rendering two textures\nindistinguishable.",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 47,
            "languages": [
                "eng"
            ],
            "coordinates": [
                133.76800537109375,
                126.97892761230469,
                477.5273742675781,
                184.7615966796875
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "69d9f7e1ed2e83dc2010028f5cc7cb83",
        "text": "Acknowledgements",
        "type": "Title",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 47,
            "languages": [
                "eng"
            ],
            "coordinates": [
                133.76800537109375,
                204.03109741210938,
                267.7041320800781,
                218.37728881835938
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "9c6eda107a1c5cb7b3236a17ae34e7cf",
        "text": "We thank Rafael Grompone von Gioi for valuable corrections and suggestions,\nArthur Leclaire and Yang Lu for their feedback and for helping produce some\nof the experiments, and the anonymous referees for valuable advice.",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 47,
            "languages": [
                "eng"
            ],
            "coordinates": [
                133.76800537109375,
                229.2779998779297,
                477.5475158691406,
                263.151611328125
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "e06b98fa6b9afd373c01106d7154c9d9",
        "text": "References",
        "type": "Title",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 47,
            "languages": [
                "eng"
            ],
            "coordinates": [
                133.76800537109375,
                282.42108154296875,
                209.2864227294922,
                296.76727294921875
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "20a9eb97d75f1debb79cfda44a53201f",
        "text": "[1] Cecilia Aguerrebere, Yann Gousseau, and Guillaume Tartavel. Exemplar-\nbased texture synthesis: the Efros-Leung algorithm. Image Processing On\nLine, 2013:213–231, 2013.",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 47,
            "languages": [
                "eng"
            ],
            "coordinates": [
                138.75,
                307.66802978515625,
                477.5182800292969,
                341.54058837890625
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "ac933847d1b0fb39fc083fd65765c602",
        "text": "[2] Miika Aittala, Timo Aila, and Jaakko Lehtinen. Reﬂectance modeling by\nneural texture synthesis. ACM Transactions on Graphics, 35(4), 2016.",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 47,
            "languages": [
                "eng"
            ],
            "coordinates": [
                138.75001525878906,
                350.8349914550781,
                477.5282897949219,
                372.7525634765625
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "ee3729a933ef8097bc7a928935f9688a",
        "text": "[3] Michael Ashikhmin. Synthesizing natural textures. In Proceedings of the\n2001 symposium on Interactive 3D graphics, pages 217–226. ACM, 2001.",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 47,
            "languages": [
                "eng"
            ],
            "coordinates": [
                138.75,
                382.0469665527344,
                477.48162841796875,
                403.96453857421875
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "08f008dc801344c5271ddda005f0beb2",
        "text": "[4] Abdourrahmane M. Atto, Zhangyun Tan, Olivier Alata, and Maxime More-\naud.\nNon-stationary texture synthesis from random ﬁeld modeling.\nIn\nImage Processing (ICIP), 2014 IEEE International Conference on, pages\n4266–4270. IEEE, 2014.",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 47,
            "languages": [
                "eng"
            ],
            "coordinates": [
                138.74998474121094,
                413.2589416503906,
                477.5480651855469,
                459.0874938964844
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "3e5af4e5685fcf0ea7df02e3d9093533",
        "text": "[5] James R. Bergen and Edward H. Adelson. Visual texture segmentation\nbased on energy measures (a). Journal of the Optical Society of America\nA, 3, 1986.",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 47,
            "languages": [
                "eng"
            ],
            "coordinates": [
                138.74998474121094,
                468.38189697265625,
                477.49835205078125,
                502.25445556640625
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "1dd10a4d366daefe3a3d28ff688757da",
        "text": "[6] Guillaume Berger and Roland Memisevic. Incorporating long-range consis-\ntency in cnn-based texture generation. In Proceedings of the International\nConference on Learning Representations (ICLR), 2017.",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 47,
            "languages": [
                "eng"
            ],
            "coordinates": [
                138.75,
                511.54888916015625,
                477.5082702636719,
                545.4214477539062
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "d358b36529c42b4a4854b126c72ff706",
        "text": "[7] Urs Bergmann, Nikolay Jetchev, and Roland Vollgraf. Learning texture\nmanifolds with the periodic spatial gan. arXiv preprint arXiv:1705.06566,\n2017.",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 47,
            "languages": [
                "eng"
            ],
            "coordinates": [
                138.75003051757812,
                554.7158813476562,
                477.52825927734375,
                588.5894165039062
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "33dd1e6c6c0f9b9e7474c74f050ac134",
        "text": "[8] Charles Bordenave, Yann Gousseau, and Fran¸cois Roueﬀ. The dead leaves\nmodel: a general tessellation modeling occlusion.\nAdvances in Applied\nProbability, pages 31–46, 2006.",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 47,
            "languages": [
                "eng"
            ],
            "coordinates": [
                138.7500457763672,
                597.8838500976562,
                477.4984436035156,
                631.7564697265625
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "06736c78f2d67c239faa223d8c722631",
        "text": "[9] Thibaud Briand, Jonathan Vacher, Bruno Galerne, and Julien Rabin. The\nHeeger & Bergen pyramid based texture synthesis algorithm. Image Pro-\ncessing On Line, 4:276–299, 2014.",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 47,
            "languages": [
                "eng"
            ],
            "coordinates": [
                138.75006103515625,
                641.0508422851562,
                477.5681457519531,
                674.9234619140625
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "a9a4dccc40a5d18f4fc747c75cd2e1e7",
        "text": "47",
        "type": "Title",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 47,
            "languages": [
                "eng"
            ],
            "coordinates": [
                300.6430358886719,
                694.848876953125,
                310.6056213378906,
                704.8114624023438
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "727f0cb6f321e81a451106b0490a19e9",
        "text": "[10] Antoni Buades, Marc Lebrun, and Jean-Michel Morel. Implementation of\nthe “Non-Local Bayes” (NL-Bayes) Image Denoising Algorithm.\nImage\nProcessing On Line, 2013:1–42, 2013.",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 48,
            "languages": [
                "eng"
            ],
            "coordinates": [
                133.76800537109375,
                126.97892761230469,
                477.5275573730469,
                160.8515625
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "4e33b9993fadf2f84650662ab9948c37",
        "text": "[11] Terry Caelli and B´ela Julesz. Experiments in the visual perception of tex-\nture. Biol. Cybernetics, 28:167–175, 1978.",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 48,
            "languages": [
                "eng"
            ],
            "coordinates": [
                133.76800537109375,
                170.81394958496094,
                477.5076599121094,
                192.7315673828125
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "d53bc247336017f424a43433613e7d51",
        "text": "[12] Tianhorng Chang and C. C. Jay Kuo. Texture analysis and classiﬁcation\nwith tree-structured wavelet transform. IEEE Transactions on Image Pro-\ncessing, 2(4):429–441, 1993.",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 48,
            "languages": [
                "eng"
            ],
            "coordinates": [
                133.7680206298828,
                202.6949920654297,
                477.52740478515625,
                236.567626953125
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "a0996908d1e786088704600114c90601",
        "text": "[13] Kostadin Dabov, Alessandro Foi, Vladimir Katkovnik, and Karen Egiazar-\nian. Image denoising by sparse 3-D transform-domain collaborative ﬁlter-\ning. Image Processing, IEEE Transactions on, 16(8):2080–2095, 2007.",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 48,
            "languages": [
                "eng"
            ],
            "coordinates": [
                133.76803588867188,
                246.53001403808594,
                477.5473327636719,
                280.40362548828125
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "ab5b0424aefc06ce92df4d702f0b51e8",
        "text": "[14] Jeremy S. De Bonet. Multiresolution sampling procedure for analysis and\nsynthesis of texture images. In Proceedings of the 24th annual conference\non Computer graphics and interactive techniques, pages 361–368. ACM\nPress/Addison-Wesley Publishing Co., 1997.",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 48,
            "languages": [
                "eng"
            ],
            "coordinates": [
                133.76805114746094,
                290.36602783203125,
                477.5275573730469,
                336.194580078125
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "68398d213fcde010870cb0c2682c22c9",
        "text": "[15] Jia Deng, Wei Dong, Richard Socher, Li-Jia Li, Kai Li, and Li Fei-Fei.\nImagenet: A large-scale hierarchical image database. In Computer Vision\nand Pattern Recognition, 2009. CVPR 2009. IEEE Conference on, pages\n248–255. IEEE, 2009.",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 48,
            "languages": [
                "eng"
            ],
            "coordinates": [
                133.76805114746094,
                346.156982421875,
                477.5274963378906,
                391.9845275878906
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "b113fef3a3a8e6002616831a5102156d",
        "text": "[16] Emily L Denton, Soumith Chintala, Rob Fergus, et al. Deep generative im-\nage models using a laplacian pyramid of adversarial networks. In Advances\nin neural information processing systems, pages 1486–1494, 2015.",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 48,
            "languages": [
                "eng"
            ],
            "coordinates": [
                133.76803588867188,
                401.94793701171875,
                477.52752685546875,
                435.82049560546875
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "5b3df6cb39a37403f7263d0b609a8c39",
        "text": "[17] Agn`es Desolneux, Lionel Moisan, and Samuel Ronsin. A compact represen-\ntation of random phase and Gaussian textures. In 2012 IEEE International\nConference on Acoustics, Speech and Signal Processing (ICASSP). IEEE,\n2012.",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 48,
            "languages": [
                "eng"
            ],
            "coordinates": [
                133.7680206298828,
                445.78289794921875,
                477.4976806640625,
                491.6114501953125
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "33007a941e064dda52c77a1e452fa066",
        "text": "[18] Alexey Dosovitskiy and Thomas Brox. Generating images with perceptual\nsimilarity metrics based on deep networks. In Advances in Neural Infor-\nmation Processing Systems, pages 658–666, 2016.",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 48,
            "languages": [
                "eng"
            ],
            "coordinates": [
                133.76803588867188,
                501.5738525390625,
                477.50762939453125,
                535.4464111328125
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "7848b93f94587f4b8cf028bb16cae04b",
        "text": "[19] Alexei Efros, Thomas K. Leung, et al. Texture synthesis by non-parametric\nsampling. In Computer Vision, 1999. The Proceedings of the Seventh IEEE\nInternational Conference on, volume 2, pages 1033–1038. IEEE, 1999.",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 48,
            "languages": [
                "eng"
            ],
            "coordinates": [
                133.7680206298828,
                545.4098510742188,
                477.5075378417969,
                579.2824096679688
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "39efcd783958ac72580167e9a571c513",
        "text": "[20] Alexei A. Efros and William T. Freeman. Image quilting for texture synthe-\nsis and transfer. In Proceedings of the 28th annual conference on Computer\ngraphics and interactive techniques, pages 341–346. ACM, 2001.",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 48,
            "languages": [
                "eng"
            ],
            "coordinates": [
                133.7680206298828,
                589.2448120117188,
                477.527587890625,
                623.118408203125
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "30b1bf59b1436b82d8346dd7984c221c",
        "text": "[21] William T. Freeman and Edward H. Adelson. The design and use of steer-\nable ﬁlters. IEEE Transactions on Pattern analysis and machine intelli-\ngence, 13(9):891–906, 1991.",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 48,
            "languages": [
                "eng"
            ],
            "coordinates": [
                133.76803588867188,
                633.080810546875,
                477.5075378417969,
                666.9534301757812
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "3124436babc3f41f64167eda2add69bc",
        "text": "48",
        "type": "Title",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 48,
            "languages": [
                "eng"
            ],
            "coordinates": [
                300.64202880859375,
                694.8488159179688,
                310.6046142578125,
                704.8114013671875
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "380083a6bb0356f2619a83305d0f36a6",
        "text": "[22] Bruno Galerne, Yann Gousseau, and Jean-Michel Morel.\nMicro-texture\nsynthesis by phase randomization. Image Processing On Line, 2011, 2011.",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 49,
            "languages": [
                "eng"
            ],
            "coordinates": [
                133.76800537109375,
                126.97892761230469,
                477.5274963378906,
                148.89654541015625
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "fd2f9bd2e823b65b279376aa9c229563",
        "text": "[23] Bruno Galerne, Yann Gousseau, and Jean-Michel Morel. Random phase\ntextures: Theory and synthesis. Image Processing, IEEE Transactions on,\n20(1):257–267, 2011.",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 49,
            "languages": [
                "eng"
            ],
            "coordinates": [
                133.76800537109375,
                157.8629608154297,
                477.527587890625,
                191.735595703125
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "2bc1fd1246e505d573f8d79be98d389c",
        "text": "[24] Bruno Galerne and Arthur Leclaire. An Algorithm for Gaussian Texture\nInpainting. submitted to Image Processing Online, (7):1–16, 2017. https:\n//doi.org/10.5201/ipol.2017.198.",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 49,
            "languages": [
                "eng"
            ],
            "coordinates": [
                133.76803588867188,
                200.70201110839844,
                477.5374450683594,
                235.05421447753906
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "4ef414ede60e873813fff06195fc5218",
        "text": "[25] Bruno Galerne and Arthur Leclaire.\nTexture Inpainting using Eﬃcient\nGaussian Conditional Simulation.\nSIAM Journal on Imaging Sciences,\n10:1446–1474, 2017. https://doi.org/10.1137/16M1109047.",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 49,
            "languages": [
                "eng"
            ],
            "coordinates": [
                133.76806640625,
                243.5420379638672,
                477.53759765625,
                277.89324951171875
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "98c32fb26d07f6b6d4a3e0b7478376fe",
        "text": "[26] Bruno Galerne, Arthur Leclaire, and Lionel Moisan. Microtexture inpaint-\ning through Gaussian conditional simulation. In 2016 IEEE International\nConference on Acoustics, Speech and Signal Processing (ICASSP), pages\n1204–1208. IEEE, 2016.",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 49,
            "languages": [
                "eng"
            ],
            "coordinates": [
                133.76809692382812,
                286.381103515625,
                477.5474548339844,
                332.2086486816406
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "9c1dcd6468e1f6a845d5f799e0d8f52f",
        "text": "[27] Leon Gatys, Alexander S. Ecker, and Matthias Bethge. Texture synthesis\nusing convolutional neural networks. In Advances in Neural Information\nProcessing Systems, pages 262–270, 2015.",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 49,
            "languages": [
                "eng"
            ],
            "coordinates": [
                133.76806640625,
                341.1760559082031,
                477.5076904296875,
                375.0486145019531
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "18bca3bbe2e3db440f954bb5b187364c",
        "text": "[28] Leon Gatys, Alexander S. Ecker, and Matthias Bethge. Code to synthesise\ntextures using convolutional neural networks as described in gatys et al.\n2015. https://github.com/leongatys/DeepTextures, 2015–2016.",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 49,
            "languages": [
                "eng"
            ],
            "coordinates": [
                133.76806640625,
                384.0150146484375,
                477.513427734375,
                418.36614990234375
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "846d5cb93a96ce308322b781c546bba6",
        "text": "[29] Leon Gatys, Alexander S. Ecker, and Matthias Bethge. Image style transfer\nusing convolutional neural networks. In Proceedings of the IEEE Conference\non Computer Vision and Pattern Recognition, pages 2414–2423, 2016.",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 49,
            "languages": [
                "eng"
            ],
            "coordinates": [
                133.76809692382812,
                426.85400390625,
                477.50775146484375,
                460.7275695800781
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "526ce46c09096e61c0bfc74b2713e9cd",
        "text": "[30] Ian Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-\nFarley, Sherjil Ozair, Aaron Courville, and Yoshua Bengio.\nGenerative\nadversarial nets.\nIn Advances in neural information processing systems,\npages 2672–2680, 2014.",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 49,
            "languages": [
                "eng"
            ],
            "coordinates": [
                133.76808166503906,
                469.6939697265625,
                477.5474853515625,
                515.521484375
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "b3cb83de5bfc1c1d653cc1c3088bec5a",
        "text": "[31] Ulf Grenander. General Pattern Theory. Oxford University Press, 1993.",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 49,
            "languages": [
                "eng"
            ],
            "coordinates": [
                133.76809692382812,
                524.4879150390625,
                469.0218200683594,
                534.4505004882812
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "ce1cb8b8d52d780d37db459fe2168299",
        "text": "[32] Baining Guo, Harry Shum, and Ying-Qing Xu. Chaos mosaic: Fast and\nmemory eﬃcient texture synthesis.\nMicrosoft research paper MSR-TR-\n2000-32, 2000.",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 49,
            "languages": [
                "eng"
            ],
            "coordinates": [
                133.76808166503906,
                543.4169311523438,
                477.5474548339844,
                577.29052734375
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "2d7451d1e3ca7089375d0f9febcd71f4",
        "text": "[33] David J. Heeger and James R. Bergen.\nPyramid-based texture analy-\nsis/synthesis. In Proceedings of the 22nd annual conference on Computer\ngraphics and interactive techniques, pages 229–238. ACM, 1995.",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 49,
            "languages": [
                "eng"
            ],
            "coordinates": [
                133.76806640625,
                586.2568969726562,
                477.4976806640625,
                620.1295166015625
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "7ac8855ccb5ae305a9caea205ced5d03",
        "text": "[34] Aaron Hertzmann, Charles E. Jacobs, Nuria Oliver, Brian Curless, and\nDavid H. Salesin.\nImage analogies.\nIn Proceedings of the 28th annual\nconference on Computer graphics and interactive techniques, pages 327–\n340. ACM, 2001.",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 49,
            "languages": [
                "eng"
            ],
            "coordinates": [
                133.76806640625,
                629.0958862304688,
                477.5274963378906,
                674.9235229492188
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "158b30eeeb01d802d31d834cc75b2741",
        "text": "49",
        "type": "Title",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 49,
            "languages": [
                "eng"
            ],
            "coordinates": [
                300.64208984375,
                694.8489379882812,
                310.60467529296875,
                704.8115234375
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "b8bbbeaa8e6871dc4d2ad73bff5ec27e",
        "text": "[35] Daniel Jiwoong Im, Chris Dongjoo Kim, Hui Jiang, and Roland Memisevic.\nGenerating images with recurrent adversarial networks.\narXiv preprint\narXiv:1602.05110, 2016.",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 50,
            "languages": [
                "eng"
            ],
            "coordinates": [
                133.76800537109375,
                126.97892761230469,
                477.5274963378906,
                160.8515625
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "6015bdac46df1b13ee9ad21b4cfa3a32",
        "text": "[36] Nikolay Jetchev, Urs Bergmann, and Roland Vollgraf.\nTexture syn-\nthesis with spatial generative adversarial networks.\narXiv preprint\narXiv:1611.08207, 2016.",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 50,
            "languages": [
                "eng"
            ],
            "coordinates": [
                133.76800537109375,
                170.81394958496094,
                477.5175476074219,
                204.68756103515625
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "a5fa03377a93a6c290014a2ecd89f598",
        "text": "[37] Nikolay Jetchev, Urs Bergmann, and Roland Vollgraf. Spatial generative\nadversarial networks. https://github.com/zalandoresearch/spatial_\ngan, 2016–2017.",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 50,
            "languages": [
                "eng"
            ],
            "coordinates": [
                133.76800537109375,
                214.6499481201172,
                477.5374755859375,
                249.0011749267578
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "3c7a7b436c17683e1796b440f6f36b4e",
        "text": "[38] B´ela Julesz.\nVisual pattern discrimination.\nInformation Theory, IRE\nTransactions on, 8(2):84–92, 1962.",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 50,
            "languages": [
                "eng"
            ],
            "coordinates": [
                133.76800537109375,
                258.48602294921875,
                477.4898986816406,
                280.40362548828125
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "18866b7b49b4a0a10731fbbb4725f687",
        "text": "[39] B´ela Julesz. Textons, the elements of texture perception, and their inter-\nactions. Nature, 290(5802):91–97, 1981.",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 50,
            "languages": [
                "eng"
            ],
            "coordinates": [
                133.76800537109375,
                290.36602783203125,
                477.497802734375,
                312.2835998535156
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "58fa91ee4c76247c7e93b0c73e6ee6a0",
        "text": "[40] B´ela Julesz. A theory of preattentive texture discrimination based on ﬁrst-\norder statistics of textons. Biological cybernetics, 41(2):131–138, 1981.",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 50,
            "languages": [
                "eng"
            ],
            "coordinates": [
                133.76800537109375,
                322.2460021972656,
                477.50775146484375,
                344.1645812988281
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "df70226c2c61f541280cfb487dca377b",
        "text": "[41] B´ela Julesz. Dialogues on Perception. The MIT Press, 1995.",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 50,
            "languages": [
                "eng"
            ],
            "coordinates": [
                133.7679901123047,
                354.1269836425781,
                417.8915710449219,
                364.0895690917969
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "2c1b44d76011c7597c4da3a0c0760264",
        "text": "[42] B´ela Julesz, Edgar N. Gilbert, Larry A. Shepp, and Harry L. Frisch. In-\nability of humans to discriminate between visual textures that agree in\nsecond-order statistics—revisited. Perception, 2(4):391–405, 1973.",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 50,
            "languages": [
                "eng"
            ],
            "coordinates": [
                133.76800537109375,
                374.0519714355469,
                477.54742431640625,
                407.925537109375
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "b03fa64e3291bff7cbe41ed241a9e33a",
        "text": "[43] B´ela Julesz, Edgar N. Gilbert, and Jonathan D. Victor. Visual discrimina-\ntion of textures with identical third-order statistics. Biological Cybernetics,\n31(3):137–140, 1978.",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 50,
            "languages": [
                "eng"
            ],
            "coordinates": [
                133.7680206298828,
                417.887939453125,
                477.53753662109375,
                451.760498046875
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "e02e1484a245898e2678e2cf5deb7e37",
        "text": "[44] Alexandre Kaspar, Boris Neubert, Dani Lischinski, Mark Pauly, and Jo-\nhannes Kopf.\nSelf tuning texture optimization.\nIn Computer Graphics\nForum, volume 34, pages 349–359. Wiley Online Library, 2015.",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 50,
            "languages": [
                "eng"
            ],
            "coordinates": [
                133.76800537109375,
                461.722900390625,
                477.5374450683594,
                495.5964660644531
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "0ca0148a5d6f53c935eb871f166cac16",
        "text": "[45] Alex Krizhevsky, Ilya Sutskever, and Geoﬀrey E Hinton. Imagenet clas-\nsiﬁcation with deep convolutional neural networks. In Advances in neural\ninformation processing systems, pages 1097–1105, 2012.",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 50,
            "languages": [
                "eng"
            ],
            "coordinates": [
                133.7679901123047,
                505.55889892578125,
                477.5076904296875,
                539.4314575195312
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "181140a65b20c8655cd5b7fe4550384d",
        "text": "[46] Vivek Kwatra, Irfan Essa, Aaron Bobick, and Nipun Kwatra. Texture op-\ntimization for example-based synthesis. In ACM Transactions on Graphics\n(TOG), volume 24, pages 795–802. ACM, 2005.",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 50,
            "languages": [
                "eng"
            ],
            "coordinates": [
                133.7679901123047,
                549.3948364257812,
                477.5374755859375,
                583.2674560546875
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "9e18086b089b274698be00f2c6105a57",
        "text": "[47] Vivek Kwatra, Arno Sch¨odl, Irfan Essa, Greg Turk, and Aaron Bobick.\nGraphcut textures: image and video synthesis using graph cuts. In ACM\nTransactions on Graphics (ToG), volume 22, pages 277–286. ACM, 2003.",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 50,
            "languages": [
                "eng"
            ],
            "coordinates": [
                133.76800537109375,
                593.2298583984375,
                477.5473937988281,
                627.1034545898438
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "df509e6666150134676bc879562cfbf5",
        "text": "[48] Andrew Laine and Jian Fan. Texture classiﬁcation by wavelet packet signa-\ntures. IEEE Transactions on Pattern Analysis and Machine Intelligence,\n15(11):1186–1191, 1993.",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 50,
            "languages": [
                "eng"
            ],
            "coordinates": [
                133.76800537109375,
                637.0658569335938,
                477.5074768066406,
                670.9384765625
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "a2c4b98e5e94d3b9a5fd6e6355e1202a",
        "text": "50",
        "type": "Title",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 50,
            "languages": [
                "eng"
            ],
            "coordinates": [
                300.6419677734375,
                694.848876953125,
                310.60455322265625,
                704.8114624023438
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "5a88885088c1c21f8df0ec7ebfebf4db",
        "text": "[49] Marc Lebrun, Antoni Buades, and Jean-Michel Morel. A nonlocal Bayesian\nimage denoising algorithm. SIAM Journal on Imaging Sciences, 6(3):1665–\n1688, 2013.",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 51,
            "languages": [
                "eng"
            ],
            "coordinates": [
                133.76800537109375,
                126.97892761230469,
                477.5274353027344,
                160.8515625
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "5ccbdd73b4c14acd159a1eff117ee860",
        "text": "[50] Sylvain Lefebvre and Hugues Hoppe. Parallel controllable texture synthesis.\nACM Transactions on Graphics (TOG), 24(3):777–786, 2005.",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 51,
            "languages": [
                "eng"
            ],
            "coordinates": [
                133.76800537109375,
                170.81394958496094,
                477.5374450683594,
                192.7315673828125
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "b8dd48a5f751a0305ee1992e90e25afb",
        "text": "[51] Elizaveta Levina and Peter J. Bickel. Texture synthesis and nonparametric\nresampling of random ﬁelds. The Annals of Statistics, 34(4):1751–1773,\n2006.",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 51,
            "languages": [
                "eng"
            ],
            "coordinates": [
                133.76800537109375,
                202.6949920654297,
                477.517578125,
                236.567626953125
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "845985f4f861e0c2793cd222494fdda4",
        "text": "[52] Chuan Li and Michael Wand. Code for paper ”combining markov random\nﬁelds and convolutional neural networks for image synthesis”. https://\ngithub.com/chuanli11/CNNMRF, 2015–2016.",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 51,
            "languages": [
                "eng"
            ],
            "coordinates": [
                133.76797485351562,
                246.53001403808594,
                477.5473937988281,
                280.8822021484375
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "1d5d4d78f9eac1e48cc02fceb43bcf36",
        "text": "[53] Chuan Li and Michael Wand. Combining markov random ﬁelds and con-\nvolutional neural networks for image synthesis. In Proceedings of the IEEE\nConference on Computer Vision and Pattern Recognition, pages 2479–2486,\n2016.",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 51,
            "languages": [
                "eng"
            ],
            "coordinates": [
                133.76797485351562,
                290.36602783203125,
                477.54736328125,
                336.194580078125
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "aeb77934db73c7d9e9fe060745a4fa37",
        "text": "[54] Lin Liang, Ce Liu, Ying-Qing Xu, Baining Guo, and Heung-Yeung Shum.\nReal-time texture synthesis by patch-based sampling. ACM Transactions\non Graphics (ToG), 20(3):127–150, 2001.",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 51,
            "languages": [
                "eng"
            ],
            "coordinates": [
                133.76795959472656,
                346.156982421875,
                477.557373046875,
                380.029541015625
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "97dcc3f3a5aa93d9099eaa8864985873",
        "text": "[55] Gang Liu, Yann Gousseau, and Gui-Song Xia. Texture synthesis through\nconvolutional neural networks and spectrum constraints. In 23rd Interna-\ntional Conference on Pattern Recognition, ICPR 2016, Canc´un, Mexico,\nDecember 4-8, 2016, pages 3234–3239. IEEE, 2016.",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 51,
            "languages": [
                "eng"
            ],
            "coordinates": [
                133.76797485351562,
                389.991943359375,
                477.54736328125,
                435.82049560546875
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "063e53a86c90056dd0a229ed3f761259",
        "text": "[56] Yitzchak David Lockerman, Basile Sauvage, R´emi All`egre, Jean-Michel\nDischler, Julie Dorsey, and Holly E Rushmeier. Multi-scale label-map ex-\ntraction for texture synthesis. ACM Trans. Graph., 35(4):140–1, 2016.",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 51,
            "languages": [
                "eng"
            ],
            "coordinates": [
                133.76797485351562,
                445.78289794921875,
                477.50347900390625,
                479.6564636230469
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "d5455eb812b2cd1b8b9e23cb3e701cdf",
        "text": "[57] Yang Lu, Song-Chun Zhu, and Ying Nian Wu.\nCode for Learning\nFRAME Models Using CNN Filters. http://www.stat.ucla.edu/~yang.\nlu/project/deepFrame/main.html.",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 51,
            "languages": [
                "eng"
            ],
            "coordinates": [
                133.76797485351562,
                489.6188659667969,
                477.5572814941406,
                523.9700317382812
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "b16667322334bab960f89b7c8da59cfb",
        "text": "[58] Yang Lu, Song-Chun Zhu, and Ying Nian Wu. Learning FRAME Models\nUsing CNN Filters. In Thirtieth AAAI Conference on Artiﬁcial Intelligence,\n2016.",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 51,
            "languages": [
                "eng"
            ],
            "coordinates": [
                133.76797485351562,
                533.453857421875,
                477.5673828125,
                567.327392578125
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "4e316cfd2a9d88dfc3bc7ac8a59ad5bd",
        "text": "[59] Jitendra Malik and Pietro Perona. Preattentive texture discrimination with\nearly vision mechanisms.\nJournal of the Optical Society of America A,\n7(5):923–932, 1990.",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 51,
            "languages": [
                "eng"
            ],
            "coordinates": [
                133.76797485351562,
                577.2898559570312,
                477.55743408203125,
                611.1624145507812
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "c45fc3669be496565bbe82e40ce094f2",
        "text": "[60] B.S. Manjunathi and W. Y. Ma. Texture features for browsing and retrieval\nof image data. IEEE Transactions on Pattern Analysis and Machine In-\ntelligence, 18(8):837–842, 1996.",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 51,
            "languages": [
                "eng"
            ],
            "coordinates": [
                133.76797485351562,
                621.1258544921875,
                477.5573425292969,
                654.9984130859375
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "264217b9429e400b2acbb4e0c40e92e9",
        "text": "51",
        "type": "Title",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 51,
            "languages": [
                "eng"
            ],
            "coordinates": [
                300.6419677734375,
                694.8488159179688,
                310.60455322265625,
                704.8114013671875
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "88f55368caac376dbf113ca2807e9be2",
        "text": "[61] Georges Matheron.\nSch´ema bool´een s´equentiel de partition al´eatoire.\nRapport technique N-83, Centre de Morphologie Math´ematique, ´Ecole des\nMines de Paris, 214, 1968.",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 52,
            "languages": [
                "eng"
            ],
            "coordinates": [
                133.76800537109375,
                126.97892761230469,
                477.50750732421875,
                160.8515625
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "2c17eae4e2d2c4d4e227a13b0f60fe6a",
        "text": "[62] David Mumford and Agn`es Desolneux. Pattern Theory: The Stochastic\nAnalysis of Real-World Signals. A K Peters, Ltd., 2010.",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 52,
            "languages": [
                "eng"
            ],
            "coordinates": [
                133.76800537109375,
                170.81394958496094,
                477.4795837402344,
                192.7315673828125
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "542a99226c36dd558aba668d5bb1b756",
        "text": "[63] Roman Novak and Yaroslav Nikulin. Improving the neural algorithm of\nartistic style. arXiv preprint arXiv:1605.04603, 2016.",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 52,
            "languages": [
                "eng"
            ],
            "coordinates": [
                133.7680206298828,
                202.6949920654297,
                477.54736328125,
                224.61260986328125
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "f0abdee4ea832dd47403bd04e0d3b53e",
        "text": "[64] Aaron van den Oord, Nal Kalchbrenner, and Koray Kavukcuoglu. Pixel\nrecurrent neural networks. arXiv preprint arXiv:1601.06759, 2016.",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 52,
            "languages": [
                "eng"
            ],
            "coordinates": [
                133.76800537109375,
                234.5749969482422,
                477.5672912597656,
                256.49261474609375
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "58ee07fa154305826c82742ed94bbfb6",
        "text": "[65] Ken Perlin.\nAn image synthesizer.\nACM Siggraph Computer Graphics,\n19(3):287–296, 1985.",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 52,
            "languages": [
                "eng"
            ],
            "coordinates": [
                133.76803588867188,
                266.4560546875,
                477.48162841796875,
                288.3736267089844
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "5ef39e19447111cb5550d75bf608c913",
        "text": "[66] Gabriel Peyr´e. Sparse modeling of textures. Journal of Mathematical Imag-\ning and Vision, 34(1):17–31, 2009.",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 52,
            "languages": [
                "eng"
            ],
            "coordinates": [
                133.76803588867188,
                298.3360290527344,
                477.49932861328125,
                320.25360107421875
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "829f2f2fe7a114f5c653618752ca3352",
        "text": "[67] Gabriel Peyr´e. Texture synthesis with grouplets. IEEE Trans. Pattern.\nAnal. Mach. Intell., 4(32):733–746, 2010.",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 52,
            "languages": [
                "eng"
            ],
            "coordinates": [
                133.76803588867188,
                330.2170104980469,
                477.4803161621094,
                352.13458251953125
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "f539a60f8c643f077d75ede95a603141",
        "text": "[68] Javier Portilla and Eero P. Simoncelli.\nRepresentation and synthesis of\nvisual texture. http://www.cns.nyu.edu/~lcv/texture/.",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 52,
            "languages": [
                "eng"
            ],
            "coordinates": [
                133.76803588867188,
                362.09698486328125,
                477.5374755859375,
                386.4231262207031
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "f45407fb65ffb9ea066e0d66bfed3929",
        "text": "[69] Javier Portilla and Eero P. Simoncelli. A parametric texture model based\non joint statistics of complex wavelet coeﬃcients. International Journal of\nComputer Vision, 40(1):49–70, 2000.",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 52,
            "languages": [
                "eng"
            ],
            "coordinates": [
                133.76806640625,
                393.9769592285156,
                477.527587890625,
                427.85052490234375
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "71a1552e11e97902fdd0f8191b69f356",
        "text": "[70] Lara Raad, Agn`es Desolneux, and Jean-Michel Morel. A conditional multi-\nscale locally Gaussian texture synthesis algorithm. Journal of Mathematical\nImaging and Vision, 56(2):260–279, 2016.",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 52,
            "languages": [
                "eng"
            ],
            "coordinates": [
                133.76808166503906,
                437.81292724609375,
                477.5275573730469,
                471.68548583984375
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "6b720b3c33c92fb53ec8c93378d3d4bf",
        "text": "[71] Lara Raad and Bruno Galerne. Efros and freeman image quilting algorithm\nfor texture synthesis. IPOL Journal, 7:1–22, 2017.",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 52,
            "languages": [
                "eng"
            ],
            "coordinates": [
                133.76808166503906,
                481.6488952636719,
                477.54742431640625,
                503.56646728515625
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "d92f6e54a2127e1afbb3cdf809c79092",
        "text": "[72] Julien Rabin, Gabriel Peyr´e, Julie Delon, and Marc Bernot. Wasserstein\nbarycenter and its application to texture mixing. In Scale Space and Varia-\ntional Methods in Computer Vision, volume 6667 of Lecture Notes in Com-\nputer Science, pages 435–446. Springer Berlin / Heidelberg, 2012.",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 52,
            "languages": [
                "eng"
            ],
            "coordinates": [
                133.76808166503906,
                513.5288696289062,
                477.5275573730469,
                559.357421875
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "804259d20a784736941ea6704612506f",
        "text": "[73] Alec Radford, Luke Metz, and Soumith Chintala. Unsupervised represen-\ntation learning with deep convolutional generative adversarial networks.\narXiv preprint arXiv:1511.06434, 2015.",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 52,
            "languages": [
                "eng"
            ],
            "coordinates": [
                133.76806640625,
                569.3198852539062,
                477.53338623046875,
                603.1924438476562
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "1d1e594ffeb511e1d8e031e213a25578",
        "text": "[74] Amir Rosenberger, Daniel Cohen-Or, and Dani Lischinski. Layered shape\nsynthesis: automatic generation of control maps for non-stationary tex-\ntures. In ACM Transactions on Graphics (TOG), volume 28, page 107.\nACM, 2009.",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 52,
            "languages": [
                "eng"
            ],
            "coordinates": [
                133.76806640625,
                613.1558227539062,
                477.517578125,
                658.9834594726562
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "0cde27b880a1049d820916238ca30c68",
        "text": "52",
        "type": "Title",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 52,
            "languages": [
                "eng"
            ],
            "coordinates": [
                300.64208984375,
                694.848876953125,
                310.60467529296875,
                704.8114624023438
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "a1e2b77e5abe9bec4e69f90885394f0c",
        "text": "[75] Olga Russakovsky, Jia Deng, Hao Su, Jonathan Krause, Sanjeev Satheesh,\nSean Ma, Zhiheng Huang, Andrej Karpathy, Aditya Khosla, Michael Bern-\nstein, Alexander C. Berg, and Li Fei-Fei.\nImageNet Large Scale Visual\nRecognition Challenge. International Journal of Computer Vision (IJCV),\n115(3):211–252, 2015.",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 53,
            "languages": [
                "eng"
            ],
            "coordinates": [
                133.76800537109375,
                126.97892761230469,
                477.5533142089844,
                184.7615966796875
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "5454afc4885ef7a5f81accc27b0239bf",
        "text": "[76] Tim Salimans, Andrej Karpathy, Xi Chen, and Diederik P Kingma. Pixel-\ncnn++: Improving the pixelcnn with discretized logistic mixture likelihood\nand other modiﬁcations. In Proceedings of the International Conference on\nLearning Representations (ICLR), 2017.",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 53,
            "languages": [
                "eng"
            ],
            "coordinates": [
                133.76800537109375,
                194.7250213623047,
                477.54742431640625,
                240.55267333984375
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "857601e5b71b651dd6e9a9bac78aaca0",
        "text": "[77] Jean Serra. Image analysis and mathematical morphology, v. 1. Academic\npress, 1982.",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 53,
            "languages": [
                "eng"
            ],
            "coordinates": [
                133.76800537109375,
                250.5150604248047,
                477.47509765625,
                272.43365478515625
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "c211c044753589312e28111044b7d391",
        "text": "[78] Claude E. Shannon. A mathematical theory of communication. Bell System\nTechnical Journal, 27(3):379–423, 1948.",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 53,
            "languages": [
                "eng"
            ],
            "coordinates": [
                133.76797485351562,
                282.39605712890625,
                477.4952392578125,
                304.3136291503906
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "28bf79b354563546b5fa3fdaf44f2cd2",
        "text": "[79] Eero P. Simoncelli and William T. Freeman. The steerable pyramid: a\nﬂexible architecture for multi-scale derivative computation. In ICIP (3),\npages 444–447, 1995.",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 53,
            "languages": [
                "eng"
            ],
            "coordinates": [
                133.76797485351562,
                314.2760314941406,
                477.5174865722656,
                348.14959716796875
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "c751cc2af412defc3d54a996f83bcd90",
        "text": "[80] Karen Simonyan and Andrew Zisserman. Very deep convolutional networks\nfor large-scale image recognition. arXiv preprint arXiv:1409.1556, 2014.",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 53,
            "languages": [
                "eng"
            ],
            "coordinates": [
                133.76797485351562,
                358.11199951171875,
                477.5274658203125,
                380.0295715332031
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "892bf93b9bc78938b7758442af551cc0",
        "text": "[81] Guillaume Tartavel, Yann Gousseau, and Gabriel Peyr´e. Variational tex-\nture synthesis with sparsity and spectrum constraints. Journal of Mathe-\nmatical Imaging and Vision, 52(1):124–144, 2014.",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 53,
            "languages": [
                "eng"
            ],
            "coordinates": [
                133.76797485351562,
                389.9919738769531,
                477.5374755859375,
                423.86553955078125
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "308e414c2e73e48e78ca836169ead05e",
        "text": "[82] M. R. Turner. Texture discrimination by Gabor functions. Biological Cy-\nbernetics, 55:71–82, 1986.",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 53,
            "languages": [
                "eng"
            ],
            "coordinates": [
                133.7679901123047,
                433.82794189453125,
                477.5010681152344,
                455.7455139160156
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "3bec1bff80999b3116569731df1e49b7",
        "text": "[83] Dmitry Ulyanov, Vadim Lebedev, Andrea Vedaldi, and Victor Lempitsky.\nTexture networks: Feed-forward synthesis of textures and stylized images.\nIn Int. Conf. on Machine Learning (ICML), 2016.",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 53,
            "languages": [
                "eng"
            ],
            "coordinates": [
                133.76797485351562,
                465.70892333984375,
                477.5374755859375,
                499.58148193359375
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "405e728966459dc8b91da478c3deb9a8",
        "text": "[84] M. Unser. Texture classiﬁcation and segmentation using wavelet frames.\nIEEE Transactions on Image Processing, 4(11):1549–1560, 1995.",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 53,
            "languages": [
                "eng"
            ],
            "coordinates": [
                133.76797485351562,
                509.54388427734375,
                477.4876708984375,
                531.46142578125
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "b5b65ecaa1caef9e2deb0b58fdf2a075",
        "text": "[85] Ivan Ustyuzhaninov, Wieland Brendel, Leon Gatys, and Matthias Bethge.\nWhat does it take to generate natural textures?\nIn Proceedings of the\nInternational Conference on Learning Representations (ICLR), 2017.",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 53,
            "languages": [
                "eng"
            ],
            "coordinates": [
                133.76800537109375,
                541.4248657226562,
                477.5375061035156,
                575.2974853515625
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "14bba4709b6bff826615d519e5bac72b",
        "text": "[86] Aaron\nvan\nden\nOord,\nNal\nKalchbrenner,\nLasse\nEspeholt,\nkoray\nkavukcuoglu, Oriol Vinyals, and Alex Graves. Conditional image gener-\nation with pixelcnn decoders. In D. D. Lee, M. Sugiyama, U. V. Luxburg,\nI. Guyon, and R. Garnett, editors, Advances in Neural Information Pro-\ncessing Systems 29, pages 4790–4798. Curran Associates, Inc., 2016.",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 53,
            "languages": [
                "eng"
            ],
            "coordinates": [
                133.76797485351562,
                585.2598876953125,
                477.5432434082031,
                643.04345703125
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "52e43e88de6266fe56b509220731f114",
        "text": "[87] Jarke J. van Wijk. Spot noise texture synthesis for data visualization. In\nSIGGRAPH ’91, pages 309–318, New York, NY, USA, 1991. ACM.",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 53,
            "languages": [
                "eng"
            ],
            "coordinates": [
                133.76797485351562,
                653.005859375,
                477.53741455078125,
                674.9234619140625
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "9a43b60cf18cc0a530da8d4af3822714",
        "text": "53",
        "type": "Title",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 53,
            "languages": [
                "eng"
            ],
            "coordinates": [
                300.6419677734375,
                694.848876953125,
                310.60455322265625,
                704.8114624023438
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "5e36445f234e26d92b341cfc469ec936",
        "text": "[88] Xiaolong Wang and Abhinav Gupta. Generative image modeling using style\nand structure adversarial networks. In European Conference on Computer\nVision, pages 318–335. Springer, 2016.",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 54,
            "languages": [
                "eng"
            ],
            "coordinates": [
                133.76800537109375,
                126.97892761230469,
                477.5374450683594,
                160.8515625
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "c5f07ff50e86689cf8eca41a8b5deffd",
        "text": "[89] Li-Yi Wei, Sylvain Lefebvre, Vivek Kwatra, and Greg Turk. State of the\nart in example-based texture synthesis. In Eurographics 2009, State of the\nArt Report, EG-STAR, pages 93–117. Eurographics Association, 2009.",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 54,
            "languages": [
                "eng"
            ],
            "coordinates": [
                133.76800537109375,
                170.81394958496094,
                477.5375671386719,
                204.68756103515625
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "4c46d9004a3fc4b587c449f7947dc279",
        "text": "[90] Li-Yi Wei and Marc Levoy. Fast texture synthesis using tree-structured vec-\ntor quantization. In Proceedings of the 27th annual conference on Computer\ngraphics and interactive techniques, pages 479–488. ACM Press/Addison-\nWesley Publishing Co., 2000.",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 54,
            "languages": [
                "eng"
            ],
            "coordinates": [
                133.7680206298828,
                214.6499481201172,
                477.4977111816406,
                260.47760009765625
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "0e6d6c2ff1843d2c29de8d613394e453",
        "text": "[91] Pierre Wilmot, Eric Risser, and Connelly Barnes. Stable and controllable\nneural texture synthesis and style transfer using histogram losses. arXiv\npreprint arXiv:1701.08893, 2017.",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 54,
            "languages": [
                "eng"
            ],
            "coordinates": [
                133.7679901123047,
                270.4410400390625,
                477.5274963378906,
                304.3135986328125
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "bf6c3db8d0e4fd344c6bc140aee8d2db",
        "text": "[92] Ying Nian Wu, Song-Chun Zhu, and Xiuwen Liu. Equivalence of Julesz\nensembles and FRAME models. International Journal of Computer Vision,\n38(3):247–265, 2000.",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 54,
            "languages": [
                "eng"
            ],
            "coordinates": [
                133.76800537109375,
                314.2760009765625,
                477.55743408203125,
                348.1495666503906
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "b7acd1aec4b158a4e0ba838b51abda19",
        "text": "[93] Jianwen Xie, Yang Lu, Song-Chun Zhu, and Ying Nian Wu.\nA theory\nof generative convnet. In International Conference on Machine Learning,\npages 2635–2644, 2016.",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 54,
            "languages": [
                "eng"
            ],
            "coordinates": [
                133.76797485351562,
                358.1119689941406,
                477.5573425292969,
                391.9845275878906
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "9f1b61f780393557268b22be61041258",
        "text": "[94] Ciyou Zhu, Richard H. Byrd, Peihuang Lu, and Jorge Nocedal. Lbfgs-b:\nFortran subroutines for large-scale bound constrained optimization. Report\nNAM-11, EECS Department, Northwestern University, 1994.",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 54,
            "languages": [
                "eng"
            ],
            "coordinates": [
                133.76797485351562,
                401.94793701171875,
                477.5473937988281,
                435.82049560546875
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "6eb7fd19c45051d5e782b849a0533ac3",
        "text": "[95] Song-Chun Zhu, Cheng-en Guo, Yizhou Wang, and Zijian Xu. What are\nTextons?\nInternational Journal of Computer Vision, 62(1–2):121–143,\n2005.",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 54,
            "languages": [
                "eng"
            ],
            "coordinates": [
                133.76797485351562,
                445.78289794921875,
                477.5572814941406,
                479.6564636230469
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "5540466ca084aa0db0ca169edf589004",
        "text": "[96] Song-Chun Zhu, Xiu Wen Liu, and Ying Nian Wu.\nExploring texture\nensembles by eﬃcient Markov Chain Monte Carlo – toward a “trichromacy”\ntheory of texture. IEEE Transactions on Pattern Analysis and Machine\nIntelligence, 22(6):554–569, 2000.",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 54,
            "languages": [
                "eng"
            ],
            "coordinates": [
                133.7679901123047,
                489.6188659667969,
                477.5772399902344,
                535.4464111328125
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "2f0192e27c5663b4881133703b0eadaa",
        "text": "[97] Song-Chun Zhu, Ying Nian Wu, and David Mumford. Minimax entropy\nprinciple and its application to texture modeling.\nNeural computation,\n9(8):1627–1660, 1997.",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 54,
            "languages": [
                "eng"
            ],
            "coordinates": [
                133.76800537109375,
                545.4098510742188,
                477.57733154296875,
                579.2824096679688
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "22b3f2338c7ca54faef79b961809ff2b",
        "text": "[98] Song-Chun Zhu, Ying Nian Wu, and David Mumford.\nFilters, random\nﬁelds and maximum entropy (frame): Towards a uniﬁed theory for texture\nmodeling. International Journal of Computer Vision, 27(2):107–126, 1998.",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 54,
            "languages": [
                "eng"
            ],
            "coordinates": [
                133.76800537109375,
                589.2448120117188,
                477.5773010253906,
                623.118408203125
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "74d402446df1b60e97281cd0b87fd895",
        "text": "54",
        "type": "Title",
        "metadata": {
            "source_doc": "A_survey_of_exemplar-based_texture_synthesis.pdf",
            "page_number": 54,
            "languages": [
                "eng"
            ],
            "coordinates": [
                300.6419982910156,
                694.8488159179688,
                310.6045837402344,
                704.8114013671875
            ],
            "is_full_width": false
        }
    }
]