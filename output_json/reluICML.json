[
    {
        "element_id": "b3a0c89fb7a2f4fdfde6b877d02182aa",
        "text": "Rectiﬁed Linear Units Improve Restricted Boltzmann Machines",
        "type": "Title",
        "metadata": {
            "source_doc": "reluICML.pdf",
            "page_number": 1,
            "languages": [
                "eng"
            ],
            "coordinates": [
                72.4136962890625,
                89.83982849121094,
                524.538818359375,
                104.18602752685547
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "55febdd2d33935a64d444d9e1c3445af",
        "text": "Vinod Nair\nvnair@cs.toronto.edu\nGeoﬀrey E. Hinton\nhinton@cs.toronto.edu\nDepartment of Computer Science, University of Toronto, Toronto, ON M5S 2G4, Canada",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "reluICML.pdf",
            "page_number": 1,
            "languages": [
                "eng"
            ],
            "coordinates": [
                55.440185546875,
                139.37936401367188,
                531.4727172851562,
                177.70281982421875
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "1465960ec7302e5546d842417454f3dd",
        "text": "Abstract",
        "type": "Title",
        "metadata": {
            "source_doc": "reluICML.pdf",
            "page_number": 1,
            "languages": [
                "eng"
            ],
            "coordinates": [
                146.73617553710938,
                206.6207733154297,
                198.1344757080078,
                218.5758819580078
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "8eb775202170efb697159f4a95cfec32",
        "text": "Restricted Boltzmann machines were devel-\noped using binary stochastic hidden units.\nThese can be generalized by replacing each\nbinary unit by an inﬁnite number of copies\nthat all have the same weights but have pro-\ngressively more negative biases. The learning\nand inference rules for these “Stepped Sig-\nmoid Units” are unchanged. They can be ap-\nproximated eﬃciently by noisy, rectiﬁed lin-\near units. Compared with binary units, these\nunits learn features that are better for object\nrecognition on the NORB dataset and face\nveriﬁcation on the Labeled Faces in the Wild\ndataset. Unlike binary units, rectiﬁed linear\nunits preserve information about relative in-\ntensities as information travels through mul-\ntiple layers of feature detectors.",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "reluICML.pdf",
            "page_number": 1,
            "languages": [
                "eng"
            ],
            "coordinates": [
                75.36587524414062,
                242.026123046875,
                269.5660705566406,
                443.27459716796875
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "82591927b3c8edc27031622893808626",
        "text": "1. Introduction",
        "type": "Title",
        "metadata": {
            "source_doc": "reluICML.pdf",
            "page_number": 1,
            "languages": [
                "eng"
            ],
            "coordinates": [
                55.44047546386719,
                484.3421325683594,
                144.41534423828125,
                496.2972106933594
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "df1a44947b4b9db836e365c68db646ca",
        "text": "Restricted Boltzmann machines (RBMs) have been\nused as generative models of many diﬀerent types\nof\ndata\nincluding\nlabeled\nor\nunlabeled\nimages\n(Hinton et al., 2006), sequences of mel-cepstral coef-\nﬁcients that represent speech (Mohamed & Hinton,\n2010),\nbags\nof\nwords\nthat\nrepresent\ndocuments\n(Salakhutdinov & Hinton, 2009), and user ratings of\nmovies (Salakhutdinov et al., 2007).\nIn their con-\nditional form they can be used to model high-\ndimensional temporal sequences such as video or mo-\ntion capture data (Taylor et al., 2006). Their most im-\nportant use is as learning modules that are composed\nto form deep belief nets (Hinton et al., 2006).",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "reluICML.pdf",
            "page_number": 1,
            "languages": [
                "eng"
            ],
            "coordinates": [
                55.44000244140625,
                505.53692626953125,
                289.4573974609375,
                658.9686889648438
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "90bad5c322a6f3e824f5deab2308b86a",
        "text": "Appearing in Proceedings of the 27 th International Confer-\nence on Machine Learning, Haifa, Israel, 2010. Copyright\n2010 by the author(s)/owner(s).",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "reluICML.pdf",
            "page_number": 1,
            "languages": [
                "eng"
            ],
            "coordinates": [
                55.44020080566406,
                679.6174926757812,
                291.5604553222656,
                712.3233642578125
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "cec1fda6d7afb844ce2ddcd42c46296c",
        "text": "1.1. Learning a Restricted Boltzmann Machine",
        "type": "Title",
        "metadata": {
            "source_doc": "reluICML.pdf",
            "page_number": 1,
            "languages": [
                "eng"
            ],
            "coordinates": [
                307.4405822753906,
                208.17864990234375,
                541.4314575195312,
                218.1412811279297
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "dbd3552ba156acc7af193370d5a6f0c0",
        "text": "Images composed of binary pixels can be modeled by\nan RBM that uses a layer of binary hidden units (fea-\nture detectors) to model the higher-order correlations\nbetween pixels. If there are no direct interactions be-\ntween the hidden units and no direct interactions be-\ntween the visible units that represent the pixels, there\nis a simple and eﬃcient method called “Contrastive\nDivergence” to learn a good set of feature detectors\nfrom a set of training images (Hinton, 2002). We start\nwith small, random weights on the symmetric connec-\ntions between each pixel i and each feature detector j.\nThen we repeatedly update each weight, wij, using the\ndiﬀerence between two measured, pairwise correlations",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "reluICML.pdf",
            "page_number": 1,
            "languages": [
                "eng"
            ],
            "coordinates": [
                307.44000244140625,
                227.09478759765625,
                541.4716796875,
                380.5178527832031
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "ea8408fb08d5f3950a12f0a677a9fa9c",
        "text": "∆wij = ǫ(<vihj>data −<vihj>recon)\n(1)",
        "type": "Title",
        "metadata": {
            "source_doc": "reluICML.pdf",
            "page_number": 1,
            "languages": [
                "eng"
            ],
            "coordinates": [
                342.2613525390625,
                392.998046875,
                541.43896484375,
                404.6737060546875
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "c2c8b3a55045de7c7360f3c0cb1a6293",
        "text": "where ǫ is a learning rate, <vihj>data is the frequency\nwith which visible unit i and hidden unit j are on to-\ngether when the feature detectors are being driven by\nimages from the training set and <vihj>recon is the\ncorresponding frequency when the hidden units are be-\ning driven by reconstructed images. A similar learning\nrule can be used for the biases.",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "reluICML.pdf",
            "page_number": 1,
            "languages": [
                "eng"
            ],
            "coordinates": [
                307.4400634765625,
                415.6691589355469,
                541.4755859375,
                497.5807800292969
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "d0836017063edcee749a38db095e1b53",
        "text": "Given a training image, we set the binary state, hj, of\neach feature detector to be 1 with probability",
        "type": "Title",
        "metadata": {
            "source_doc": "reluICML.pdf",
            "page_number": 1,
            "languages": [
                "eng"
            ],
            "coordinates": [
                307.4409484863281,
                505.32733154296875,
                541.4403076171875,
                527.4697875976562
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "36f5a463a4b5bfe47f2f2e988945b877",
        "text": "p(hj = 1) =\n1\n1 + exp(−bj −P\ni∈vis viwij)\n(2)",
        "type": "Title",
        "metadata": {
            "source_doc": "reluICML.pdf",
            "page_number": 1,
            "languages": [
                "eng"
            ],
            "coordinates": [
                335.48504638671875,
                537.568115234375,
                541.4376831054688,
                563.8716430664062
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "1622537556badff93dfc6a2397c496e5",
        "text": "where bj is the bias of j and vi is the binary state\nof pixel i. Once binary states have been chosen for\nthe hidden units we produce a “reconstruction” of the\ntraining image by setting the state of each pixel to be\n1 with probability",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "reluICML.pdf",
            "page_number": 1,
            "languages": [
                "eng"
            ],
            "coordinates": [
                307.43994140625,
                573.0613403320312,
                541.470458984375,
                631.0597534179688
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "d29571907a49ff1e339b6ae2ba2287c3",
        "text": "p(vi = 1) =\n1\n1 + exp(−bi −P\nj∈hid hjwij)\n(3)",
        "type": "Title",
        "metadata": {
            "source_doc": "reluICML.pdf",
            "page_number": 1,
            "languages": [
                "eng"
            ],
            "coordinates": [
                334.75482177734375,
                641.1581420898438,
                541.4375610351562,
                667.461669921875
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "6aad294410f9955d9f3258d38e0dfb1d",
        "text": "The learned weights and biases implicitly deﬁne a\nprobability distribution over all possible binary images\nvia the energy, E(v, h), of a joint conﬁguration of the",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "reluICML.pdf",
            "page_number": 1,
            "languages": [
                "eng"
            ],
            "coordinates": [
                307.4398193359375,
                683.6737670898438,
                541.478759765625,
                717.54931640625
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "4fb2726b12c4fedcc238c0391428a375",
        "text": "visible and hidden units:",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "reluICML.pdf",
            "page_number": 2,
            "languages": [
                "eng"
            ],
            "coordinates": [
                55.44020080566406,
                69.54999542236328,
                162.6788330078125,
                79.51263427734375
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "1232fcb649fe559b7e90f2239eb2154f",
        "text": "E(v, h) = −\nX",
        "type": "Title",
        "metadata": {
            "source_doc": "reluICML.pdf",
            "page_number": 2,
            "languages": [
                "eng"
            ],
            "coordinates": [
                68.94920349121094,
                81.67881774902344,
                138.69383239746094,
                101.6075439453125
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "2a59958c88f903954c76372a3a76a2d5",
        "text": "i,j\nvihjwij −\nX",
        "type": "Title",
        "metadata": {
            "source_doc": "reluICML.pdf",
            "page_number": 2,
            "languages": [
                "eng"
            ],
            "coordinates": [
                127.07067108154297,
                81.67887878417969,
                199.16494750976562,
                112.45510864257812
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "6f3df0d601b76b1e6c3442180e755a14",
        "text": "i\nvibi −\nX",
        "type": "Title",
        "metadata": {
            "source_doc": "reluICML.pdf",
            "page_number": 2,
            "languages": [
                "eng"
            ],
            "coordinates": [
                190.56561279296875,
                81.67893981933594,
                243.12982177734375,
                112.45516967773438
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "e95bb50268e33c7456c9e46f58671fa5",
        "text": "j\nhjbj\n(4)",
        "type": "Title",
        "metadata": {
            "source_doc": "reluICML.pdf",
            "page_number": 2,
            "languages": [
                "eng"
            ],
            "coordinates": [
                234.08985900878906,
                91.42621612548828,
                289.437255859375,
                112.45523071289062
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "4b733702cb2922b03f71ca6a7b718f2f",
        "text": "p(v) =\nP\nh e−E(v,h)\nP\nu,g e−E(u,g)\n(5)",
        "type": "Title",
        "metadata": {
            "source_doc": "reluICML.pdf",
            "page_number": 2,
            "languages": [
                "eng"
            ],
            "coordinates": [
                124.856689453125,
                118.02073669433594,
                289.43743896484375,
                152.60797119140625
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "e357dd06edadb1ff6f5abd9d9a52d76a",
        "text": "1.2. Gaussian units",
        "type": "Title",
        "metadata": {
            "source_doc": "reluICML.pdf",
            "page_number": 2,
            "languages": [
                "eng"
            ],
            "coordinates": [
                55.44087219238281,
                165.041748046875,
                150.88104248046875,
                175.00437927246094
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "764e2a6443b66b41c8da307249a0e5bb",
        "text": "RBMs were originally developed using binary stochas-\ntic units for both the visible and hidden layers\n(Hinton, 2002).\nTo deal with real-valued data\nsuch as the pixel intensities\nin\nnatural images,\n(Hinton & Salakhutdinov, 2006) replaced the binary\nvisible units by linear units with independent Gaus-\nsian noise as ﬁrst suggested by (Freund & Haussler,\n1994). The energy function then becomes:",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "reluICML.pdf",
            "page_number": 2,
            "languages": [
                "eng"
            ],
            "coordinates": [
                55.44000244140625,
                183.96685791015625,
                289.4902648925781,
                277.61163330078125
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "55ca67dea771369ee9b426b77b6ce52b",
        "text": "2σ2\ni\n−\nX",
        "type": "Title",
        "metadata": {
            "source_doc": "reluICML.pdf",
            "page_number": 2,
            "languages": [
                "eng"
            ],
            "coordinates": [
                134.3699951171875,
                286.1590576171875,
                202.77406311035156,
                314.79351806640625
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "0b4aedd0cda795ce8ccaa6dc9b6d5524",
        "text": "E(v, h) =\nX",
        "type": "Title",
        "metadata": {
            "source_doc": "reluICML.pdf",
            "page_number": 2,
            "languages": [
                "eng"
            ],
            "coordinates": [
                55.44919967651367,
                286.1590881347656,
                117.48989868164062,
                306.08782958984375
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "26e544e24bf61f67104f58a2c99dbe92",
        "text": "j∈hid\nbjhj −\nX",
        "type": "Title",
        "metadata": {
            "source_doc": "reluICML.pdf",
            "page_number": 2,
            "languages": [
                "eng"
            ],
            "coordinates": [
                185.5169219970703,
                286.1590881347656,
                252.27410888671875,
                317.3143005371094
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "c291623c297b9d9e26ff64b7928a0687",
        "text": "(vi −bi)2",
        "type": "Title",
        "metadata": {
            "source_doc": "reluICML.pdf",
            "page_number": 2,
            "languages": [
                "eng"
            ],
            "coordinates": [
                122.04881286621094,
                288.00250244140625,
                161.67474365234375,
                300.84051513671875
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "9d072d07e64a78c46750dd71b8771b14",
        "text": "vi\nσi\nhjwij",
        "type": "Title",
        "metadata": {
            "source_doc": "reluICML.pdf",
            "page_number": 2,
            "languages": [
                "eng"
            ],
            "coordinates": [
                255.14100646972656,
                289.16534423828125,
                288.5257263183594,
                313.50640869140625
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "4705948ff31487f1e0d593bf8a8c907e",
        "text": "i∈vis",
        "type": "Title",
        "metadata": {
            "source_doc": "reluICML.pdf",
            "page_number": 2,
            "languages": [
                "eng"
            ],
            "coordinates": [
                101.41165161132812,
                309.26971435546875,
                119.20002746582031,
                317.1701354980469
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "9a71ec5acc3f1f72391f0160ea1e28c0",
        "text": "i,j",
        "type": "Title",
        "metadata": {
            "source_doc": "reluICML.pdf",
            "page_number": 2,
            "languages": [
                "eng"
            ],
            "coordinates": [
                240.6419677734375,
                309.9615173339844,
                249.1213836669922,
                316.93536376953125
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "7f9c528c6a1f5a4aa8af0437065131b3",
        "text": "(6)\nwhere σi is the standard deviation of the Gaussian\nnoise for visible unit i.",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "reluICML.pdf",
            "page_number": 2,
            "languages": [
                "eng"
            ],
            "coordinates": [
                55.44105529785156,
                318.9309997558594,
                289.4705810546875,
                352.7976379394531
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "a189f30a1e92ace4248260550fb4e861",
        "text": "It is possible to learn the variance of the noise for each\nvisible unit but this is diﬃcult using binary hidden\nunits. In many applications, it is much easier to ﬁrst\nnormalise each component of the data to have zero\nmean and unit variance and then to use noise-free re-\nconstructions, with the variance in equation 6 set to 1.\nThe reconstructed value of a Gaussian visible unit is\nthen equal to its top-down input from the binary hid-\nden units plus its bias. We use this type of noise-free\nvisible unit for the models of object and face images\ndescribed later.",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "reluICML.pdf",
            "page_number": 2,
            "languages": [
                "eng"
            ],
            "coordinates": [
                55.44000244140625,
                360.7720947265625,
                289.5085144042969,
                490.28155517578125
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "bade5952296f14779c74e9ab9e54c260",
        "text": "2. Rectiﬁed linear units",
        "type": "Title",
        "metadata": {
            "source_doc": "reluICML.pdf",
            "page_number": 2,
            "languages": [
                "eng"
            ],
            "coordinates": [
                55.44000244140625,
                507.05853271484375,
                193.89585876464844,
                519.0136108398438
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "77f22e2f1d764b1c6c3a6d9d0c6ec3f1",
        "text": "To allow each unit to express more information,\n(Teh & Hinton, 2001) introduced binomial units which\ncan be viewed as N separate copies of a binary unit\nthat all share the same bias and weights. A nice side-\neﬀect of using weight-sharing to synthesize a new type\nof unit out of binary units is that the mathematics\nunderlying learning in binary-binary RBM’s remains\nunchanged. Since all N copies receive the same total\ninput, they all have the same probability, p, of turn-\ning on and this only has to be computed once. The\nexpected number that are on is Np and the variance\nin this number is Np(1 −p). For small p, this acts like\na Poisson unit, but as p approaches 1 the variance be-\ncomes small again which may not be desireable. Also,\nfor small values of p the growth in p is exponential in\nthe total input. This makes learning much less stable",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "reluICML.pdf",
            "page_number": 2,
            "languages": [
                "eng"
            ],
            "coordinates": [
                55.43934631347656,
                528.2619018554688,
                289.48907470703125,
                717.549560546875
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "15f951fcca359fa056225f1baf65c91d",
        "text": "10",
        "type": "Title",
        "metadata": {
            "source_doc": "reluICML.pdf",
            "page_number": 2,
            "languages": [
                "eng"
            ],
            "coordinates": [
                339.6789855957031,
                67.52885437011719,
                347.4310607910156,
                77.10742950439453
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "345ab1f98342c05daccb24a1d09b997c",
        "text": "8",
        "type": "Title",
        "metadata": {
            "source_doc": "reluICML.pdf",
            "page_number": 2,
            "languages": [
                "eng"
            ],
            "coordinates": [
                343.5429992675781,
                92.07383728027344,
                347.4190368652344,
                101.65241241455078
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "e7de4e89bd5ca77b8613bfb0688923db",
        "text": "6",
        "type": "Title",
        "metadata": {
            "source_doc": "reluICML.pdf",
            "page_number": 2,
            "languages": [
                "eng"
            ],
            "coordinates": [
                343.5429992675781,
                116.61784362792969,
                347.4190368652344,
                126.19641876220703
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "a14ae1e8bd907254afa69da14e5e3113",
        "text": "4",
        "type": "Title",
        "metadata": {
            "source_doc": "reluICML.pdf",
            "page_number": 2,
            "languages": [
                "eng"
            ],
            "coordinates": [
                343.5429992675781,
                141.16282653808594,
                347.4190368652344,
                150.7414093017578
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "40a4bb23d06aad2b6839028335f9b1eb",
        "text": "2",
        "type": "Title",
        "metadata": {
            "source_doc": "reluICML.pdf",
            "page_number": 2,
            "languages": [
                "eng"
            ],
            "coordinates": [
                343.5429992675781,
                165.70787048339844,
                347.4190368652344,
                175.2864532470703
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "db4b06e894d660df8e804f280c09e541",
        "text": "−5\n0\n5\n10\n0",
        "type": "Title",
        "metadata": {
            "source_doc": "reluICML.pdf",
            "page_number": 2,
            "languages": [
                "eng"
            ],
            "coordinates": [
                342.4389953613281,
                190.28184509277344,
                508.00408935546875,
                204.7404327392578
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "e6c9d4bf8a1d91850ca2d0f4e93412fb",
        "text": "Figure 1. A comparison of three diﬀerent ways to model\nrectiﬁed linear units. The red curve shows the expected\nvalue of the sum of an inﬁnite number of binary units with\neach having a bias one less than the previous one. The blue\ncurve is the approximation log(1+exp(x)). The green curve\nis the expected value of a rectiﬁed linear unit with added\nGaussian noise as described in section 2. The red and blue\ncurves are virtually indistinguishable.",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "reluICML.pdf",
            "page_number": 2,
            "languages": [
                "eng"
            ],
            "coordinates": [
                307.43994140625,
                207.8423309326172,
                541.43212890625,
                293.6886901855469
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "43b64b734e99b6514e72695307e230cd",
        "text": "than for the stepped sigmoid units (SSU) described\nnext.",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "reluICML.pdf",
            "page_number": 2,
            "languages": [
                "eng"
            ],
            "coordinates": [
                307.44000244140625,
                314.13409423828125,
                541.4820556640625,
                336.0487365722656
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "c7fb49fa1a7e2ad6221b65edaae051fc",
        "text": "A small modiﬁcation to binomial units makes them\nfar more interesting as models of real neurons and also\nmore useful for practical applications. We make an in-\nﬁnite number of copies that all have the same learned\nweight vector w and the same learned bias, b, but each\ncopy has a diﬀerent, ﬁxed oﬀset to the bias. If the oﬀ-\nsets are −0.5, −1.5, −2.5, ... the sum of the probabili-\nties of the copies is extremely close to having a closed\nform (ﬁgure 1):",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "reluICML.pdf",
            "page_number": 2,
            "languages": [
                "eng"
            ],
            "coordinates": [
                307.439697265625,
                344.023193359375,
                541.4630126953125,
                449.61993408203125
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "27f1814479b5c3c73a26e9c0880ad4ca",
        "text": "N\nX",
        "type": "Title",
        "metadata": {
            "source_doc": "reluICML.pdf",
            "page_number": 2,
            "languages": [
                "eng"
            ],
            "coordinates": [
                354.67205810546875,
                459.10931396484375,
                369.05810546875,
                469.4883117675781
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "5f3199935ab386731f10e925a278549a",
        "text": "i=1\nσ(x −i + 0.5) ≈log(1 + ex),\n(7)",
        "type": "Title",
        "metadata": {
            "source_doc": "reluICML.pdf",
            "page_number": 2,
            "languages": [
                "eng"
            ],
            "coordinates": [
                355.4099426269531,
                467.4523010253906,
                541.4376220703125,
                490.4468994140625
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "c7dead4e687fdace52b9bdd893b68905",
        "text": "where x = vwT + b.",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "reluICML.pdf",
            "page_number": 2,
            "languages": [
                "eng"
            ],
            "coordinates": [
                307.43988037109375,
                496.114013671875,
                395.2043762207031,
                509.69464111328125
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "6ad1b69d35c8e46533f3f78fe8531b93",
        "text": "So the total activity of all of the copies behaves like\na noisy, integer-valued version of a smoothed rectiﬁed\nlinear unit1.\nEven though log(1 + ex) is not in the\nexponential family, we can model it accurately using\na set of binary units with shared weights and ﬁxed\nbias oﬀsets. This set has no more parameters than an\nordinary binary unit, but it provides a much more ex-\npressive variable. The variance in the integer activity\nlevel is σ(x) so units that are ﬁrmly oﬀdo not create\nnoise and the noise does not become large when x is\nlarge.",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "reluICML.pdf",
            "page_number": 2,
            "languages": [
                "eng"
            ],
            "coordinates": [
                307.4397277832031,
                517.668701171875,
                541.4954833984375,
                647.1786499023438
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "5485ed7dfcf3c62ca10db09d0a2952b4",
        "text": "A drawback of giving each copy a bias that diﬀers\nby a ﬁxed oﬀset is that the logistic sigmoid function\nneeds to be used many times to get the probabilities",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "reluICML.pdf",
            "page_number": 2,
            "languages": [
                "eng"
            ],
            "coordinates": [
                307.4397277832031,
                655.1527099609375,
                541.4683227539062,
                689.0199584960938
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "2914b39687b218129764f3abb371ad0b",
        "text": "1If we only use N copies, we need to subtract the term\nlog(1 + ex−N) from the approximation.",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "reluICML.pdf",
            "page_number": 2,
            "languages": [
                "eng"
            ],
            "coordinates": [
                307.44012451171875,
                696.400634765625,
                541.427734375,
                717.3001708984375
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "09006dfddd5a03ebd09856c2801c467a",
        "text": "required for sampling an integer value correctly.\nIt\nis possible, however, to use a fast approximation in\nwhich the sampled value of the rectiﬁed linear unit is\nnot constrained to be an integer. Instead it is given by\nmax(0, x+N(0, σ(x)) where N(0, V ) is Gaussian noise\nwith zero mean and variance V . We call a unit that\nuses this approximation a N oisyRectiﬁed Linear U nit\n(NReLU) and this paper shows that NReLUs work\nbetter than binary hidden units for several diﬀerent\ntasks.",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "reluICML.pdf",
            "page_number": 3,
            "languages": [
                "eng"
            ],
            "coordinates": [
                55.43975830078125,
                69.54999542236328,
                289.492919921875,
                187.107666015625
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "989e04eb1958142664e0d19ccad20cc4",
        "text": "(Jarrett et al., 2009) have explored various rectiﬁed\nnonlinearities (including the max(0, x) nonlinearity,\nwhich they refer to as “positive part”) in the con-\ntext of convolutional networks and have found them\nto improve discriminative performance. Our empirical\nresults in sections 5 and 6 further support this ob-\nservation. We also give an approximate probabilistic\ninterpretation for the max(0, x) nonlinearity, further\njustifying their use.",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "reluICML.pdf",
            "page_number": 3,
            "languages": [
                "eng"
            ],
            "coordinates": [
                55.43959045410156,
                195.08203125,
                289.47772216796875,
                300.68780517578125
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "1ddd0630b20ed7dda2ff3837f1e6700a",
        "text": "3. Intensity equivariance",
        "type": "Title",
        "metadata": {
            "source_doc": "reluICML.pdf",
            "page_number": 3,
            "languages": [
                "eng"
            ],
            "coordinates": [
                55.44126892089844,
                317.46435546875,
                199.52374267578125,
                329.41943359375
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "b6d9d55ac386df3387022a4eb3d0ca78",
        "text": "NReLU’s have some interesting mathematical proper-\nties (Hahnloser et al., 2003), one of which is very use-\nful for object recognition. A major consideration when\ndesigning an object recognition system is how to make\nthe output invariant to properties of the input such as\nlocation, scale, orientation, lighting etc. Convolutional\nneural networks are often said to achieve translation\ninvariance but in their pure form they actually achieve\nsomething quite diﬀerent. If an object is translated in\nthe input image, its representation in a pool of local\nﬁlters that have shared weights is also translated. So\nif it can be represented well by a pattern of feature\nactivities when it is in one location, it can also be rep-\nresented equally well by a translated pattern of feature\nactivities when it is another location.\nWe call this\ntranslation equivariance: the representation varies in\nthe same way as the image. In a deep convolutional\nnet, translation invaraince is achieved by using sub-\nsampling to introduce a small amount of translation\ninvariance after each layer of ﬁlters.",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "reluICML.pdf",
            "page_number": 3,
            "languages": [
                "eng"
            ],
            "coordinates": [
                55.440093994140625,
                338.6591796875,
                289.4920654296875,
                575.7726440429688
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "b30446a548ddaad8840f270bb646ebeb",
        "text": "Binary hidden units do not exhibit intensity equivari-\nance, but rectiﬁed linear units do, provided they have\nzero biases and are noise-free. Scaling up all of the in-\ntensities in an image by α > 0 cannot change whether\na zero-bias unit receives a total input above or below\nzero. So all of the “oﬀ” units remain oﬀand the re-\nmainder all increase their activities by a factor of α.\nThis stays true for many layers of rectiﬁed linear units.\nWhen deciding whether two face images come from the\nsame person, we make use of this nice property of rec-\ntiﬁed linear units by basing the decision on the cosine",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "reluICML.pdf",
            "page_number": 3,
            "languages": [
                "eng"
            ],
            "coordinates": [
                55.440093994140625,
                583.7380981445312,
                289.4956970214844,
                713.2567749023438
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "7dda6ecc1fbf51dd20a6348d5f7bce00",
        "text": "of the angle between the activities of the feature detec-\ntors in the last hidden layer. The feature vectors are\nintensity equivariant and the cosine is intensity invari-\nant. The type of intensity invariance that is important\nfor recognition cannot be achieved by simply dividing\nall the pixel intensities by their sum. This would cause\na big change in the activities of feature detectors that\nattend to the parts of a face when there is a bright\nspot in the background.",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "reluICML.pdf",
            "page_number": 3,
            "languages": [
                "eng"
            ],
            "coordinates": [
                307.4403076171875,
                69.55011749267578,
                541.47265625,
                175.155517578125
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "9b705f1553570ade4b84bd8720389f50",
        "text": "4. Empirical Evaluation",
        "type": "Title",
        "metadata": {
            "source_doc": "reluICML.pdf",
            "page_number": 3,
            "languages": [
                "eng"
            ],
            "coordinates": [
                307.4403076171875,
                191.9320526123047,
                446.2536926269531,
                203.8871612548828
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "e224c88f4f9ada75446fe9388ee6f989",
        "text": "We empirically compare NReLUs to stochastic bi-\nnary hidden units2 on two vision tasks:\n1) object\nrecognition on the Jittered-Cluttered NORB dataset\n(LeCun et al., 2004), and 2) face veriﬁcation on the\nLabeled Faces in the Wild dataset (Huang et al.,\n2007). Both datasets contain complicated image vari-\nability that make them diﬃcult tasks. Also, they both\nalready have a number of published results for various\nmethods, which gives a convenient basis for judging\nhow good our results are. We use RBMs with binary\nhidden units or NReLUs to generatively pre-train one\nor more layers of features and we then discriminatively\nﬁne-tune the features using backpropagation. On both\ntasks NReLUs give better discriminative performance\nthan binary units. The discriminative models use the\ndeterministic version of NReLUs that implement the\nfunction y = max(0, x). For backpropagation, we take\nthe gradient of this function to be 0 when x ≤0 and 1\nwhen x > 0 (i.e. we ignore the discontinuity at x = 0).",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "reluICML.pdf",
            "page_number": 3,
            "languages": [
                "eng"
            ],
            "coordinates": [
                307.44000244140625,
                213.12689208984375,
                541.4852294921875,
                438.28857421875
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "fb05e00046ab7017625d4e05321b3500",
        "text": "5. Jittered-Cluttered NORB",
        "type": "Title",
        "metadata": {
            "source_doc": "reluICML.pdf",
            "page_number": 3,
            "languages": [
                "eng"
            ],
            "coordinates": [
                307.44061279296875,
                455.0655212402344,
                474.58831787109375,
                467.0205993652344
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "b4b1f98bfa83594a462c90fc287300b9",
        "text": "NORB is a synthetic 3D object recognition dataset\nthat contains ﬁve classes of toys (humans, animals,\ncars, planes, trucks) imaged by a stereo-pair cam-\nera system from diﬀerent viewpoints under diﬀerent\nlighting conditions. NORB comes in several versions\n– the Jittered-Cluttered version has grayscale stereo-\npair images with cluttered background and a central\nobject which is randomly jittered in position, size,\npixel intensity etc. There is also a distractor object\nplaced in the periphery. Examples from the dataset\nare shown in ﬁgure 2. For each class, there are ten\ndiﬀerent instances, ﬁve of which are in the training set\nand the rest in the test set. So at test time a clas-\nsiﬁer needs to recognize unseen instances of the same\nclasses. In addition to the ﬁve object classes, there is\na sixth class whose images contain none of the objects\nin the centre. For details see (LeCun et al., 2004).",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "reluICML.pdf",
            "page_number": 3,
            "languages": [
                "eng"
            ],
            "coordinates": [
                307.440185546875,
                476.25994873046875,
                541.4683837890625,
                677.5088500976562
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "12fbbbde31ed11440a462e03a085abfe",
        "text": "2We also compared with binomial units but they were\nno better than binary units, so we omit those results.",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "reluICML.pdf",
            "page_number": 3,
            "languages": [
                "eng"
            ],
            "coordinates": [
                307.44012451171875,
                685.8438720703125,
                541.4102783203125,
                706.3385009765625
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "e325509ed8dc7377d37e43657f553310",
        "text": "Truck\nCar\nPlane",
        "type": "Title",
        "metadata": {
            "source_doc": "reluICML.pdf",
            "page_number": 4,
            "languages": [
                "eng"
            ],
            "coordinates": [
                91.75270080566406,
                65.37277221679688,
                256.280029296875,
                72.10629272460938
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "15206df304f97f2f7ee3566d3cf1a618",
        "text": "Animal\nHuman\nNone",
        "type": "Title",
        "metadata": {
            "source_doc": "reluICML.pdf",
            "page_number": 4,
            "languages": [
                "eng"
            ],
            "coordinates": [
                90.091796875,
                112.09078979492188,
                255.87062072753906,
                118.82431030273438
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "bb2999c5b7b19bc2a02c602232294a6f",
        "text": "Figure 2. Stereo-pair training cases from the Jittered-\nCluttered NORB training set.",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "reluICML.pdf",
            "page_number": 4,
            "languages": [
                "eng"
            ],
            "coordinates": [
                55.44020080566406,
                153.4012908935547,
                289.4223937988281,
                173.4846954345703
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "f978843a91820de152e229d189033c4d",
        "text": "5.1. Training",
        "type": "Title",
        "metadata": {
            "source_doc": "reluICML.pdf",
            "page_number": 4,
            "languages": [
                "eng"
            ],
            "coordinates": [
                55.44020080566406,
                198.5037841796875,
                119.20659637451172,
                208.46641540527344
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "788e8a3c3612f401a05e2ed8c8e2ed07",
        "text": "The stereo-pair images are subsampled from their orig-\ninal resolution of 108 × 108 × 2 to 32 × 32 × 2 to speed\nup experiments. They are normalized to be zero-mean\nand divided by the average standard deviation of all\nthe pixels in all the training images. There are 291,600\ntraining cases (48,600 cases per class) and 58,320 test\ncases (9,720 cases per class). We hold out 58,320 cases\nfrom the training set and use them as a validation set\nfor selecting the model architecture (number of hid-\nden units and number of layers) and for early stop-\nping. The validation set is created by taking all 9,720\ntraining images of a single (randomly selected) object\ninstance from each of the ﬁve object classes, and an\nequal number of randomly selected images from the\n“None” class.",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "reluICML.pdf",
            "page_number": 4,
            "languages": [
                "eng"
            ],
            "coordinates": [
                55.439849853515625,
                217.42889404296875,
                289.4936218261719,
                394.7647399902344
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "f7d6441f4863934be0f9e97a1918a138",
        "text": "To train a classiﬁer we use a similar approach to\n(Larochelle et al., 2007).\nWe ﬁrst greedily pre-train\ntwo layers of features, each as an RBM using CD.\nThen we use multinomial regression at the top-most\nhidden layer to predict the label and discriminatively\nﬁne-tune the parameters in all layers of the classiﬁer\n(see ﬁgure 3).\nWe have tried 1000, 2000 and 4000\nunits for the ﬁrst hidden layer, and 1000 and 2000\nunits for the second one.\nUsing more units always\ngave better classiﬁcation results, so the architecture\nwith the best results have 4000 units in the ﬁrst layer\nand 2000 in the second. We suspect that the results\nwill be even better with more hidden units.\nIn all\ncases, the pixels are represented by Gaussian units\n(Hinton & Salakhutdinov, 2006) and the hidden units\nare either NReLUs or stochastic binary units.\nPre-\ntraining is done for 300 epochs (in both layers), using\nmini-batches of 100 training examples with a learn-\ning rate of 10−3 applied to the average per-case CD\nupdate, along with momentum (Hinton et al., 2006).",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "reluICML.pdf",
            "page_number": 4,
            "languages": [
                "eng"
            ],
            "coordinates": [
                55.439849853515625,
                402.7301940917969,
                289.47943115234375,
                639.84375
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "bd9fc3af7b633b992f6d914fc4ee12f4",
        "text": "Figure 4 shows a subset of features learned by the ﬁrst-\nlevel RBM with 4000 NReLUs in the hidden layer.\nMany of these are Gabor-like ﬁlters, so NReLUs seem\ncapable of learning qualitatively sensible features from\nimages. The classiﬁcation results (section 5.2) show\nthat they are quantitatively sensible as well. Figure 5",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "reluICML.pdf",
            "page_number": 4,
            "languages": [
                "eng"
            ],
            "coordinates": [
                55.44000244140625,
                647.8090209960938,
                289.4677429199219,
                717.5492553710938
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "9487c76aef8b9ffeb93cd5b109ba7aa5",
        "text": "Figure 3. Network\narchitecture\nused\nfor\nthe\nJittered-\nCluttered NORB classiﬁcation task. We greedily pre-train\ntwo hidden layers of NReLUs as RBMs. The class label is\nrepresented as a K-dimensional binary vector with 1-of-K\nactivation, where K is the number of classes. The classiﬁer\ncomputes the probability of the K classes from the second\nlayer hidden activities h2 using the softmax function.",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "reluICML.pdf",
            "page_number": 4,
            "languages": [
                "eng"
            ],
            "coordinates": [
                307.43896484375,
                179.09629821777344,
                541.4307250976562,
                254.9796905517578
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "ecf455e5f68aee9b1d822264b63ebba2",
        "text": "0.04",
        "type": "Title",
        "metadata": {
            "source_doc": "reluICML.pdf",
            "page_number": 4,
            "languages": [
                "eng"
            ],
            "coordinates": [
                324.6579895019531,
                272.7276306152344,
                333.4275207519531,
                278.91943359375
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "6fcc1a8d626f06f5f2497d40ebe383f4",
        "text": "0.035",
        "type": "Title",
        "metadata": {
            "source_doc": "reluICML.pdf",
            "page_number": 4,
            "languages": [
                "eng"
            ],
            "coordinates": [
                322.1610107421875,
                290.09661865234375,
                333.4361267089844,
                296.2884216308594
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "99da104921164448955761f869c8b85d",
        "text": "0.03",
        "type": "Title",
        "metadata": {
            "source_doc": "reluICML.pdf",
            "page_number": 4,
            "languages": [
                "eng"
            ],
            "coordinates": [
                324.6579895019531,
                307.4836120605469,
                333.4275207519531,
                313.6754150390625
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "b3ccae58265a68fc84afd5efa623257b",
        "text": "Fraction of hidden units of the RBM",
        "type": "Title",
        "metadata": {
            "source_doc": "reluICML.pdf",
            "page_number": 4,
            "languages": [
                "eng"
            ],
            "coordinates": [
                315.2696228027344,
                309.9852600097656,
                321.46142578125,
                380.6189880371094
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "1e31d8d237b1d8aa2984ec359cf577b5",
        "text": "0.025",
        "type": "Title",
        "metadata": {
            "source_doc": "reluICML.pdf",
            "page_number": 4,
            "languages": [
                "eng"
            ],
            "coordinates": [
                322.1610107421875,
                324.85162353515625,
                333.4361267089844,
                331.0434265136719
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "700ed1f5ab102b3c9cf9a6401835d161",
        "text": "0.02",
        "type": "Title",
        "metadata": {
            "source_doc": "reluICML.pdf",
            "page_number": 4,
            "languages": [
                "eng"
            ],
            "coordinates": [
                324.6579895019531,
                342.2396240234375,
                333.4275207519531,
                348.4314270019531
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "a3b3934f5274531b7145d03de53d5cd1",
        "text": "0.015",
        "type": "Title",
        "metadata": {
            "source_doc": "reluICML.pdf",
            "page_number": 4,
            "languages": [
                "eng"
            ],
            "coordinates": [
                322.1610107421875,
                359.6266174316406,
                333.4361267089844,
                365.81842041015625
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "b11653cd00987553b478098c10535f84",
        "text": "0.01",
        "type": "Title",
        "metadata": {
            "source_doc": "reluICML.pdf",
            "page_number": 4,
            "languages": [
                "eng"
            ],
            "coordinates": [
                324.6579895019531,
                376.9945983886719,
                333.4275207519531,
                383.1864013671875
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "c3caab29356275bf909ff9e3bee28687",
        "text": "0.005",
        "type": "Title",
        "metadata": {
            "source_doc": "reluICML.pdf",
            "page_number": 4,
            "languages": [
                "eng"
            ],
            "coordinates": [
                322.1610107421875,
                394.3825988769531,
                333.4361267089844,
                400.57440185546875
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "ec7b8f5843f9b3937cb544fb2c1d1585",
        "text": "0.1\n0.2\n0.3\n0.4\n0.5\n0.6\n0.7\n0.8\n0.9\n0",
        "type": "Title",
        "metadata": {
            "source_doc": "reluICML.pdf",
            "page_number": 4,
            "languages": [
                "eng"
            ],
            "coordinates": [
                330.92999267578125,
                411.7696228027344,
                516.1359252929688,
                421.11541748046875
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "d3c726e1638e104ef830b3b59fce4d9b",
        "text": "Fraction of training images on which a hidden unit is active\nFigure 5. Histogram of NReLUs binned according to how\noften they are “active” (i.e.\nhas a value above zero) on\ntraining images, as computed on Jittered-Cluttered NORB\nfor an RBM with 4000 NReLUs in the hidden layer.",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "reluICML.pdf",
            "page_number": 4,
            "languages": [
                "eng"
            ],
            "coordinates": [
                307.4389953613281,
                419.2615966796875,
                541.4295043945312,
                470.4578857421875
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "e683a9599180abac87e9f95ac5c26be5",
        "text": "is a histogram that shows how often the hidden units\nin this RBM have values above zero on the training\nset. If a unit is always “active”, then it would end up\nin the rightmost bin of the histogram. Note that an\nalways-active unit is purely linear since it never gets\nrectiﬁed. As the histgroam shows, there are no such\nunits in this model. There is some variety in how often\nthe units are active. We have looked at the features\nthat correspond to each of the three peaks in the his-\ntogram: the peak near 0.2 on the x-axis are Gabor-like\nﬁlters, while the peak near 0.6 are point ﬁlters. The\nsmaller peak between 0.4 and 0.5 corresponds mostly\nto more global ﬁlters.",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "reluICML.pdf",
            "page_number": 4,
            "languages": [
                "eng"
            ],
            "coordinates": [
                307.4388427734375,
                496.4290771484375,
                541.4749145507812,
                649.8516235351562
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "bac1251991b5e4f42fd817d9354a613b",
        "text": "5.2. Classiﬁcation Results",
        "type": "Title",
        "metadata": {
            "source_doc": "reluICML.pdf",
            "page_number": 4,
            "languages": [
                "eng"
            ],
            "coordinates": [
                307.43914794921875,
                664.757568359375,
                435.7851867675781,
                674.72021484375
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "170bceda3bd0357e3fc597fd9bae2a22",
        "text": "Table 1 lists the test set error rates of classiﬁers with a\nsingle hidden layer, using either binary units or NRe-\nLUs, with and without pre-training.\nNReLUs out-",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "reluICML.pdf",
            "page_number": 4,
            "languages": [
                "eng"
            ],
            "coordinates": [
                307.43914794921875,
                683.6737060546875,
                541.4815673828125,
                717.5498657226562
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "eae81d83bc64cab26a6424ceae8a2eeb",
        "text": "Figure 4. A subset of the features learned by an RBM on images from Jittered-Cluttered NORB. The RBM has 4000\nNReLUs in the hidden layer, and those shown are the 216 features with the highest L2 norm. Sorting by L2 norm tends\nto pick features with well-deﬁned Gabor-like weight patterns. Only about 25% of the features are Gabor-like. The rest\nconsist of ﬁlters with more global weight patterns, as well as “point” ﬁlters that copy pixels to the hidden units.",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "reluICML.pdf",
            "page_number": 5,
            "languages": [
                "eng"
            ],
            "coordinates": [
                55.439239501953125,
                234.2123260498047,
                541.4324951171875,
                276.2195129394531
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "0f761153447edcb807a6caa784169f26",
        "text": "perform binary units, both when randomly initialized\nand when pre-trained. Pre-training helps improve the\nperformance of both unit types. But NReLUs with-\nout pre-training are better than binary units with pre-\ntraining.",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "reluICML.pdf",
            "page_number": 5,
            "languages": [
                "eng"
            ],
            "coordinates": [
                55.43843078613281,
                298.14111328125,
                289.48248291015625,
                355.920654296875
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "f46fae7e7332da3c229301f98ab099d6",
        "text": "Table 2 lists the results for classiﬁers with two hidden\nlayers. Just as for single hidden layer classiﬁers, NRe-\nLUs outperform binary units regardless of whether\ngreedy pre-training is used only in the ﬁrst layer, in\nboth layers, or not at all. Pre-training improves the\nresults: pre-training only the ﬁrst layer and randomly\ninitializing the second layer is better than randomly\ninitialized both. Pre-training both layers gives further\nimprovement for NReLUs but not for binary units.",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "reluICML.pdf",
            "page_number": 5,
            "languages": [
                "eng"
            ],
            "coordinates": [
                55.43843078613281,
                363.89501953125,
                289.4935302734375,
                469.5003662109375
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "c80e82397d94939d801eed403493d2bc",
        "text": "For comparison, the error rates of some other mod-\nels are: multinomial regression on pixels 49.9%, Gaus-\nsian kernel SVM 43.3%, convolutional net 7.2%, con-\nvolutional net with an SVM at the top-most hid-\nden layer 5.9%.\nThe last three results are from\n(Bengio & LeCun, 2007). Our results are worse than\nthat of convolutional nets, but 1) our models use heav-\nily subsampled images, and 2) convolutional nets have\nknowledge of image topology and approximate trans-\nlation invariance hard-wired into their architecture.",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "reluICML.pdf",
            "page_number": 5,
            "languages": [
                "eng"
            ],
            "coordinates": [
                55.44020080566406,
                477.4658203125,
                289.47723388671875,
                595.0238647460938
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "cd5bd88e5e4ecef8d179db0a63652466",
        "text": "Table 1. Test error rates for classiﬁers with 4000 hidden\nunits trained on 32 × 32 × 2 Jittered-Cluttered NORB im-\nages.",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "reluICML.pdf",
            "page_number": 5,
            "languages": [
                "eng"
            ],
            "coordinates": [
                55.440765380859375,
                647.4297485351562,
                289.41839599609375,
                678.4751586914062
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "33dcab1717dee9cb9afeb9630031aab0",
        "text": "Pre-trained?\nNReLU\nBinary\nNo\n17.8%\n23.0%\nYes\n16.5%\n18.7%",
        "type": "Title",
        "metadata": {
            "source_doc": "reluICML.pdf",
            "page_number": 5,
            "languages": [
                "eng"
            ],
            "coordinates": [
                92.6636962890625,
                684.9805908203125,
                252.06134033203125,
                719.9254760742188
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "0fbdb448bbf35f299ba02f6c9ec1a9c4",
        "text": "Table 2. Test error rates for classiﬁers with two hidden lay-\ners (4000 units in the ﬁrst, 2000 in the second), trained on\n32 × 32 × 2 Jittered-Cluttered NORB images.",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "reluICML.pdf",
            "page_number": 5,
            "languages": [
                "eng"
            ],
            "coordinates": [
                307.44000244140625,
                304.95233154296875,
                541.4168090820312,
                335.997802734375
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "5ce5dcdf144ff77be227bf4f7f7feeb4",
        "text": "Layer 1\nLayer 2\nNReLU\nBinary\npre-trained?\npre-trained?\nNo\nNo\n17.6%\n23.6%\nYes\nNo\n16.5%\n18.8%\nYes\nYes\n15.2%\n18.8%",
        "type": "Title",
        "metadata": {
            "source_doc": "reluICML.pdf",
            "page_number": 5,
            "languages": [
                "eng"
            ],
            "coordinates": [
                313.4159851074219,
                352.7189025878906,
                535.7403564453125,
                411.9636535644531
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "2cb878b0b90019b120cc0c33144a00d8",
        "text": "6. Labeled Faces in the Wild",
        "type": "Title",
        "metadata": {
            "source_doc": "reluICML.pdf",
            "page_number": 5,
            "languages": [
                "eng"
            ],
            "coordinates": [
                307.44000244140625,
                436.2286071777344,
                476.4626770019531,
                448.1836853027344
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "45c2a2e272fe4b7f0340eefc5069904a",
        "text": "The prediction task for the Labeled Faces in the Wild\n(LFW) dataset is as follows: given two face images\nas input, predict whether the identities of the faces\nare the same or diﬀerent. The dataset contains colour\nfaces of public ﬁgures collected from the web using a\nfrontal-face detector. The bounding box computed by\nthe face detector is used to approximately normalize\nthe face’s position and scale within the image. Some\nexamples from the dataset are shown in ﬁgure 6. For\ndetails see (Huang et al., 2007).",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "reluICML.pdf",
            "page_number": 5,
            "languages": [
                "eng"
            ],
            "coordinates": [
                307.44000244140625,
                457.43231201171875,
                541.4790649414062,
                574.9896850585938
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "864ecc72ecf0b71c52a074161f4336fa",
        "text": "Same\nSame\nSame",
        "type": "Title",
        "metadata": {
            "source_doc": "reluICML.pdf",
            "page_number": 5,
            "languages": [
                "eng"
            ],
            "coordinates": [
                345.1239929199219,
                603.4592895507812,
                506.66937255859375,
                608.2532348632812
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "5ae443173b8cdc23ed1cfc4d775ccfe4",
        "text": "Different\nDifferent\nDifferent",
        "type": "Title",
        "metadata": {
            "source_doc": "reluICML.pdf",
            "page_number": 5,
            "languages": [
                "eng"
            ],
            "coordinates": [
                343.13299560546875,
                651.7962646484375,
                508.75006103515625,
                656.5902099609375
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "2d7fd59e5b39f6d77504137a74528555",
        "text": "Figure 6. Face-pair examples from the Labeled Faces in the\nWild dataset.",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "reluICML.pdf",
            "page_number": 5,
            "languages": [
                "eng"
            ],
            "coordinates": [
                307.44000244140625,
                697.2172241210938,
                541.4110717773438,
                717.3001708984375
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "09fc9b49c6ccd0f84cd7981d1c9c2df4",
        "text": "6.1. Network architecture",
        "type": "Title",
        "metadata": {
            "source_doc": "reluICML.pdf",
            "page_number": 6,
            "languages": [
                "eng"
            ],
            "coordinates": [
                55.44020080566406,
                69.28185272216797,
                183.8961639404297,
                79.24449157714844
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "02b03c880b0f12a366edccbacb46dc59",
        "text": "The task requires a binary classiﬁer with two sets of\ninputs (the two faces).\nIf we stitch the two inputs\ntogether and treat the result as one extended input\nvector, the classiﬁer’s output will depend on the order\nin which the inputs are stitched. To make the clas-\nsiﬁer symmetric with respect to the inputs, we use a\nsiamese architecture (Chopra et al., 2005). The idea is\nto learn a function that takes a single face as input and\ncomputes some feature vector from it. Given a pair of\nfaces, this function is applied to both faces separately,\nand the two corresponding feature vectors are com-\nbined using a ﬁxed, symmetric function into a single\nrepresentation which is invariant to input order. The\nprobability of the two faces being the same person is\ncomputed as output from this representation. The en-\ntire system, including the feature extractor replicated\nover the two faces, can be learned jointly.",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "reluICML.pdf",
            "page_number": 6,
            "languages": [
                "eng"
            ],
            "coordinates": [
                55.439697265625,
                87.96028137207031,
                289.4881896972656,
                289.4468688964844
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "64d21eb2dc5f044e4d3c613399799abb",
        "text": "Here we choose the feature extractor to be a fully-\nconnected feedforward layer of NReLUs, pre-trained\nas an RBM. We use cosine distance as the symmetric\nfunction that combines the two feature vectors. Co-\nsine distance is invariant to rescaling of its inputs,\nwhich when combined with the equivariance of NRe-\nLUs makes the entire model analytically invariant to\nrescaling of the pixels by a positive scalar.\nThe in-\nvariance holds regardless of the number of layers of\nNReLUs, so it is possible to train deep architectures\nwith this property. In order to make the feature ex-\ntractor exactly equivariant, we do not use biases into\nthe hidden units. Figure 7 shows the architecture of\nour face veriﬁcation model.",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "reluICML.pdf",
            "page_number": 6,
            "languages": [
                "eng"
            ],
            "coordinates": [
                55.44000244140625,
                297.42132568359375,
                289.464599609375,
                462.795654296875
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "2ad472c607f0a777fd3a8bc976700c08",
        "text": "6.2. Training",
        "type": "Title",
        "metadata": {
            "source_doc": "reluICML.pdf",
            "page_number": 6,
            "languages": [
                "eng"
            ],
            "coordinates": [
                55.44000244140625,
                477.7015686035156,
                119.2063980102539,
                487.6642150878906
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "5f4856fa0a0df511aaa462f197099744",
        "text": "LFW images are of size 250×250 (×3 colour channels)\nwith the face in the centre and a lot of background sur-\nrounding it. Recently it has been found that humans\nare able to get 94.27% accuracy on the LFW task even\nwhen the centre of the image is masked (Kumar et al.,\n2009). To prevent background information from arti-\nﬁcially inﬂating the results, we only use a 144 × 144\nwindow from the centre. The images are then rotated\nand scaled such that the coordinates of the eyes are the\nsame across all images. We further subsample this win-\ndow to 32×32 (×3 channels). The same image normal-\nization procedure used for Jittered-Cluttered NORB is\napplied here as well.",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "reluICML.pdf",
            "page_number": 6,
            "languages": [
                "eng"
            ],
            "coordinates": [
                55.44000244140625,
                496.61810302734375,
                289.4831237792969,
                650.0493774414062
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "0d18ac6c85f46262a98a059a72902d14",
        "text": "LFW contains 13,233 images of 5,749 people. For the\npurposes of reporting results, the designers of LFW\nhave pre-deﬁned 10 splits of the dataset for 10-fold\ncross validation, each containing 5,400 training pairs\nand 600 test pairs. The number of “same” and ”diﬀer-",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "reluICML.pdf",
            "page_number": 6,
            "languages": [
                "eng"
            ],
            "coordinates": [
                55.440025329589844,
                658.0148315429688,
                289.4790344238281,
                715.8032836914062
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "f0af538e251710c756879c820323fa2b",
        "text": "Figure 7. Siamese network used for the Labeled Faces in\nthe Wild task.\nThe feature extractor FW contains one\nhidden layer of NReLUs pre-trained as an RBM (on single\nfaces) with parameters W. FW is applied to the face im-\nages IA and IB, and the cosine distance d between the re-\nsulting feature vectors FW(IA) and FW(IB) is computed.\nThe probability of the two faces having the same identity\nis then computed as Pr(“Same”) =\n1\n1+exp(−(wd+b)) where\nw and b are scalar learnable parameters.",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "reluICML.pdf",
            "page_number": 6,
            "languages": [
                "eng"
            ],
            "coordinates": [
                307.4384460449219,
                233.19529724121094,
                541.4405517578125,
                329.9945373535156
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "e6a77c966dee02f5a4b7a7eefb72e2dc",
        "text": "ent” cases are always equal, both for training and test\nsets. The identities of the people in the training and\ntest sets are always kept disjoint, so at test time the\nmodel must predict on unseen identities. We ﬁrst pre-\ntrain a layer of features as an RBM using all 10,800\nsingle faces in the training set of each split, then plug\nit into the siamese architecture in ﬁgure 7 and discrim-\ninatively ﬁne-tune the parameters on pairs of faces. As\nbefore, during pre-training pixels are Gaussian units,\nand the hidden units are either NReLUs or stochastic\nbinary units.",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "reluICML.pdf",
            "page_number": 6,
            "languages": [
                "eng"
            ],
            "coordinates": [
                307.4389343261719,
                360.88916015625,
                541.4859619140625,
                490.40777587890625
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "e9f157f26d1c9f3e53cd4b9782d9a7cb",
        "text": "Figure 8 shows 100 of the 4000 features learned by\nan RBM on 32 × 32 colour images with NReLUs in\nthe hidden layer.\nLike the NORB model in section\n5.1, this model is also pre-trained for 300 epochs on\nmini-batches of size 100 with a learning rate of 10−3",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "reluICML.pdf",
            "page_number": 6,
            "languages": [
                "eng"
            ],
            "coordinates": [
                307.4389953613281,
                498.3730163574219,
                541.4502563476562,
                556.1526489257812
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "272b3961ae50f438bd1b12082fefce8d",
        "text": "and momentum. The model has learned detectors for\nparts of faces like eyes, nose, mouth, eye brows etc.\nSome features detect the boundary of the face. There\nis a mix of localized ﬁlters and more global ones that\ndetect more than just a single part of the face. The\nhistogram in ﬁgure 9 shows how often the units in\nthis RBM turn on for the faces in LFW. Unlike the\nNORB model, here the histogram has only one peak.\nIn particular, there are almost no point ﬁlters in this\nmodel.",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "reluICML.pdf",
            "page_number": 6,
            "languages": [
                "eng"
            ],
            "coordinates": [
                307.43896484375,
                558.1509399414062,
                541.4714965820312,
                675.7088623046875
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "84daab9e96868bdc67d272f2c8f68d93",
        "text": "During discriminative ﬁne-tuning, we use a subset of\nthe Pubﬁg face dataset (Kumar et al., 2009) as a vali-\ndation set for selecting the model architecture and for",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "reluICML.pdf",
            "page_number": 6,
            "languages": [
                "eng"
            ],
            "coordinates": [
                307.4389953613281,
                683.6738891601562,
                541.4593505859375,
                717.5496826171875
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "614d6b2299830840dcae14682f755a2e",
        "text": "Figure 8. A subset of the features learned by an RBM on\n32×32 colour images from LFW. The RBM has 4000 NRe-\nLUs in the hidden layer, and shown above are the 100 fea-\ntures with the highest L2 norm.",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "reluICML.pdf",
            "page_number": 7,
            "languages": [
                "eng"
            ],
            "coordinates": [
                55.44020080566406,
                281.3993225097656,
                289.4201965332031,
                324.396728515625
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "d821a67f16e8f046a0a0e4afd8bd73b2",
        "text": "0.12",
        "type": "Title",
        "metadata": {
            "source_doc": "reluICML.pdf",
            "page_number": 7,
            "languages": [
                "eng"
            ],
            "coordinates": [
                94.83319854736328,
                339.0801086425781,
                101.65393829345703,
                343.89599609375
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "652093bfbe639511c56c11552fb3b87d",
        "text": "0.1",
        "type": "Title",
        "metadata": {
            "source_doc": "reluICML.pdf",
            "page_number": 7,
            "languages": [
                "eng"
            ],
            "coordinates": [
                96.78980255126953,
                357.1011047363281,
                101.66175842285156,
                361.9169921875
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "40ea5ce0e5e199bb107e809991ced584",
        "text": "Fraction of hidden units of the RBM",
        "type": "Title",
        "metadata": {
            "source_doc": "reluICML.pdf",
            "page_number": 7,
            "languages": [
                "eng"
            ],
            "coordinates": [
                89.4731216430664,
                368.0574035644531,
                94.28899383544922,
                422.9949951171875
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "6af02f8c93ebc4fb3268ede0193b4964",
        "text": "0.08",
        "type": "Title",
        "metadata": {
            "source_doc": "reluICML.pdf",
            "page_number": 7,
            "languages": [
                "eng"
            ],
            "coordinates": [
                94.83319854736328,
                375.12310791015625,
                101.65393829345703,
                379.9389953613281
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "21924036eedc17ef8abd64a0b5f9b24e",
        "text": "0.06",
        "type": "Title",
        "metadata": {
            "source_doc": "reluICML.pdf",
            "page_number": 7,
            "languages": [
                "eng"
            ],
            "coordinates": [
                94.83319854736328,
                393.14410400390625,
                101.65393829345703,
                397.9599914550781
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "7ea7bbb1afedbc032a775b3420957963",
        "text": "0.04",
        "type": "Title",
        "metadata": {
            "source_doc": "reluICML.pdf",
            "page_number": 7,
            "languages": [
                "eng"
            ],
            "coordinates": [
                94.83319854736328,
                411.1661071777344,
                101.65393829345703,
                415.98199462890625
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "a84140d9bd7b1269a464da0a7ae2e0a9",
        "text": "0.02",
        "type": "Title",
        "metadata": {
            "source_doc": "reluICML.pdf",
            "page_number": 7,
            "languages": [
                "eng"
            ],
            "coordinates": [
                94.83319854736328,
                429.1871032714844,
                101.65393829345703,
                434.00299072265625
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "4e1418aa246d704c177dd8630210ec05",
        "text": "0.1\n0.2\n0.3\n0.4\n0.5\n0.6\n0.7\n0.8\n0.9\n0",
        "type": "Title",
        "metadata": {
            "source_doc": "reluICML.pdf",
            "page_number": 7,
            "languages": [
                "eng"
            ],
            "coordinates": [
                99.71089935302734,
                447.2231140136719,
                243.75994873046875,
                454.4930114746094
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "6a0a66526dd13259608ea363b11fa640",
        "text": "Fraction of training images on which a hidden unit is active\nFigure 9. Histogram of NReLUs binned according to how\noften they have a value above zero on single face images in\nLFW for an RBM with 4000 NReLUs in the hidden layer.",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "reluICML.pdf",
            "page_number": 7,
            "languages": [
                "eng"
            ],
            "coordinates": [
                55.44020080566406,
                453.05010986328125,
                289.4298095703125,
                490.7438049316406
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "45c748c9394af7b65b441e707f12dc60",
        "text": "early stopping. This subset, called the “development\nset” by the creators of Pubﬁg, do not contain any iden-\ntities that are in LFW.",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "reluICML.pdf",
            "page_number": 7,
            "languages": [
                "eng"
            ],
            "coordinates": [
                55.44020080566406,
                514.3661499023438,
                289.4803771972656,
                548.2327270507812
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "289f20f5783746d9c3f825fc5d33e8f0",
        "text": "6.3. Classiﬁcation Results",
        "type": "Title",
        "metadata": {
            "source_doc": "reluICML.pdf",
            "page_number": 7,
            "languages": [
                "eng"
            ],
            "coordinates": [
                55.44020080566406,
                563.138671875,
                183.78591918945312,
                573.101318359375
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "2a4e56e830632449754cb12b01eae532",
        "text": "As explained before, after pre-training a single layer\nof features as an RBM, we insert it into the siamese\narchitecture in ﬁgure 7 and discriminatively ﬁne-tune\nthe parameters. We have tried models with 1000, 2000,\n4000 and 8000 units in the hidden layer. The diﬀerence\nin accuracy is small between 4000 and 8000 units – all\nthe results in this section are for 4000 units.",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "reluICML.pdf",
            "page_number": 7,
            "languages": [
                "eng"
            ],
            "coordinates": [
                55.44020080566406,
                582.0552368164062,
                289.470458984375,
                663.7564697265625
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "000fbf3c1f162abac401f3c8c1263dd7",
        "text": "The rules of LFW specify that a model’s accuracy must\nbe computed using ten-fold cross validation using the\nten pre-speciﬁed splits of the dataset. To speed up ex-\nperiments, we merge two splits into one and perform",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "reluICML.pdf",
            "page_number": 7,
            "languages": [
                "eng"
            ],
            "coordinates": [
                55.44099426269531,
                671.721923828125,
                289.4693298339844,
                717.5494995117188
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "7e0517163680061161290fb35917e361",
        "text": "ﬁve-fold cross validation.\nTable 3 lists the average\naccuracy of various models, along with the standard\ndeviations. Models using NReLUs seem to be more\naccurate, but the standard deviations are too large to\ndraw ﬁrm conclusions.",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "reluICML.pdf",
            "page_number": 7,
            "languages": [
                "eng"
            ],
            "coordinates": [
                307.44000244140625,
                69.54987335205078,
                541.4617309570312,
                127.33843994140625
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "37c49e45a5a13b3a55d2a452fc0f6249",
        "text": "The two current best LFW results are 0.8683 ± 0.0034\n(Wolf et al., 2009), and 0.8529±0.0123 (Kumar et al.,\n2009). The former uses a commercial automatic face\nalignment system to normalize the faces, while the lat-\nter uses additional labels (collected manually) that de-\nscribe the face, such as ethnicity, sex, age etc. Such\nenhancements can be applied to our model as well,\nand they are likely to increase accuracy signiﬁcantly.\nThese results may also be beneﬁting from the back-\nground pixels around the face, which we have (mostly)\nremoved here.",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "reluICML.pdf",
            "page_number": 7,
            "languages": [
                "eng"
            ],
            "coordinates": [
                307.44000244140625,
                135.0850372314453,
                541.455810546875,
                264.82269287109375
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "5cad0a94789ffb822b30757142970de1",
        "text": "7. Mixtures of Exponentially Many\nLinear Models",
        "type": "Title",
        "metadata": {
            "source_doc": "reluICML.pdf",
            "page_number": 7,
            "languages": [
                "eng"
            ],
            "coordinates": [
                307.440185546875,
                281.59063720703125,
                514.718017578125,
                307.4957275390625
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "d68c67e59fbda4167ce2511d627f5966",
        "text": "We have shown that NReLUs work well for discrimina-\ntion, but they are also an interesting way of modeling\nthe density of real-valued, high-dimensional data. A\nstandard way to do this is to use a mixture of diag-\nonal Gaussians. Alternatively we can use a mixture\nof factor analysers. Both of these models are expo-\nnentially ineﬃcient if the data contains componential\nstructure. Consider, for example, images of pairs of\nindependent digits. If a mixture model for single digit\nimages needs N components, a single mixture model\nof pairs of digits needs N 2 components. Fortunately,\nthis exponential growth in the number of components\nin the mixture can be achieved with only linear growth\nin the number of latent variables and quadratic growth\nin the number of parameters if we use rectiﬁed linear\nhidden units.",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "reluICML.pdf",
            "page_number": 7,
            "languages": [
                "eng"
            ],
            "coordinates": [
                307.43988037109375,
                316.74407958984375,
                541.4800415039062,
                506.0322265625
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "8a6ba50db5c2c4ddd13ec0a245918dc0",
        "text": "Consider using rectiﬁed linear units with zero bias to\nmodel data that lies on the surface of a unit hyper-\nsphere.\nEach rectiﬁed linear unit corresponds to a\nplane through the centre of the hypersphere. It has\nan activity of 0 for one half of the hypersphere and\nfor the other half its activity increases linearly with\ndistance from that plane. N units can create 2N re-\ngions on the surface of the hypersphere3. As we move",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "reluICML.pdf",
            "page_number": 7,
            "languages": [
                "eng"
            ],
            "coordinates": [
                307.4395751953125,
                514.0066528320312,
                541.48974609375,
                607.6515502929688
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "188efff04ca5f45523f283ffcc691ee9",
        "text": "3Assuming the hypersphere is at least N-dimensional.",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "reluICML.pdf",
            "page_number": 7,
            "languages": [
                "eng"
            ],
            "coordinates": [
                319.87799072265625,
                615.0315551757812,
                537.4865112304688,
                625.9682006835938
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "f6729110fd2573cc07ea590af7316ecd",
        "text": "Table 3. Accuracy on the LFW task for various models\ntrained on 32 × 32 colour images.",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "reluICML.pdf",
            "page_number": 7,
            "languages": [
                "eng"
            ],
            "coordinates": [
                307.4398193359375,
                658.3910522460938,
                541.406494140625,
                678.4744262695312
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "2719f6e128ce326d13c07640d693a7d2",
        "text": "Pre-trained?\nNReLU\nBinary\nNo\n0.7925 ± 0.0173\n0.7768 ± 0.0070\nYes\n0.8073 ± 0.0134\n0.7777 ± 0.0109",
        "type": "Title",
        "metadata": {
            "source_doc": "reluICML.pdf",
            "page_number": 7,
            "languages": [
                "eng"
            ],
            "coordinates": [
                313.4880065917969,
                684.9805908203125,
                535.3660278320312,
                719.9254760742188
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "162f5ce6e3d55918913a724ac2d9f697",
        "text": "around within each of these regions the subset of units\nthat are non-zero does not change so we have a lin-\near model, but it is a diﬀerent linear model in every\nregion. The mixing proportions of the exponentially\nmany linear models are deﬁned implicitly by the same\nparameters as are used to deﬁne p(v|h) and, unlike\na directed model, the mixing proportions are hard to\ncompute explicitly (Nair & Hinton, 2008).",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "reluICML.pdf",
            "page_number": 8,
            "languages": [
                "eng"
            ],
            "coordinates": [
                55.440155029296875,
                69.54999542236328,
                289.4729309082031,
                163.20367431640625
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "9b4e8c46db9d223df4b1337ea34ebc03",
        "text": "This is a much better way of implementing an\nexponentially large mixture of linear models with\nshared latent variables than the method described in\n(Hinton et al., 1999) which uses directed linear models\nas the components of the mixture and a separate sig-\nmoid belief net to decide which hidden units should be\npart of the current linear model. In that model, it is\nhard to infer the values of the binary latent variables\nand there can be jumps in density at the boundary be-\ntween two linear regions. A big advantage of switch-\ning between linear models at the point where a hidden\nunit receives an input of exactly zero is that it avoids\ndiscontinuities in the modeled probability density.",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "reluICML.pdf",
            "page_number": 8,
            "languages": [
                "eng"
            ],
            "coordinates": [
                55.44000244140625,
                171.168701171875,
                289.4811096191406,
                324.5919189453125
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "365e8c1e0f22c3a0a47026bd72460b72",
        "text": "8. Summary",
        "type": "Title",
        "metadata": {
            "source_doc": "reluICML.pdf",
            "page_number": 8,
            "languages": [
                "eng"
            ],
            "coordinates": [
                55.4403076171875,
                341.36846923828125,
                126.87437438964844,
                353.32354736328125
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "2b94afe213cd7945d838c6690206175b",
        "text": "We showed how to create a more powerful type of hid-\nden unit for an RBM by tying the weights and biases\nof an inﬁnite set of binary units. We then approxi-\nmated these stepped sigmoid units with noisy rectiﬁed\nlinear units and showed that they work better than bi-\nnary hidden units for recognizing objects and compar-\ning faces. We also showed that they can deal with large\nintensity variations much more naturally than binary\nunits. Finally we showed that they implement mix-\ntures of undirected linear models (Marks & Movellan,\n2001) with a huge number of components using a mod-\nest number of parameters.",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "reluICML.pdf",
            "page_number": 8,
            "languages": [
                "eng"
            ],
            "coordinates": [
                55.44020080566406,
                362.5721740722656,
                289.4919128417969,
                504.04296875
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "7e161a51e6a5a91cfd278ab4e3f8c4c7",
        "text": "References",
        "type": "Title",
        "metadata": {
            "source_doc": "reluICML.pdf",
            "page_number": 8,
            "languages": [
                "eng"
            ],
            "coordinates": [
                55.44020080566406,
                520.8198852539062,
                118.36520385742188,
                532.7749633789062
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "d4d8748feff2e05fc6a7122885df821d",
        "text": "Bengio, Y. and LeCun, Y. Scaling learning algorithms to-\nwards AI. 2007.",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "reluICML.pdf",
            "page_number": 8,
            "languages": [
                "eng"
            ],
            "coordinates": [
                55.44020080566406,
                539.3322143554688,
                289.4017333984375,
                558.2618408203125
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "0e49d1941a175240f6e092f46199ed8b",
        "text": "Chopra, S., Hadsell, R., and LeCun, Y. Learning a sim-\nilarity metric discriminatively, with application to face\nveriﬁcation. In CVPR, pp. 539–546, Washington, DC,\nUSA, 2005. IEEE Computer Society.",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "reluICML.pdf",
            "page_number": 8,
            "languages": [
                "eng"
            ],
            "coordinates": [
                55.44020080566406,
                569.1314086914062,
                289.4176025390625,
                607.9778442382812
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "c21dd896e6b537663a5b5cdd188ced0e",
        "text": "Freund, Y. and Haussler, D. Unsupervised learning of dis-\ntributions on binary vectors using two layer networks.\nTechnical report, Santa Cruz, CA, USA, 1994.",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "reluICML.pdf",
            "page_number": 8,
            "languages": [
                "eng"
            ],
            "coordinates": [
                55.44019317626953,
                618.8473510742188,
                289.4059143066406,
                647.739501953125
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "40ae2ceed36878db295ae68e6a8223b7",
        "text": "Hahnloser, Richard H. R., Seung, H. Sebastian, and Slo-\ntine, Jean-Jacques. Permitted and forbidden sets in sym-\nmetric threshold-linear networks. Neural Computation,\n15(3):621–638, 2003. ISSN 0899-7667.",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "reluICML.pdf",
            "page_number": 8,
            "languages": [
                "eng"
            ],
            "coordinates": [
                55.44019317626953,
                658.6090698242188,
                289.4460144042969,
                697.4644775390625
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "2e32c9d75bc601fe47a5e39bfacfa6b0",
        "text": "Hinton, G. E. Training products of experts by minimiz-",
        "type": "Title",
        "metadata": {
            "source_doc": "reluICML.pdf",
            "page_number": 8,
            "languages": [
                "eng"
            ],
            "coordinates": [
                55.439697265625,
                708.3340454101562,
                289.3689270019531,
                717.3004150390625
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "bee80f4fd533fd21459d7b09300404c2",
        "text": "ing contrastive divergence. Neural Computation, 14(8):\n1711–1800, 2002.",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "reluICML.pdf",
            "page_number": 8,
            "languages": [
                "eng"
            ],
            "coordinates": [
                317.4010009765625,
                70.29033660888672,
                541.429443359375,
                89.22633361816406
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "cab98b4b2ccc43af300eec56930e09c1",
        "text": "Hinton, G. E. and Salakhutdinov, R. Reducing the dimen-\nsionality of data with neural networks.\nScience, 313:\n504–507, 2006.",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "reluICML.pdf",
            "page_number": 8,
            "languages": [
                "eng"
            ],
            "coordinates": [
                307.4381103515625,
                96.37018585205078,
                541.43017578125,
                125.26234436035156
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "ab7097b96d6bfaa204e9a3968cbd0b09",
        "text": "Hinton, G. E., Sallans, B., and Ghahramani, Z. A hierar-\nchical community of experts. pp. 479–494, 1999.",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "reluICML.pdf",
            "page_number": 8,
            "languages": [
                "eng"
            ],
            "coordinates": [
                307.4373779296875,
                132.39715576171875,
                541.3737182617188,
                151.32643127441406
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "0ad30ac3f6ad2a718c8bdfab2bbec87c",
        "text": "Hinton, G. E., Osindero, S., and Teh, Y. A fast learning\nalgorithm for deep belief nets. Neural Computation, 18:\n1527–1554, 2006.",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "reluICML.pdf",
            "page_number": 8,
            "languages": [
                "eng"
            ],
            "coordinates": [
                307.4373779296875,
                158.47027587890625,
                541.430908203125,
                187.36244201660156
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "69ccab46917e17fbd90ff1f59201d6c7",
        "text": "Huang, G. B., Ramesh, M., Berg, T., and Learned-Miller,\nE. Labeled Faces in the Wild: A Database for Study-\ning Face Recognition in Unconstrained Environments.\nTechnical Report 07-49, University of Massachusetts,\nAmherst, 2007.",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "reluICML.pdf",
            "page_number": 8,
            "languages": [
                "eng"
            ],
            "coordinates": [
                307.43792724609375,
                194.50628662109375,
                541.4609375,
                243.3152618408203
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "e78ce2ac59639471edcabfb56ed4fd13",
        "text": "Jarrett, K., Kavukcuoglu, K., Ranzato, M., and LeCun,\nY.\nWhat is the best multi-stage architecture for ob-\nject recognition? In Proc. International Conference on\nComputer Vision (ICCV’09). IEEE, 2009.",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "reluICML.pdf",
            "page_number": 8,
            "languages": [
                "eng"
            ],
            "coordinates": [
                307.43792724609375,
                250.4591064453125,
                541.4381103515625,
                289.3141784667969
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "c79e89f25d62e726955ab8358ddf69f9",
        "text": "Kumar, N., Berg, A. C., Belhumeur, P. N., and Nayar,\nS. K. Attribute and simile classiﬁers for face veriﬁcation.\nIn International Conference on Computer Vision, 2009.",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "reluICML.pdf",
            "page_number": 8,
            "languages": [
                "eng"
            ],
            "coordinates": [
                307.43780517578125,
                296.4579772949219,
                541.3838500976562,
                325.35015869140625
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "772739a3b52790b6daeb74b06e30b3c3",
        "text": "Larochelle, H., Erhan, D., Courville, A., Bergstra, J., and\nBengio., Y. An empirical evaluation of deep architec-\ntures on problems with many factors of variation.\nIn\nICML, pp. 473–480, 2007.",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "reluICML.pdf",
            "page_number": 8,
            "languages": [
                "eng"
            ],
            "coordinates": [
                307.43719482421875,
                332.48455810546875,
                541.4071655273438,
                371.3396301269531
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "e2edc42b13e9ffb04e7e1d5d1ce72256",
        "text": "LeCun, Y., Huang, F. J., and Bottou., L. Learning meth-\nods for generic object recognition with invariance to pose\nand lighting. In CVPR, Washington, D.C., 2004.",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "reluICML.pdf",
            "page_number": 8,
            "languages": [
                "eng"
            ],
            "coordinates": [
                307.437255859375,
                378.4834289550781,
                541.406982421875,
                407.3756103515625
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "8e8a32550258ac48cfef670c058cfd61",
        "text": "Marks, T. K. and Movellan, J. R. Diﬀusion networks, prod-\nucts of experts, and factor analysis.\nTechnical Report\nUCSD MPLab TR 2001.02, 2001.",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "reluICML.pdf",
            "page_number": 8,
            "languages": [
                "eng"
            ],
            "coordinates": [
                307.43756103515625,
                414.5104064941406,
                541.4474487304688,
                443.402587890625
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "bd045adbaaededd8194c1ee0237cfc67",
        "text": "Mohamed, A. and Hinton, G. E. Phone recognition using\nrestricted boltzmann machines. In ICASSP, Dallas, TX,\nUSA, 2010.",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "reluICML.pdf",
            "page_number": 8,
            "languages": [
                "eng"
            ],
            "coordinates": [
                307.43743896484375,
                450.54638671875,
                541.4146118164062,
                479.4385681152344
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "d3e6adfdade20d5628dc4d9923e701bc",
        "text": "Nair, V. and Hinton, G. E. Implicit mixtures of restricted\nboltzmann machines. In Neural information processing\nsystems, 2008.",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "reluICML.pdf",
            "page_number": 8,
            "languages": [
                "eng"
            ],
            "coordinates": [
                307.43731689453125,
                486.5823669433594,
                541.4584350585938,
                515.4744873046875
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "903c0ee654db3c65db1fc076b89a3aa7",
        "text": "Salakhutdinov, R. and Hinton, G. E. Replicated softmax:\nan undirected topic model. In Advances in Neural In-\nformation Processing Systems 22, 2009.",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "reluICML.pdf",
            "page_number": 8,
            "languages": [
                "eng"
            ],
            "coordinates": [
                307.4374084472656,
                522.6093139648438,
                541.431396484375,
                551.5018920898438
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "0ce89fc2647c1f145e9be401a9a1306c",
        "text": "Salakhutdinov, R., Mnih, A., and Hinton, G. E.\nRe-\nstricted Boltzmann machines for collaborative ﬁltering.\nIn Proceedings of the International Conference on Ma-\nchine Learning, volume 24, pp. 791–798, 2007.",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "reluICML.pdf",
            "page_number": 8,
            "languages": [
                "eng"
            ],
            "coordinates": [
                307.43829345703125,
                558.6453247070312,
                541.4363403320312,
                597.5003662109375
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "f84aced9c7ff4912c19fdf6a56425d6c",
        "text": "Taylor, G. W., Hinton, G. E., and Roweis, S. Modeling hu-\nman motion using binary latent variables. In Advances in\nNeural Information Processing Systems 19, Cambridge,\nMA, 2006. MIT Press.",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "reluICML.pdf",
            "page_number": 8,
            "languages": [
                "eng"
            ],
            "coordinates": [
                307.43829345703125,
                604.6351928710938,
                541.4353637695312,
                643.490234375
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "81c75be80bb49473494d7fbe665efa36",
        "text": "Teh, Y.W. and Hinton, G. E. Rate-coded restricted boltz-\nmann machines for face recognition. In Advances in Neu-\nral Information Processing Systems, volume 13, 2001.",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "reluICML.pdf",
            "page_number": 8,
            "languages": [
                "eng"
            ],
            "coordinates": [
                307.43829345703125,
                650.6340942382812,
                541.4312744140625,
                679.526611328125
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "de8436b235c85bb1f3ada3616f3bea95",
        "text": "Wolf, L., Hassner, T., and Taigman, Y. Similarity scores\nbased on background samples. In Asian Conference on\nComputer Vision, 2009.",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "reluICML.pdf",
            "page_number": 8,
            "languages": [
                "eng"
            ],
            "coordinates": [
                307.4382019042969,
                686.6700439453125,
                541.43896484375,
                715.5535888671875
            ],
            "is_full_width": false
        }
    }
]