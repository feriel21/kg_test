[
    {
        "element_id": "5480cea0bdc8135c4e7b24b4c6ed5da1",
        "text": "See discussions, stats, and author profiles for this publication at: https://www.researchgate.net/publication/224241106",
        "type": "Title",
        "metadata": {
            "source_doc": "sommer_11_ilastik.pdf",
            "page_number": 1,
            "languages": [
                "eng"
            ],
            "coordinates": [
                39.86970138549805,
                72.0516357421875,
                336.1473083496094,
                80.04115295410156
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "a7b12fdd0faa8674622470296e34d81d",
        "text": "Ilastik: Interactive learning and segmentation toolkit",
        "type": "Title",
        "metadata": {
            "source_doc": "sommer_11_ilastik.pdf",
            "page_number": 1,
            "languages": [
                "eng"
            ],
            "coordinates": [
                39.86970138549805,
                91.03842163085938,
                391.7065734863281,
                112.45281219482422
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "00955187c3b7caaf6fece7a0b3e69713",
        "text": "Conference Paper  in  Proceedings / IEEE International Symposium on Biomedical Imaging: from nano to macro. IEEE International Symposium on Biomedical Imaging · May 2011",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "sommer_11_ilastik.pdf",
            "page_number": 1,
            "languages": [
                "eng"
            ],
            "coordinates": [
                39.86970138549805,
                126.50065612792969,
                530.229248046875,
                135.51092529296875
            ],
            "is_full_width": true
        }
    },
    {
        "element_id": "9e55cdc652f08dc5e2a5cb9c1ea6ae89",
        "text": "DOI: 10.1109/ISBI.2011.5872394 · Source: IEEE Xplore",
        "type": "Title",
        "metadata": {
            "source_doc": "sommer_11_ilastik.pdf",
            "page_number": 1,
            "languages": [
                "eng"
            ],
            "coordinates": [
                39.86970138549805,
                138.43756103515625,
                141.7595977783203,
                144.65162658691406
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "f1423094aa6a476ed2723a2f8e087ce4",
        "text": "CITATIONS\n1,139",
        "type": "Title",
        "metadata": {
            "source_doc": "sommer_11_ilastik.pdf",
            "page_number": 1,
            "languages": [
                "eng"
            ],
            "coordinates": [
                39.86970138549805,
                170.3651123046875,
                63.66929626464844,
                189.11892700195312
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "9de70e7fd6a6f8ba68b95deece984838",
        "text": "READS\n8,019",
        "type": "Title",
        "metadata": {
            "source_doc": "sommer_11_ilastik.pdf",
            "page_number": 1,
            "languages": [
                "eng"
            ],
            "coordinates": [
                305.667724609375,
                170.3651123046875,
                323.5054016113281,
                189.11892700195312
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "330c0b2720cab863d41c6d0aa9baa476",
        "text": "4 authors, including:",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "sommer_11_ilastik.pdf",
            "page_number": 1,
            "languages": [
                "eng"
            ],
            "coordinates": [
                39.86970138549805,
                204.91107177734375,
                97.39005279541016,
                213.8596954345703
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "51ab4e05ff89e6d4bd5226cc9d92f8fd",
        "text": "Christoph Sommer",
        "type": "Title",
        "metadata": {
            "source_doc": "sommer_11_ilastik.pdf",
            "page_number": 1,
            "languages": [
                "eng"
            ],
            "coordinates": [
                66.44950866699219,
                222.92381286621094,
                118.77254486083984,
                231.80105590820312
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "81459163a0e951892de2a42bf8e5c8f3",
        "text": "Institute of Science and Technology Austria",
        "type": "Title",
        "metadata": {
            "source_doc": "sommer_11_ilastik.pdf",
            "page_number": 1,
            "languages": [
                "eng"
            ],
            "coordinates": [
                66.44950866699219,
                233.5557403564453,
                185.63516235351562,
                242.4329833984375
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "1c6f708b0039466069953d8c6deaae23",
        "text": "43 PUBLICATIONS   3,306 CITATIONS",
        "type": "Title",
        "metadata": {
            "source_doc": "sommer_11_ilastik.pdf",
            "page_number": 1,
            "languages": [
                "eng"
            ],
            "coordinates": [
                66.44950866699219,
                245.5166473388672,
                154.33770751953125,
                254.39389038085938
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "40b6e6ae6fd6a1ebda5502aa4070190e",
        "text": "SEE PROFILE",
        "type": "Title",
        "metadata": {
            "source_doc": "sommer_11_ilastik.pdf",
            "page_number": 1,
            "languages": [
                "eng"
            ],
            "coordinates": [
                73.75894927978516,
                262.72991943359375,
                102.3641357421875,
                269.83172607421875
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "c945a3074c747e22beb7cb1c45c1c85c",
        "text": "Ullrich Köthe",
        "type": "Title",
        "metadata": {
            "source_doc": "sommer_11_ilastik.pdf",
            "page_number": 1,
            "languages": [
                "eng"
            ],
            "coordinates": [
                66.44950866699219,
                286.05084228515625,
                102.59492492675781,
                294.9280700683594
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "57c0c569118a63cc51864b6c1c70f2a1",
        "text": "Heidelberg University",
        "type": "Title",
        "metadata": {
            "source_doc": "sommer_11_ilastik.pdf",
            "page_number": 1,
            "languages": [
                "eng"
            ],
            "coordinates": [
                66.44950866699219,
                296.6827697753906,
                126.21046447753906,
                305.55999755859375
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "5f80a9a719ef293f812f0a9b8a306d7d",
        "text": "171 PUBLICATIONS   7,448 CITATIONS",
        "type": "Title",
        "metadata": {
            "source_doc": "sommer_11_ilastik.pdf",
            "page_number": 1,
            "languages": [
                "eng"
            ],
            "coordinates": [
                66.44950866699219,
                308.6436767578125,
                157.40061950683594,
                317.5209045410156
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "11e396d61bd8f28d89f3109ef10d55bf",
        "text": "SEE PROFILE",
        "type": "Title",
        "metadata": {
            "source_doc": "sommer_11_ilastik.pdf",
            "page_number": 1,
            "languages": [
                "eng"
            ],
            "coordinates": [
                73.75894927978516,
                325.8569641113281,
                102.3641357421875,
                332.9587707519531
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "5a8f9a808f9caba64f0f176d6b42c384",
        "text": "Christoph Straehle",
        "type": "Title",
        "metadata": {
            "source_doc": "sommer_11_ilastik.pdf",
            "page_number": 1,
            "languages": [
                "eng"
            ],
            "coordinates": [
                332.9120178222656,
                222.92381286621094,
                384.6944274902344,
                231.80105590820312
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "17f1849c7d9eaed14357dbf04faa9dc9",
        "text": "Bosch",
        "type": "Title",
        "metadata": {
            "source_doc": "sommer_11_ilastik.pdf",
            "page_number": 1,
            "languages": [
                "eng"
            ],
            "coordinates": [
                332.9120178222656,
                233.5557403564453,
                349.8500061035156,
                242.4329833984375
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "047da2b8b0c85e04b00983c899c97210",
        "text": "26 PUBLICATIONS   4,173 CITATIONS",
        "type": "Title",
        "metadata": {
            "source_doc": "sommer_11_ilastik.pdf",
            "page_number": 1,
            "languages": [
                "eng"
            ],
            "coordinates": [
                332.9120178222656,
                245.5166473388672,
                420.80023193359375,
                254.39389038085938
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "5d4782bb056c38fc81c524b824f56632",
        "text": "SEE PROFILE",
        "type": "Title",
        "metadata": {
            "source_doc": "sommer_11_ilastik.pdf",
            "page_number": 1,
            "languages": [
                "eng"
            ],
            "coordinates": [
                340.2214660644531,
                262.72991943359375,
                368.82666015625,
                269.83172607421875
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "315ae25f1036d819b5ad1c1b72d7395f",
        "text": "ilastik: Interactive Learning and Segmentation\nToolkit",
        "type": "Title",
        "metadata": {
            "source_doc": "sommer_11_ilastik.pdf",
            "page_number": 2,
            "languages": [
                "eng"
            ],
            "coordinates": [
                145.01499938964844,
                163.16873168945312,
                466.3057861328125,
                202.30215454101562
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "b7372b20be20a530652c6d0e5b01ee61",
        "text": "Christoph Sommer, Christoph Straehle, Ullrich K¨othe, Fred A. Hamprecht",
        "type": "Title",
        "metadata": {
            "source_doc": "sommer_11_ilastik.pdf",
            "page_number": 2,
            "languages": [
                "eng"
            ],
            "coordinates": [
                151.3179931640625,
                218.07362365722656,
                534.015869140625,
                230.02882385253906
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "dc5ca9b6da82cc4558efa61a56071577",
        "text": "Heidelberg Collaboratory for Image Processing (HCI), University of Heidelberg",
        "type": "Title",
        "metadata": {
            "source_doc": "sommer_11_ilastik.pdf",
            "page_number": 2,
            "languages": [
                "eng"
            ],
            "coordinates": [
                139.74598693847656,
                240.52565002441406,
                545.6011352539062,
                252.48085021972656
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "f83b9c59e5a89ae6f8efc1194ef724cf",
        "text": "January 24, 2011",
        "type": "Title",
        "metadata": {
            "source_doc": "sommer_11_ilastik.pdf",
            "page_number": 2,
            "languages": [
                "eng"
            ],
            "coordinates": [
                261.9709777832031,
                263.8376770019531,
                349.3157958984375,
                275.7928771972656
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "a3054e822ed80cebe38cbf5da775b5af",
        "text": "Abstract",
        "type": "Title",
        "metadata": {
            "source_doc": "sommer_11_ilastik.pdf",
            "page_number": 2,
            "languages": [
                "eng"
            ],
            "coordinates": [
                285.3299865722656,
                302.03948974609375,
                325.91192626953125,
                311.0058898925781
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "7c23c728438301a9072a6318a82ba93e",
        "text": "Segmentation is the process of partitioning digital images into mean-\ningful regions. The analysis of biological high content images often re-\nquires segmentation as a ﬁrst step. We propose ilastik as an easy-to-use\ntool which allows the user without expertise in image processing to per-\nform segmentation and classiﬁcation in a uniﬁed way. ilastik learns from\nlabels provided by the user through a convenient mouse interface. Based\non these labels, ilastik infers a problem speciﬁc segmentation. A random\nforest classiﬁer is used in the learning step, in which each pixel’s neigh-\nborhood is characterized by a set of generic (nonlinear) features. ilastik\nsupports up to three spatial plus one spectral dimension and makes use\nof all dimensions in the feature calculation. ilastik provides realtime feed-\nback that enables the user to interactively reﬁne the segmentation result\nand hence further ﬁne-tune the classiﬁer. An uncertainty measure guides\nthe user to ambiguous regions in the images. Real time performance is\nachieved by multi-threading which fully exploits the capabilities of mod-\nern multi-core machines. Once a classiﬁer has been trained on a set of\nrepresentative images, it can be exported and used to automatically pro-\ncess a very large number of images (e.g. using the CellProﬁler pipeline).\nilastik is an open source project and released under the BSD license at\nwww.ilastik.org.",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "sommer_11_ilastik.pdf",
            "page_number": 2,
            "languages": [
                "eng"
            ],
            "coordinates": [
                158.67498779296875,
                317.656494140625,
                452.6441955566406,
                535.2723999023438
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "2707ce3d921cf04d8980dbd28f86e4f9",
        "text": "1\nIntroduction",
        "type": "Title",
        "metadata": {
            "source_doc": "sommer_11_ilastik.pdf",
            "page_number": 2,
            "languages": [
                "eng"
            ],
            "coordinates": [
                133.76800537109375,
                554.6167602539062,
                246.84471130371094,
                568.9630126953125
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "f8b9d769351d5c313d3e229bac8e0d7a",
        "text": "ilastik is a software that combines interactive machine learning, active learning,\nand the ability to cope with complex textures within a convenient and uniﬁed\nuser interface. The basic recipe behind ilastik consists of three parts: (1) Non-\nlinear image features provide a generic basis to represent diverse local image\ncharacteristics. (2) A state-of-the-art classiﬁer is used to learn from user input,\nwhich is given by a paint interface. The user can deﬁne an arbitrary number\nof classes (e.g. background, type one, type two, etc) (3) In the training phase,\nthe user can ﬁne-tune the classiﬁer by interactively providing new labels. To",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "sommer_11_ilastik.pdf",
            "page_number": 2,
            "languages": [
                "eng"
            ],
            "coordinates": [
                133.76797485351562,
                579.8627319335938,
                477.53765869140625,
                673.5123291015625
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "fff7bdce0cd0832fc763e24fe038d141",
        "text": "1",
        "type": "Title",
        "metadata": {
            "source_doc": "sommer_11_ilastik.pdf",
            "page_number": 2,
            "languages": [
                "eng"
            ],
            "coordinates": [
                303.13299560546875,
                694.8487548828125,
                308.1142883300781,
                704.8113403320312
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "e2cfd11966d27e64cb8484fea383d4d8",
        "text": "guide the user ilastik displays several overlays. The prediction by the classiﬁer\nindicates where the classiﬁer may still be wrong. Another overlay, called uncer-\ntainty map, highlights regions in which the prediction is the most ambiguous. It\nallows to actively guide the user to diﬃcult image regions, where the classiﬁer\ndeems new labels most informative. Once ilastik has been interactively trained\non a set of representative images, it can be used to automatically process a very\nlarge number of images in a batch processing mode or using the CellProﬁler [1]\npipeline.\nTo demonstrate ilastik, we present experimental results in section 3 that\ncorroborate ilastik’s performance and transferability to other segmentation and\nclassiﬁcation tasks.\nYet, neither problem-speciﬁc preprocessing nor special-\npurpose features are needed to achieve reliable results. ilastik also shows an\nexcellent run-time performance of the underlying algorithms (in 2D and 3D).\nAs an open source tool, ilastik is designed to be extensible without requiring a\ndetailed understanding of the aspects of the internal software architecture. The\nbasic ingredients of ilastik (features, classiﬁer) can easily be extended and ex-\nchanged (e.g. using diﬀerent classiﬁers). Whole new modules, which may oﬀer\ncustom functionality within ilastik can be integrated via a plug-in mechanism.",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "sommer_11_ilastik.pdf",
            "page_number": 3,
            "languages": [
                "eng"
            ],
            "coordinates": [
                133.76800537109375,
                126.97892761230469,
                477.52764892578125,
                340.17962646484375
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "09701829b0ba421fa1b821bc0d7ab639",
        "text": "1.1\nRelated Work",
        "type": "Title",
        "metadata": {
            "source_doc": "sommer_11_ilastik.pdf",
            "page_number": 3,
            "languages": [
                "eng"
            ],
            "coordinates": [
                133.76800537109375,
                356.5477600097656,
                246.29029846191406,
                368.5029602050781
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "0d61b9b1a73c91f2de2a2b5d0e923f7f",
        "text": "The majority of interactive segmentation approaches are based on user seeds\n[2, 3, 4, 5, 6, 7]. The seeds, provided by brush strokes, act as hard constraints\nfrom which the segmentation works outwards to ﬁll a desired region. Methods\nbased on graph cut [5, 8, 4] extend this idea by explicitly modeling a boundary\ncomponent. A segmentation is achieved by modeling the region and the bound-\nary term as a weighted combination and optimizing the minimal cut between\nforeground and background seeds. Usually, the region weights are inferred from\nthe respective seed pixels, while edge ﬁlters act as boundary weights. ilastik\ncan be used to learn the regional properties of objects or even to explicitly learn\nthe boundary weights between diﬀerent objects. This ﬂexibility may be a useful\ninput to seeded segmentation techniques.",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "sommer_11_ilastik.pdf",
            "page_number": 3,
            "languages": [
                "eng"
            ],
            "coordinates": [
                133.76800537109375,
                376.4940490722656,
                477.5474548339844,
                506.0085144042969
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "10ca91238ceb2f87fbbe1cdc203066b8",
        "text": "2\nMethods",
        "type": "Title",
        "metadata": {
            "source_doc": "sommer_11_ilastik.pdf",
            "page_number": 3,
            "languages": [
                "eng"
            ],
            "coordinates": [
                133.76800537109375,
                525.5659790039062,
                219.7591094970703,
                539.9122314453125
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "325cafa67876b5d50da0e9a43c9b6327",
        "text": "2.1\nFeature Computation",
        "type": "Title",
        "metadata": {
            "source_doc": "sommer_11_ilastik.pdf",
            "page_number": 3,
            "languages": [
                "eng"
            ],
            "coordinates": [
                133.76800537109375,
                551.2476196289062,
                290.81146240234375,
                563.2028198242188
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "b8ca01ae6fda69e2f09320178b980e96",
        "text": "The features are computed in the full 2D/3D pixel neighborhoods, depending\non the available data. While the provided set of features includes popular color,\nedge and texture descriptors, the plug-in functionality allows advanced users\nto add their own problem-speciﬁc features.\nThe standard features of ilastik\naccounting for a speciﬁc type of image structure are grouped together: Color\nand intensity consist of the raw intensity values of the image smoothed with a\nGaussian. Edge is deﬁned by including edge indicator functions such as the\neigenvalues of the structure tensor, eigenvalues of the Hessian matrix, gradient",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "sommer_11_ilastik.pdf",
            "page_number": 3,
            "languages": [
                "eng"
            ],
            "coordinates": [
                133.76800537109375,
                571.1949462890625,
                477.5374755859375,
                664.843505859375
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "ff586b9662b3d342d2fbb0477555b495",
        "text": "2",
        "type": "Title",
        "metadata": {
            "source_doc": "sommer_11_ilastik.pdf",
            "page_number": 3,
            "languages": [
                "eng"
            ],
            "coordinates": [
                303.13299560546875,
                694.8489379882812,
                308.1142883300781,
                704.8115234375
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "18e2bc5a733c598475e64672e0bfe623",
        "text": "magnitude, diﬀerence of Gaussians and Laplacian of Gaussian. Texture com-\nprises the eigenvalues of the structure tensor, eigenvalues of the Hessian matrix.\nOrientation comprises the raw structure tensor and Hessian matrix entries.\nAll these groups can be selected on 7 scales, with a total of 35 diﬀerent choices.\nThe user is free to combine these selections in order to generate an appropriate\nfeature set for the problem at hand.",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "sommer_11_ilastik.pdf",
            "page_number": 4,
            "languages": [
                "eng"
            ],
            "coordinates": [
                133.76800537109375,
                126.97892761230469,
                477.48773193359375,
                196.71759033203125
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "9868f605512ca93843658fec49a46219",
        "text": "Figure 1: The basic ilastik work ﬂow: (A) Initial labels, (B) live prediction\nmode showing interactive prediction, (C) a few more labels to correct for wrong\nclassiﬁcation due to illumination inhomogeneity, (D) updated classiﬁcation re-\nsult",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "sommer_11_ilastik.pdf",
            "page_number": 4,
            "languages": [
                "eng"
            ],
            "coordinates": [
                133.76797485351562,
                461.3949279785156,
                477.5274963378906,
                507.22247314453125
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "8546c68dd1accdf35fa975e86d4d8f62",
        "text": "In order to provide feedback to the user as to which features were important\nfor a speciﬁc classiﬁcation task, ilastik outputs a variable importance (mean\nGini decrease [9]). This refers to the process of selecting a subset of relevant\nfeatures from the entire set. In particular, for applications (e.g. dealing with\nmulti-spectral data) in which each variable has an associate interpretation the\ndetection of informative features can facilitate the imaging procedure [10].",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "sommer_11_ilastik.pdf",
            "page_number": 4,
            "languages": [
                "eng"
            ],
            "coordinates": [
                133.76797485351562,
                519.2328491210938,
                477.5374450683594,
                588.971435546875
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "08575c0bf59b5691dd8b6bafe58dbdeb",
        "text": "2.2\nClassiﬁcation and Active Learning",
        "type": "Title",
        "metadata": {
            "source_doc": "sommer_11_ilastik.pdf",
            "page_number": 4,
            "languages": [
                "eng"
            ],
            "coordinates": [
                133.76797485351562,
                605.340576171875,
                366.5357360839844,
                617.2957763671875
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "a61e2bfc0d480fd5e222e09a55b1af6b",
        "text": "The ability of the random forest to capture highly non-linear decision boundaries\nin feature space is a major prerequisite for the application to general sets of\nuse cases.\nThe classiﬁcation is performed using the random forest classiﬁer\nintroduced in [9]. Random forests consist of many decision trees. The individual",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "sommer_11_ilastik.pdf",
            "page_number": 4,
            "languages": [
                "eng"
            ],
            "coordinates": [
                133.76797485351562,
                625.2869262695312,
                477.54742431640625,
                671.115478515625
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "0e01c4df1d2442de14d6cd2a98d27b65",
        "text": "3",
        "type": "Title",
        "metadata": {
            "source_doc": "sommer_11_ilastik.pdf",
            "page_number": 4,
            "languages": [
                "eng"
            ],
            "coordinates": [
                303.1329650878906,
                694.848876953125,
                308.1142578125,
                704.8114624023438
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "1b7c2d7ef0a510659ff881f3720bb63d",
        "text": "trees are not pruned in the training phase and are built under random inﬂuence:\n(1) Each tree is built based on a bootstrap sample (bag) of the training data .\nThe out-of-bag samples are used to estimate of the real test error. (2) In each\nnode only a random subset of candidate features are evaluated to ﬁnd the best\nsplit according to the Gini impurity.\nDuring prediction, each pixel is classiﬁed by collecting the votes of each\nindividual tree. The ratio of the tree votes is interpreted as a posterior proba-\nbility and provides the basis of the segmentation step. ilastik defaults to train\nNT = 100 decision trees. Besides the prediction ilastik computes a uncertainty\nmap, which guides the user to ambiguous regions in the image. For this purpose,\nilastik implements the margin [9] of the classiﬁcation.",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "sommer_11_ilastik.pdf",
            "page_number": 5,
            "languages": [
                "eng"
            ],
            "coordinates": [
                133.76800537109375,
                126.97892761230469,
                477.55743408203125,
                256.49267578125
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "ba5bb4991a40e0db5b21439f41f8985a",
        "text": "2.3\nGraphical User Interface",
        "type": "Title",
        "metadata": {
            "source_doc": "sommer_11_ilastik.pdf",
            "page_number": 5,
            "languages": [
                "eng"
            ],
            "coordinates": [
                133.7680206298828,
                272.86181640625,
                309.9637145996094,
                284.8170166015625
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "56aa19bb3205fa7cbf4c659922933c3d",
        "text": "To illustrate the basic work ﬂow of ilastik1, we consider the problem of cell\nsegmentation.\nThe cell images consist of two channels.\nOne channel shows\nthe cell nuclei (red) while the other shows the cytoplasm (green). Some of the\ncell nuclei are of the mitosis phenotype (condensed nuclei, appearing yellow).\nTo discriminate these classes and the background one would use ilastik in the\nfollowing way: (0) Create new project and add the RGB images to it (1)\nCreate four label classes (background, nuclei, mitotic nuclei, cytoplasm), (2)\ngive some label strokes to indicate the four diﬀerent objects, (3) compute color\nfeatures, (4) switch to live prediction mode, (5) correct with more labels until\na satisfactory result is achieved. This process is illustrated in Figure 1.",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "sommer_11_ilastik.pdf",
            "page_number": 5,
            "languages": [
                "eng"
            ],
            "coordinates": [
                133.76800537109375,
                291.5289306640625,
                477.5076904296875,
                410.3675842285156
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "98a1b723ce2fcf51fd9c5bd470721ce5",
        "text": "3\nResults",
        "type": "Title",
        "metadata": {
            "source_doc": "sommer_11_ilastik.pdf",
            "page_number": 5,
            "languages": [
                "eng"
            ],
            "coordinates": [
                133.76800537109375,
                429.9250793457031,
                209.86026000976562,
                444.2712707519531
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "d614be71b531b85db34a2fde32bd5163",
        "text": "To evaluate the performance of ilastik, we show results on three biological data\nsets.\n3D neuron data: The ﬁrst data set (courtesy of Graham Knott, EPF\nLausanne) is a 3D-volume containing neurons, which include mitochondria and\nvesicles. One aim in preprocessing for automated neuron segmentation is to\ndistinguish between the four classes neuron interior (red), neuron boundary\n(green), mitochondria (yellow), and vesicles (blue).The high-resolution volume\nin Figure 2 shows a 3D sub-cube (1503 voxels) of the mammalian brain recorded\nwith the FIBS-technique (Focused Ion Beam). ilastik computes the image fea-\ntures in 3D and can thus beneﬁt from the isotropic resolution of the 3D volume.\nFigure 2 shows that after training with a few examples ilastik is able to predict\nother instances of the same kind (e.g. mitochondria in the upper left slice view).\nFundus images: The publicly available STARE database [11], consists of\n20 retinal images. The aim is to segment low-contrast blood vessels in retinal\nfundus images. Two observers manually segmented all images. Performance\nis estimated by taking the segmentation of the ﬁrst observer as ground truth.\nFor the sake of comparability, the evaluation procedure of Soares et al. [12]",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "sommer_11_ilastik.pdf",
            "page_number": 5,
            "languages": [
                "eng"
            ],
            "coordinates": [
                133.76797485351562,
                455.1719970703125,
                477.5474853515625,
                656.41650390625
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "a295a7e351a78f56ca685de7c02d8c36",
        "text": "1Also consider the tutorial videos on www.ilastik.org",
        "type": "Title",
        "metadata": {
            "source_doc": "sommer_11_ilastik.pdf",
            "page_number": 5,
            "languages": [
                "eng"
            ],
            "coordinates": [
                144.86000061035156,
                664.8773193359375,
                347.1847839355469,
                674.486083984375
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "ec13a82a8f82eb5679450da0b0d5f918",
        "text": "4",
        "type": "Title",
        "metadata": {
            "source_doc": "sommer_11_ilastik.pdf",
            "page_number": 5,
            "languages": [
                "eng"
            ],
            "coordinates": [
                303.13299560546875,
                694.8489379882812,
                308.1142883300781,
                704.8115234375
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "5211d5267ff34fdc59dfa7322c25af70",
        "text": "Figure 2: ilastik for 3D volumes: (top) initial labels in diﬀerent slices, (bottom)\nprediction after ﬁrst classiﬁcation round into four classes: neuron interior (red),\nneuron boundary (green), mitochondria (yellow) and vesicles (blue)",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "sommer_11_ilastik.pdf",
            "page_number": 6,
            "languages": [
                "eng"
            ],
            "coordinates": [
                133.76800537109375,
                268.4049072265625,
                477.5474853515625,
                302.2774658203125
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "1a93562c2cde7b520878ae98e00b2a8d",
        "text": "is adopted which includes leave-one-image-out cross-validation and ROC-curve\nanalysis. We labeled the 20 images from the STARE database in approximately\n1h, resulting in an average of 0.84% of foreground and 11% background coverage.\nEvery image was segmented using the user labels from the other 19 images of\nthe training set. Performance, however, was computed against the ground truth\nsegmentation. The segmentation was produced by thresholding the smoothed\nprobability map. The smoothing with a Gaussian ﬁlter (σ = 1) was used to re-\nduce spurious vessel detections. The results were compared to the matched ﬁlter\nresults from Chaudhuri et al. [13], 2-D Gabor wavelets from Soares et al. [12],\nadaptive local thresholding scheme from Jiang et al. [14], and the ridge-based\nsegmentation proposed by Staal et al. [15]. Performance was measured using\nROC curves (see Figure 3). Results indicate that ilastik achieves competitive\nperformance without a problem-speciﬁc development eﬀort.\nCell counting: Identiﬁcation and segmentation of cells and their phenotype\nis a standard task in biological image processing. Especially in high-throughput\nexperiments, it facilitates the study of many normal, neoplastic and replication\nprocesses. A main discipline in that area is the counting of cells with a partic-\nular phenotype of interest. We use the Human HT29 Colon Cancer 1 image\nset [16] published in the Broad Bioimage Benchmark Collection. Some of the\ncells are mitotic and appear slightly brighter.\nThe background and the two\ndiﬀerent types of cell nuclei types were marked by a user in about 5 minutes,\nresulting in 5.12% background and 0.37% cell nuclei (normal and mitotic) la-\nbel coverage. Once again leave-one-image-out cross-validation was performed.\nThe probability maps from the supervised classiﬁcation were fed into a modiﬁed\nmarker-based watershed transform (not yet part of ilastik). Seeds for the three\ndiﬀerent classes are generated by smoothing (σ = 1) and thresholding (t = 0.5)\neach probability map. The actual watershed transform is computed on the gra-\ndient of the background probability. The ground truth for this data set is the\ntotal cell count of two observers for each image. The average absolute deviation",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "sommer_11_ilastik.pdf",
            "page_number": 6,
            "languages": [
                "eng"
            ],
            "coordinates": [
                133.76795959472656,
                324.6938781738281,
                477.56732177734375,
                669.4012451171875
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "66e9b21eea6819f29b7223484817f534",
        "text": "5",
        "type": "Title",
        "metadata": {
            "source_doc": "sommer_11_ilastik.pdf",
            "page_number": 6,
            "languages": [
                "eng"
            ],
            "coordinates": [
                303.13299560546875,
                694.8486938476562,
                308.1142883300781,
                704.811279296875
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "482a2de46fced2c553977e3723fada1b",
        "text": "from the mean count of the two observers is 10.47% while the two human ob-\nservers vary by 11% for this image set. The average cell count of the algorithm\nis slightly higher than the two human counts due to over-segmentation. While\nthe human observers merely counted all cells in this data set, ilastik predicts\neach cell to be mitotic or not.",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "sommer_11_ilastik.pdf",
            "page_number": 7,
            "languages": [
                "eng"
            ],
            "coordinates": [
                133.76800537109375,
                126.97892761230469,
                477.517578125,
                184.7615966796875
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "9ecb0a0a3070b85c0c2135be5814dae4",
        "text": "Method\nAz\nAccuracy\nSoares et al. [12]\n0.967\n0.948\nChaudhuri et al. [13]\n0.899\n−\nJiang et al. [14]\n0.930\n0.901\nStaal et al. [15]\n0.964\n0.952\nour results\n0.945\n0.959",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "sommer_11_ilastik.pdf",
            "page_number": 7,
            "languages": [
                "eng"
            ],
            "coordinates": [
                226.9219970703125,
                349.05511474609375,
                384.3182373046875,
                408.33221435546875
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "8c81b7e11a03f30eb3bb66525932f86c",
        "text": "Figure 3:\nROC analysis for fundus images after leave-one-image-out cross-\nvalidation",
        "type": "Title",
        "metadata": {
            "source_doc": "sommer_11_ilastik.pdf",
            "page_number": 7,
            "languages": [
                "eng"
            ],
            "coordinates": [
                133.76800537109375,
                419.9209289550781,
                477.4775695800781,
                441.8385009765625
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "323a15d646f84ffd780795a818f9f53c",
        "text": "Outlook: ilastik is released in version 0.5 and available at www.ilastik.\norg. Future versions are already in the making and will include: (1) seeded\nsegmentation algorithms such as watershed (2) unsupervised dimension reduc-\ntion techniques (e.g. PCA, PLSA) to help condense information from image\nfeatures and multi-spectral images. (3) Hierarchical processing by allowing sub-\nsequent analyses on top of intermediate results (e.g. interactive learning inside\na previously learned mask).",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "sommer_11_ilastik.pdf",
            "page_number": 7,
            "languages": [
                "eng"
            ],
            "coordinates": [
                133.76800537109375,
                455.0809020996094,
                477.5274353027344,
                536.7744140625
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "572bfda9e2ffd8734d8b747cd5b6d510",
        "text": "4\nConclusion",
        "type": "Title",
        "metadata": {
            "source_doc": "sommer_11_ilastik.pdf",
            "page_number": 7,
            "languages": [
                "eng"
            ],
            "coordinates": [
                133.76800537109375,
                556.02783203125,
                235.22430419921875,
                570.3740844726562
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "531eabf13b0f926ff9de81a500bc786a",
        "text": "In this paper we proposed ilastik to tackle standard image processing tasks\n(2D and 3D) in the ﬁeld of biomedical image processing without resorting to\nprogramming expertise. ilastik combines a user friendly interface with a set\nof state-of-the-art algorithms. The approach is robust and work across many\ntypes of images and volumes. The segmentation framework is extended in a\nmulti-class sense to allow for diﬀerent object types and problems.\nilastik is limited to local cues such as brightness, color and texture and is\nnot designed to capture global conﬁgurations. For many standard problems,",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "sommer_11_ilastik.pdf",
            "page_number": 7,
            "languages": [
                "eng"
            ],
            "coordinates": [
                133.76800537109375,
                581.2748413085938,
                477.5374450683594,
                674.9234008789062
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "4275ad2c73efc3fcb6493d85522a0011",
        "text": "6",
        "type": "Title",
        "metadata": {
            "source_doc": "sommer_11_ilastik.pdf",
            "page_number": 7,
            "languages": [
                "eng"
            ],
            "coordinates": [
                303.13299560546875,
                694.8488159179688,
                308.1142883300781,
                704.8114013671875
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "67629292b5ae377ef234e267eb48a468",
        "text": "however, ilastik yields results of surprisingly good quality and hence allows to\nsolve problems that previously would have required hand-tailored algorithms.\nWe release ilastik under the open source BSD license to endorse the idea of\nfree software. It can be used and extended without any restrictions. We expect\nilastik to be a useful tool in many applications in the ﬁeld of biomedical image\nprocessing and invite developers to contribute in a collaborative setting.",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "sommer_11_ilastik.pdf",
            "page_number": 8,
            "languages": [
                "eng"
            ],
            "coordinates": [
                133.76800537109375,
                126.97892761230469,
                477.5276184082031,
                196.71759033203125
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "4c7c9dc695f39c308fd6699262a27026",
        "text": "References",
        "type": "Title",
        "metadata": {
            "source_doc": "sommer_11_ilastik.pdf",
            "page_number": 8,
            "languages": [
                "eng"
            ],
            "coordinates": [
                133.76800537109375,
                214.77310180664062,
                209.2864227294922,
                229.11929321289062
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "3940c1627830a08a355af43f06475ca6",
        "text": "[1] A. E. Carpenter, T. R. Jones, M. R. Lamprecht, C. Clarke, I. H. Kang, O. Friman,\nD. A. Guertin, J. H. Chang, R. A. Lindquist, J. Moﬀat, P. Golland, and D. M.\nSabatini, “CellProﬁler: image analysis software for identifying and quantifying\ncell phenotypes,” Genome Biol., vol. 7, pp. R100, 2006.",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "sommer_11_ilastik.pdf",
            "page_number": 8,
            "languages": [
                "eng"
            ],
            "coordinates": [
                138.37600708007812,
                238.8155975341797,
                477.5881042480469,
                280.658935546875
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "05bde84cd0d88219a008e4e1cc7a16f6",
        "text": "[2] R. Adams and L. Bischof,\n“Seeded region growing,”\nIEEE Transactions on\nPattern Analysis and Machine Intelligence, vol. 16, pp. 641–647, 1994.",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "sommer_11_ilastik.pdf",
            "page_number": 8,
            "languages": [
                "eng"
            ],
            "coordinates": [
                138.37600708007812,
                286.63653564453125,
                477.4905700683594,
                306.56195068359375
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "fde617b1382d72c223b03093b3760246",
        "text": "[3] L. Grady,\n“Random walks for image segmentation,”\nIEEE Transactions on\nPattern Analysis and Machine Intelligence, pp. 1768–1783, 2006.",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "sommer_11_ilastik.pdf",
            "page_number": 8,
            "languages": [
                "eng"
            ],
            "coordinates": [
                138.3760223388672,
                312.53955078125,
                477.4849853515625,
                332.4649658203125
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "c1952ae894fcdf879ebfe855fa5c7bd1",
        "text": "[4] C. Rother, V. Kolmogorov, and A. Blake,\n“Grabcut: Interactive foreground\nextraction using iterated graph cuts,” ACM Trans. Graph., vol. 23, no. 3, pp.\n309–314, 2004.",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "sommer_11_ilastik.pdf",
            "page_number": 8,
            "languages": [
                "eng"
            ],
            "coordinates": [
                138.3760223388672,
                338.44256591796875,
                477.5570983886719,
                369.32598876953125
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "d4789f22eba2324797190857c6849ab0",
        "text": "[5] Y. Boykov and M.-P. Jolly, “Interactive graph cuts for optimal boundary and\nregion segmentation of objects in n-d images,” ICCV’01, vol. 1, pp. 105–112,\n2001.",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "sommer_11_ilastik.pdf",
            "page_number": 8,
            "languages": [
                "eng"
            ],
            "coordinates": [
                138.3760223388672,
                375.3035888671875,
                477.5391540527344,
                406.18798828125
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "c83dccf3438fb60fbc76375c493c6271",
        "text": "[6] G. Friedland, K. Jantz, and R. Rojas, “SIOX: Simple interactive object extraction\nin still images,” in Seventh IEEE International Symposium on Multimedia, 2005.",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "sommer_11_ilastik.pdf",
            "page_number": 8,
            "languages": [
                "eng"
            ],
            "coordinates": [
                138.37603759765625,
                412.16558837890625,
                477.58404541015625,
                432.09100341796875
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "ab42a0498b03fa890f0c097c1af6c500",
        "text": "[7] X. Bai and G. Sapiro, “A geodesic framework for fast interactive image and video\nsegmentation and matting,” in IEEE 11th International Conference on Computer\nVision, 2007, pp. 1–8.",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "sommer_11_ilastik.pdf",
            "page_number": 8,
            "languages": [
                "eng"
            ],
            "coordinates": [
                138.37603759765625,
                438.068603515625,
                477.5481872558594,
                468.9530029296875
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "8fa2d8c76552e392324ea1444935eb7a",
        "text": "[8] B.L. Price, B. Morse, and S. Cohen, “Geodesic graph cut for interactive image\nsegmentation,” in Computer Vision and Pattern Recognition (CVPR), 2010 IEEE\nConference on. IEEE, 2010, pp. 3161–3168.",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "sommer_11_ilastik.pdf",
            "page_number": 8,
            "languages": [
                "eng"
            ],
            "coordinates": [
                138.3760223388672,
                474.93060302734375,
                477.54803466796875,
                505.81500244140625
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "1e267fe23900014d38719b8c97b47213",
        "text": "[9] L. Breiman, “Random forests,” Machine Learning, vol. 45, pp. 5–32, 2001.",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "sommer_11_ilastik.pdf",
            "page_number": 8,
            "languages": [
                "eng"
            ],
            "coordinates": [
                138.37603759765625,
                511.7915954589844,
                455.4746398925781,
                520.7579956054688
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "ce62f1ac469b982363b0bbac4849b961",
        "text": "[10] M. Jehle, C. Sommer, and B. J¨ahne, “Learning of optimal illumination for ma-\nterial classiﬁcation,” in Pattern Recognition. 2010, pp. 563–572, Springer.",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "sommer_11_ilastik.pdf",
            "page_number": 8,
            "languages": [
                "eng"
            ],
            "coordinates": [
                133.76803588867188,
                526.7356567382812,
                477.584716796875,
                546.6610107421875
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "56628b63f164070cb7318a88c089b13c",
        "text": "[11] A. Hoover, V. Kouznetsova, and M. Goldbaum, “Locating blood vessels in retinal\nimages by piece-wise threshold probing of a matched ﬁlter response,” IEEE Trans.\non Medical Imaging, vol. 19, no. 3, pp. 203–210, 2000.",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "sommer_11_ilastik.pdf",
            "page_number": 8,
            "languages": [
                "eng"
            ],
            "coordinates": [
                133.76803588867188,
                552.6386108398438,
                477.5489501953125,
                583.5230102539062
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "d45269663923ba3f34e4b2a476ee410a",
        "text": "[12] B Soares, G. Leandro, M. Cesar, F. Jelinek, and J. Cree, “Retinal vessel segmen-\ntation using the 2-d gabor wavelet and supervised classiﬁcation,” IEEE Trans.\non Medical Imaging, vol. 25, no. 9, pp. 1214–1222, 2006.",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "sommer_11_ilastik.pdf",
            "page_number": 8,
            "languages": [
                "eng"
            ],
            "coordinates": [
                133.76800537109375,
                589.5006103515625,
                477.5309143066406,
                620.385009765625
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "2259077326ba4c294ec0bae5c7415b26",
        "text": "[13] S. Chaudhuri, S. Chatterjee, N. Katz, M. Nelson, and M. Goldbaum, “Detection\nof blood vessels in retinal images using two-dimensional matched ﬁlters,” IEEE\nTrans. on Medical Imaging, vol. 8, no. 3, pp. 263–269, 1989.",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "sommer_11_ilastik.pdf",
            "page_number": 8,
            "languages": [
                "eng"
            ],
            "coordinates": [
                133.76800537109375,
                626.3626098632812,
                477.5757751464844,
                657.2470092773438
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "bf64fc5c2af7b4b582d15568e4bc0bbc",
        "text": "7",
        "type": "Title",
        "metadata": {
            "source_doc": "sommer_11_ilastik.pdf",
            "page_number": 8,
            "languages": [
                "eng"
            ],
            "coordinates": [
                303.13299560546875,
                694.8490600585938,
                308.1142883300781,
                704.8116455078125
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "951c924d350ecbe784898c288d1d99bd",
        "text": "[14] X Jiang and D. Mojon, “Adaptive local thresholding by veriﬁcation-based multi\nthreshold probing with application to vessel detection in retinal images,” IEEE\nTrans. on Pattern Analysis and Machine Intelligence, vol. 25, no. 1, pp. 131–137,\n2003.",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "sommer_11_ilastik.pdf",
            "page_number": 9,
            "languages": [
                "eng"
            ],
            "coordinates": [
                133.76800537109375,
                127.75749206542969,
                477.5577697753906,
                169.59986877441406
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "fc81d647027cc71af6cb64d21f7a0771",
        "text": "[15] J. Staal, M. D. Abramoﬀ, M. Niemeijer, M. A. Viergever, and B. van Ginneken,\n“Ridge-based vessel segmentation in color images of the retina,” IEEE Trans. on\nMedical Imaging, vol. 23, no. 4, pp. 501–509, 2004.",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "sommer_11_ilastik.pdf",
            "page_number": 9,
            "languages": [
                "eng"
            ],
            "coordinates": [
                133.7680206298828,
                175.5774383544922,
                477.57574462890625,
                206.46180725097656
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "9fe4fff191af139f9832845f48d0e639",
        "text": "[16] J. Moﬀat and et al.,\n“A lentiviral RNAi library for human and mouse genes\napplied to an arrayed viral high-content screen,” Cell, vol. 124, no. 6, pp. 1283–\n1298, 2006.",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "sommer_11_ilastik.pdf",
            "page_number": 9,
            "languages": [
                "eng"
            ],
            "coordinates": [
                133.7680206298828,
                212.4393768310547,
                477.5577087402344,
                243.32374572753906
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "db3411f4dfb659ed9e9a0bfcda7f53e8",
        "text": "8",
        "type": "Title",
        "metadata": {
            "source_doc": "sommer_11_ilastik.pdf",
            "page_number": 9,
            "languages": [
                "eng"
            ],
            "coordinates": [
                303.133056640625,
                694.8488159179688,
                308.1143493652344,
                704.8114013671875
            ],
            "is_full_width": false
        }
    }
]