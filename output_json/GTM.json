[
    {
        "element_id": "0a47d87299ee4e74573b5fe120ebe3ea",
        "text": "See discussions, stats, and author profiles for this publication at: https://www.researchgate.net/publication/224881745",
        "type": "Title",
        "metadata": {
            "source_doc": "GTM.pdf",
            "page_number": 1,
            "languages": [
                "eng"
            ],
            "coordinates": [
                39.86970138549805,
                72.0516357421875,
                336.1473083496094,
                80.04115295410156
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "5ab2ff36ad2409aa58302b2ca7496366",
        "text": "GTM: The Generative Topographic Mapping",
        "type": "Title",
        "metadata": {
            "source_doc": "GTM.pdf",
            "page_number": 1,
            "languages": [
                "eng"
            ],
            "coordinates": [
                39.86970138549805,
                91.03842163085938,
                326.35205078125,
                112.45281219482422
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "349fa53bf76fed5883ab47135732d40e",
        "text": "Article  in  Neural Computation · January 1998",
        "type": "Title",
        "metadata": {
            "source_doc": "GTM.pdf",
            "page_number": 1,
            "languages": [
                "eng"
            ],
            "coordinates": [
                39.86970138549805,
                126.50065612792969,
                167.11056518554688,
                135.51092529296875
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "57f0262526dfd5b9289f2b426bd63237",
        "text": "DOI: 10.1162/089976698300017953 · Source: OAI",
        "type": "Title",
        "metadata": {
            "source_doc": "GTM.pdf",
            "page_number": 1,
            "languages": [
                "eng"
            ],
            "coordinates": [
                39.86970138549805,
                138.43756103515625,
                132.6953125,
                144.65162658691406
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "f2f4e892a67b64541cd3f6a18a007ad7",
        "text": "CITATIONS\n1,437",
        "type": "Title",
        "metadata": {
            "source_doc": "GTM.pdf",
            "page_number": 1,
            "languages": [
                "eng"
            ],
            "coordinates": [
                39.86970138549805,
                170.3651123046875,
                63.66929626464844,
                189.11892700195312
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "a9a24c1805908d72a8d40403ce084f98",
        "text": "READS\n1,799",
        "type": "Title",
        "metadata": {
            "source_doc": "GTM.pdf",
            "page_number": 1,
            "languages": [
                "eng"
            ],
            "coordinates": [
                305.667724609375,
                170.3651123046875,
                323.5054016113281,
                189.11892700195312
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "4743571a928f10081ebfb1513be4f815",
        "text": "3 authors, including:",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "GTM.pdf",
            "page_number": 1,
            "languages": [
                "eng"
            ],
            "coordinates": [
                39.86970138549805,
                204.91107177734375,
                97.39005279541016,
                213.8596954345703
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "4f285f2876ce779ccef386aa977f45c8",
        "text": "Markus Svensen",
        "type": "Title",
        "metadata": {
            "source_doc": "GTM.pdf",
            "page_number": 1,
            "languages": [
                "eng"
            ],
            "coordinates": [
                66.44950866699219,
                222.92381286621094,
                111.180419921875,
                231.80105590820312
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "7b6e032f7f236f37dff5fe8e3d071ee0",
        "text": "General Electric",
        "type": "Title",
        "metadata": {
            "source_doc": "GTM.pdf",
            "page_number": 1,
            "languages": [
                "eng"
            ],
            "coordinates": [
                66.44950866699219,
                233.5557403564453,
                110.0840072631836,
                242.4329833984375
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "9ad2e57c5b9d915adfe11b5b97786a2d",
        "text": "25 PUBLICATIONS   3,500 CITATIONS",
        "type": "Title",
        "metadata": {
            "source_doc": "GTM.pdf",
            "page_number": 1,
            "languages": [
                "eng"
            ],
            "coordinates": [
                66.44950866699219,
                245.5166473388672,
                154.33770751953125,
                254.39389038085938
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "761a2ca9df90deb237757e6d279f4090",
        "text": "SEE PROFILE",
        "type": "Title",
        "metadata": {
            "source_doc": "GTM.pdf",
            "page_number": 1,
            "languages": [
                "eng"
            ],
            "coordinates": [
                73.75894927978516,
                262.72991943359375,
                102.3641357421875,
                269.83172607421875
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "cb9ba820fafb3f1d20c11b674f2d7f66",
        "text": "GTM: The Generative\nTopographic Mapping",
        "type": "Title",
        "metadata": {
            "source_doc": "GTM.pdf",
            "page_number": 2,
            "languages": [
                "eng"
            ],
            "coordinates": [
                175.51800537109375,
                46.582008361816406,
                427.6629943847656,
                101.24923706054688
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "3fbf740b76a062c4519aa5c999ca4c5b",
        "text": "Christopher M. Bishop,\nMarkus Svens´en\nMicrosoft Research\n7 J J Thomson Avenue\nCambridge, CB3 0FB, U.K.\n{cmbishop,markussv}@microsoft.com\nhttp://research.microsoft.com/{∼cmbishop,∼markussv}",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "GTM.pdf",
            "page_number": 2,
            "languages": [
                "eng"
            ],
            "coordinates": [
                179.20799255371094,
                150.8932342529297,
                423.9811096191406,
                220.6496124267578
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "4886979933e417f627756d99a5e9a9e6",
        "text": "Christopher K. I. Williams\nInstitute for Adaptive and Neural Computation\nDivision of Informatics, University of Edinburgh\n5 Forrest Hill, Edinburgh, EH1 2QL, Scotland, U.K.\nckiw@dai.ed.ac.uk",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "GTM.pdf",
            "page_number": 2,
            "languages": [
                "eng"
            ],
            "coordinates": [
                195.41720581054688,
                233.2790985107422,
                411.14556884765625,
                291.30474853515625
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "bc33621919bfe60a51983652f53b8169",
        "text": "Published as:\n”The Generative Topographic Mapping, Neural Computation 10, No. 1, 215–\n234 (1998)",
        "type": "Title",
        "metadata": {
            "source_doc": "GTM.pdf",
            "page_number": 2,
            "languages": [
                "eng"
            ],
            "coordinates": [
                120.89729309082031,
                330.6750183105469,
                482.30682373046875,
                350.9268493652344
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "1cd291710c842af9b05ec4aba6a53344",
        "text": "Abstract",
        "type": "Title",
        "metadata": {
            "source_doc": "GTM.pdf",
            "page_number": 2,
            "languages": [
                "eng"
            ],
            "coordinates": [
                278.2265625,
                433.0708923339844,
                324.95574951171875,
                445.0259704589844
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "a5c5be8d1b6939417e30499de26bd523",
        "text": "Latent variable models represent the probability density of data in a space of several\ndimensions in terms of a smaller number of latent, or hidden, variables. A familiar\nexample is factor analysis which is based on a linear transformations between the\nlatent space and the data space. In this paper we introduce a form of non-linear\nlatent variable model called the Generative Topographic Mapping for which the pa-\nrameters of the model can be determined using the EM algorithm. GTM provides\na principled alternative to the widely used Self-Organizing Map (SOM) of Kohonen\n(1982), and overcomes most of the signiﬁcant limitations of the SOM. We demon-\nstrate the performance of the GTM algorithm on a toy problem and on simulated\ndata from ﬂow diagnostics for a multi-phase oil pipeline.",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "GTM.pdf",
            "page_number": 2,
            "languages": [
                "eng"
            ],
            "coordinates": [
                120.89755249023438,
                456.798095703125,
                482.3871765136719,
                574.3649291992188
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "90ff532e6974da539b7092a023047cbb",
        "text": "Copyright c⃝MIT Press (1998).",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "GTM.pdf",
            "page_number": 2,
            "languages": [
                "eng"
            ],
            "coordinates": [
                89.00980377197266,
                648.3565673828125,
                210.00711059570312,
                657.599609375
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "54a8dc93ecad5120f85cf59598048918",
        "text": "Many data sets exhibit signiﬁcant correlations between the variables. One way to capture such\nstructure is to model the distribution of the data in terms of latent, or hidden, variables.\nA\nfamiliar example of this approach is factor analysis, which is based on a linear transformation\nfrom latent space to data space. In this paper we show how the latent variable framework can\nbe extended to allow non-linear transformations while remaining computationally tractable. This\nleads to the GTM (Generative Topographic Mapping) algorithm, which is based on a constrained\nmixture of Gaussians whose parameters can be optimized using the EM (expectation-maximization)\nalgorithm.",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "GTM.pdf",
            "page_number": 3,
            "languages": [
                "eng"
            ],
            "coordinates": [
                89.00961303710938,
                50.475040435791016,
                514.2153930664062,
                144.12884521484375
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "37443ba7b6b04ea28715427c8b7f10e2",
        "text": "One of the motivations for this work is to provide a principled alternative to the widely used ‘self-\norganizing map’ (SOM) algorithm (Kohonen 1982) in which a set of unlabelled data vectors tn\n(n = 1, . . . , N) in a D-dimensional data space is summarized in terms of a set of reference vectors\nhaving a spatial organization corresponding to a (generally) two-dimensional sheet. While this\nalgorithm has achieved many successes in practical applications, it also suﬀers from some signiﬁcant\ndeﬁciencies, many of which are highlighted in Kohonen (1995). They include: the absence of a\ncost function, the lack of a theoretical basis for choosing learning rate parameter schedules and\nneighbourhood parameters to ensure topographic ordering, the absence of any general proofs of\nconvergence, and the fact that the model does not deﬁne a probability density. These problems can\nall be traced to the heuristic origins of the SOM algorithm1. We show that the GTM algorithm\novercomes most of the limitations of the SOM while introducing no signiﬁcant disadvantages.",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "GTM.pdf",
            "page_number": 3,
            "languages": [
                "eng"
            ],
            "coordinates": [
                89.00930786132812,
                158.0791015625,
                514.2439575195312,
                287.5887145996094
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "1367c2672be1bdcdb9d56381615eb8aa",
        "text": "An important application of latent variable models is to data visualization. Many of the models\nused in visualization are regarded as deﬁning a projection from the D-dimensional data space\nonto a two-dimensional visualization space. We shall see that, by contrast, the GTM model is\ndeﬁned in terms of a mapping from the latent space into the data space. For the purposes of\ndata visualization, the mapping is then inverted using Bayes’ theorem, giving rise to a posterior\ndistribution in latent space.",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "GTM.pdf",
            "page_number": 3,
            "languages": [
                "eng"
            ],
            "coordinates": [
                89.00881958007812,
                301.53936767578125,
                514.2050170898438,
                371.2798156738281
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "eb5e6a3aaf12dff93f671ba694156e55",
        "text": "2\nLatent Variables",
        "type": "Title",
        "metadata": {
            "source_doc": "GTM.pdf",
            "page_number": 3,
            "languages": [
                "eng"
            ],
            "coordinates": [
                89.00881958007812,
                402.5445861816406,
                229.3940887451172,
                416.89080810546875
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "f04e3334871b877446b4db89e60f8253",
        "text": "The goal of a latent variable model is to ﬁnd a representation for the distribution p(t) of data in a\nD-dimensional space t = (t1, . . . , tD) in terms of a number L of latent variables x = (x1, . . . , xL).\nThis is achieved by ﬁrst considering a function y(x; W) which maps points x in the latent space\ninto corresponding points y(x; W) in the data space.\nThe mapping is governed by a matrix\nof parameters W, and could consist, for example, of a feed-forward neural network in which\ncase W would represent the weights and biases. We are interested in the situation in which the\ndimensionality L of the latent-variable space is less than the dimensionality D of the data space,\nsince we wish to capture the fact that the data itself has an intrinsic dimensionality which is less\nthan D. The transformation y(x; W) then maps the latent-variable space into an L-dimensional\nnon-Euclidean manifold S embedded within the data space2. This is illustrated schematically for\nthe case of L = 2 and D = 3 in Figure 1.",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "GTM.pdf",
            "page_number": 3,
            "languages": [
                "eng"
            ],
            "coordinates": [
                89.00784301757812,
                439.7322082519531,
                514.2443237304688,
                569.5050659179688
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "0341ccf1900bb9e5a7bdcb6ceb4e0805",
        "text": "If we deﬁne a probability distribution p(x) on the latent-variable space, this will induce a corre-\nsponding distribution p(y|W) in the data space. We shall refer to p(x) as the prior distribution of\nx for reasons which will become clear shortly. Since L < D, the distribution in t-space would be",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "GTM.pdf",
            "page_number": 3,
            "languages": [
                "eng"
            ],
            "coordinates": [
                89.00782775878906,
                583.1925048828125,
                514.2296752929688,
                617.3223266601562
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "944df9e5f5872c121025b37da29778d5",
        "text": "1Biological metaphor is sometimes invoked when motivating the SOM procedure. It should be stressed that our\ngoal here is not neuro-biological modelling, but rather the development of eﬀective algorithms for data analysis, for\nwhich biological realism need not be considered.\n2We assume that the matrix of partial derivatives ∂yk/∂xi has full column rank.",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "GTM.pdf",
            "page_number": 3,
            "languages": [
                "eng"
            ],
            "coordinates": [
                89.01022338867188,
                623.79638671875,
                514.1388549804688,
                663.8516845703125
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "be345aa44ab94c46a2ad12d2dbdc6808",
        "text": "2",
        "type": "Title",
        "metadata": {
            "source_doc": "GTM.pdf",
            "page_number": 3,
            "languages": [
                "eng"
            ],
            "coordinates": [
                299.11566162109375,
                699.5279541015625,
                304.09698486328125,
                709.4906005859375
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "efd6d8d1cadf913da89ab88a575968f6",
        "text": "y(x;w)",
        "type": "Title",
        "metadata": {
            "source_doc": "GTM.pdf",
            "page_number": 4,
            "languages": [
                "eng"
            ],
            "coordinates": [
                246.22799682617188,
                63.822208404541016,
                278.9371032714844,
                80.9232406616211
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "4b3fcc50038a9a2e81eeac2f4b330248",
        "text": "x2",
        "type": "Title",
        "metadata": {
            "source_doc": "GTM.pdf",
            "page_number": 4,
            "languages": [
                "eng"
            ],
            "coordinates": [
                149.3780059814453,
                98.99153137207031,
                157.87954711914062,
                114.81944274902344
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "e08b0f8f8d732acef4ff3614d67d1d9a",
        "text": "t2\nt3",
        "type": "Title",
        "metadata": {
            "source_doc": "GTM.pdf",
            "page_number": 4,
            "languages": [
                "eng"
            ],
            "coordinates": [
                303.4389953613281,
                135.3615264892578,
                410.0305480957031,
                157.7274627685547
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "88fbb7bf4af703073733885813d34d1a",
        "text": "x1",
        "type": "Title",
        "metadata": {
            "source_doc": "GTM.pdf",
            "page_number": 4,
            "languages": [
                "eng"
            ],
            "coordinates": [
                193.51199340820312,
                141.08253479003906,
                202.01454162597656,
                156.9104461669922
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "46f79118a31cdbc395ba98fa75900ac0",
        "text": "Figure 1: The non-linear function y(x; W) deﬁnes a manifold S embedded in data space given\nby the image of the latent-variable space under the mapping x →y.",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "GTM.pdf",
            "page_number": 4,
            "languages": [
                "eng"
            ],
            "coordinates": [
                110.26799774169922,
                215.52105712890625,
                492.9112243652344,
                235.67970275878906
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "27bfe908d9d98bdc2a5df77115f33231",
        "text": "conﬁned to the L-dimensional manifold and hence would be singular. Since in reality the data will\nonly approximately live on a lower-dimensional manifold, it is appropriate to include a noise model\nfor the t vector. We choose the distribution of t, for given x and W, to be a radially-symmetric\nGaussian centred on y(x; W) having variance β−1 so that",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "GTM.pdf",
            "page_number": 4,
            "languages": [
                "eng"
            ],
            "coordinates": [
                89.010498046875,
                257.3399353027344,
                514.2553100585938,
                303.4288330078125
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "e556f910fb0f75587582d24a4282e045",
        "text": "p(t|x, W, β) =\n\u0012 β",
        "type": "Title",
        "metadata": {
            "source_doc": "GTM.pdf",
            "page_number": 4,
            "languages": [
                "eng"
            ],
            "coordinates": [
                185.9049072265625,
                309.5821533203125,
                268.8355712890625,
                334.09173583984375
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "f215ea4d7d72ea422fb4234bc80816ff",
        "text": "\u0013D/2\nexp\n\u001a\n−β",
        "type": "Title",
        "metadata": {
            "source_doc": "GTM.pdf",
            "page_number": 4,
            "languages": [
                "eng"
            ],
            "coordinates": [
                272.9792785644531,
                309.5821838378906,
                336.1911926269531,
                334.091796875
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "7e3a4b284337eec947bf6c0f3fcf0c5c",
        "text": "2π",
        "type": "Title",
        "metadata": {
            "source_doc": "GTM.pdf",
            "page_number": 4,
            "languages": [
                "eng"
            ],
            "coordinates": [
                260.7659912109375,
                330.6990051269531,
                271.4216613769531,
                340.92266845703125
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "f57ec9c387942352de2147a465fe99ee",
        "text": "Note that other models for p(t|x) might also be appropriate, such as a Bernoulli for binary variables\n(with a sigmoid transformation of y) or a multinomial for mutually exclusive classes (with a\n‘softmax’, or normalized exponential transformation of y (Bishop 1995)), or even combinations of\nthese. The distribution in t-space, for a given value of W, is then obtained by integration over the\nx-distribution\np(t|W, β) =\nZ\np(t|x, W, β)p(x) dx.\n(2)",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "GTM.pdf",
            "page_number": 4,
            "languages": [
                "eng"
            ],
            "coordinates": [
                89.01010131835938,
                351.7569274902344,
                514.2412109375,
                424.3616638183594
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "02bab508622cb2cbc65441f7863500c0",
        "text": "For a given a data set D = (t1, . . . , tN) of N data points, we can determine the parameter matrix\nW, and the inverse variance β, using maximum likelihood. In practice it is convenient to maximize\nthe log likelihood, given by",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "GTM.pdf",
            "page_number": 4,
            "languages": [
                "eng"
            ],
            "coordinates": [
                89.01091003417969,
                449.1190185546875,
                514.1986083984375,
                483.24884033203125
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "45c347ef376b4415610252426d439411",
        "text": "N\nY",
        "type": "Title",
        "metadata": {
            "source_doc": "GTM.pdf",
            "page_number": 4,
            "languages": [
                "eng"
            ],
            "coordinates": [
                299.25994873046875,
                484.23089599609375,
                311.9922180175781,
                494.4416809082031
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "c27991f0d821a820e41ab7bc7e1fc1e7",
        "text": "n=1\np(tn|W, β).\n(3)",
        "type": "Title",
        "metadata": {
            "source_doc": "GTM.pdf",
            "page_number": 4,
            "languages": [
                "eng"
            ],
            "coordinates": [
                298.1165771484375,
                494.1729736328125,
                514.1943359375,
                515.2887573242188
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "8dee56ab4ad037d99e2724b18665613c",
        "text": "L(W, β) = ln",
        "type": "Title",
        "metadata": {
            "source_doc": "GTM.pdf",
            "page_number": 4,
            "languages": [
                "eng"
            ],
            "coordinates": [
                237.6549072265625,
                494.1730041503906,
                296.4596862792969,
                504.3988342285156
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "89a993c44b9bb65445e382d6bf85ec3e",
        "text": "Once we have speciﬁed the prior distribution p(x) and the functional form of the mapping y(x; W),\nwe can in principle determine W and β by maximizing L(W, β). However, the integral over x in\n(2) will, in general, be analytically intractable. If we choose y(x; W) to be a linear function of\nW, and we choose p(x) to be Gaussian, then the integral becomes a convolution of two Gaussians\nwhich is itself a Gaussian.\nFor a noise distribution p(t|x) which is Gaussian with a diagonal\ncovariance matrix, we obtain the standard factor analysis model.\nIn the case of the radially\nsymmetric Gaussian given by (1) the model is closely related to principal component analysis since\nthe maximum likelihood solution for W has columns given by the scaled principal eigenvectors.\nHere we wish to extend this formalism to non-linear functions y(x; W), and in particular to develop\na model which is similar in spirit to the SOM algorithm. We therefore consider a speciﬁc form for",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "GTM.pdf",
            "page_number": 4,
            "languages": [
                "eng"
            ],
            "coordinates": [
                89.01004028320312,
                533.2057495117188,
                514.2189331054688,
                651.0269165039062
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "e4ef3eaa31633ed4ca2760a9ae38e7fb",
        "text": "3",
        "type": "Title",
        "metadata": {
            "source_doc": "GTM.pdf",
            "page_number": 4,
            "languages": [
                "eng"
            ],
            "coordinates": [
                299.1162414550781,
                699.5279541015625,
                304.0975646972656,
                709.4906005859375
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "0c094c38013c3149316ce842c01b9b3a",
        "text": "t1",
        "type": "Title",
        "metadata": {
            "source_doc": "GTM.pdf",
            "page_number": 4,
            "languages": [
                "eng"
            ],
            "coordinates": [
                333.6789855957031,
                50.77149963378906,
                340.15155029296875,
                66.59849548339844
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "6ce371bc89811fa7709eb9c83fd09cd6",
        "text": "S",
        "type": "Title",
        "metadata": {
            "source_doc": "GTM.pdf",
            "page_number": 4,
            "languages": [
                "eng"
            ],
            "coordinates": [
                399.06298828125,
                59.45195007324219,
                405.45037841796875,
                73.3375473022461
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "6ae0a216cd59140fe639d9be55146b20",
        "text": "2 ∥y(x; W) −t∥2\n\u001b\n.\n(1)",
        "type": "Title",
        "metadata": {
            "source_doc": "GTM.pdf",
            "page_number": 4,
            "languages": [
                "eng"
            ],
            "coordinates": [
                331.14599609375,
                309.5821838378906,
                514.1947631835938,
                340.92266845703125
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "2af8ac9b897f61ea34d3a6be3c70f6d6",
        "text": "x2",
        "type": "Title",
        "metadata": {
            "source_doc": "GTM.pdf",
            "page_number": 5,
            "languages": [
                "eng"
            ],
            "coordinates": [
                132.0189971923828,
                84.06487274169922,
                142.28866577148438,
                103.1829833984375
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "93026920932c2e0b4c38b8a0cdc689bf",
        "text": "x1",
        "type": "Title",
        "metadata": {
            "source_doc": "GTM.pdf",
            "page_number": 5,
            "languages": [
                "eng"
            ],
            "coordinates": [
                185.32899475097656,
                134.90692138671875,
                195.59866333007812,
                154.02496337890625
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "96b71ca4e6769f7a2b5d4afd5a7f054a",
        "text": "Figure 2: In order to formulate a latent variable model which is similar in spirit to the SOM,\nwe consider a prior distribution p(x) consisting of a superposition of delta functions,\nlocated at the nodes of a regular grid in latent space. Each node xi is mapped to a\ncorresponding point y(xi; W) in data space, and forms the centre of a corresponding\nGaussian distribution.",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "GTM.pdf",
            "page_number": 5,
            "languages": [
                "eng"
            ],
            "coordinates": [
                110.26799774169922,
                189.133056640625,
                492.9397277832031,
                242.161865234375
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "ad48a2c24197d1a302943673b3c703b4",
        "text": "p(x) given by a sum of delta functions centred on the nodes of a regular grid in latent space",
        "type": "Title",
        "metadata": {
            "source_doc": "GTM.pdf",
            "page_number": 5,
            "languages": [
                "eng"
            ],
            "coordinates": [
                89.01095581054688,
                262.08050537109375,
                491.13824462890625,
                272.30633544921875
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "17b79ad2d50c186480cc3a15155afa1c",
        "text": "K\nX",
        "type": "Title",
        "metadata": {
            "source_doc": "GTM.pdf",
            "page_number": 5,
            "languages": [
                "eng"
            ],
            "coordinates": [
                296.1722106933594,
                283.79150390625,
                310.5582580566406,
                294.0022888183594
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "017638628989c05611d3d7520b8ed603",
        "text": "p(x) = 1",
        "type": "Title",
        "metadata": {
            "source_doc": "GTM.pdf",
            "page_number": 5,
            "languages": [
                "eng"
            ],
            "coordinates": [
                250.8494415283203,
                287.2647705078125,
                291.21905517578125,
                303.96844482421875
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "cb0ec0064be8b4ab584b92311cd2ac1b",
        "text": "i=1\nδ(x −xi)\n(4)",
        "type": "Title",
        "metadata": {
            "source_doc": "GTM.pdf",
            "page_number": 5,
            "languages": [
                "eng"
            ],
            "coordinates": [
                296.91009521484375,
                293.7425842285156,
                514.1949462890625,
                314.9751281738281
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "56665ac0479f57966acfd314d7164f60",
        "text": "K",
        "type": "Title",
        "metadata": {
            "source_doc": "GTM.pdf",
            "page_number": 5,
            "languages": [
                "eng"
            ],
            "coordinates": [
                284.1390075683594,
                300.57598876953125,
                292.5972900390625,
                310.53863525390625
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "b78e1e6fa34d14fd790632a123d510a2",
        "text": "in which case the integral in (2) can again be performed analytically. Each point xi is then mapped\nto a corresponding point y(xi; W) in data space, which forms the centre of a Gaussian density\nfunction, as illustrated in Figure 2. From (2) and (4) we see that the distribution function in data\nspace then takes the form",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "GTM.pdf",
            "page_number": 5,
            "languages": [
                "eng"
            ],
            "coordinates": [
                89.00967407226562,
                324.92779541015625,
                514.2264404296875,
                371.0185241699219
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "5a35ff02e06ac98bd40b2fd1150fc71a",
        "text": "K\nX",
        "type": "Title",
        "metadata": {
            "source_doc": "GTM.pdf",
            "page_number": 5,
            "languages": [
                "eng"
            ],
            "coordinates": [
                299.9432067871094,
                371.9919128417969,
                314.3292541503906,
                382.20269775390625
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "5e97a0cae649ba6b92392b727aff49c4",
        "text": "p(t|W, β) = 1",
        "type": "Title",
        "metadata": {
            "source_doc": "GTM.pdf",
            "page_number": 5,
            "languages": [
                "eng"
            ],
            "coordinates": [
                230.85028076171875,
                375.46484375,
                294.9886779785156,
                392.1595153808594
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "e85e2fef32687969cab7a1a32b61bad3",
        "text": "i=1\np(t|xi, W, β)\n(5)",
        "type": "Title",
        "metadata": {
            "source_doc": "GTM.pdf",
            "page_number": 5,
            "languages": [
                "eng"
            ],
            "coordinates": [
                300.68109130859375,
                381.9339904785156,
                514.1936645507812,
                403.1665344238281
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "98f34f7d616831005c43d94f5138f2d1",
        "text": "K",
        "type": "Title",
        "metadata": {
            "source_doc": "GTM.pdf",
            "page_number": 5,
            "languages": [
                "eng"
            ],
            "coordinates": [
                287.9100036621094,
                388.7760009765625,
                296.3682861328125,
                398.7386474609375
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "286962e205fa08376d9feaa3bb81e2b3",
        "text": "and the log likelihood function becomes",
        "type": "Title",
        "metadata": {
            "source_doc": "GTM.pdf",
            "page_number": 5,
            "languages": [
                "eng"
            ],
            "coordinates": [
                89.00979614257812,
                408.84637451171875,
                262.31378173828125,
                418.80902099609375
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "bac2858b8a052a76c515a4f74d39cf79",
        "text": "(\n1\nK",
        "type": "Title",
        "metadata": {
            "source_doc": "GTM.pdf",
            "page_number": 5,
            "languages": [
                "eng"
            ],
            "coordinates": [
                284.3995666503906,
                422.4240417480469,
                302.07427978515625,
                456.49163818359375
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "4b17f3da8477c96628439d547ac65fdf",
        "text": "K\nX",
        "type": "Title",
        "metadata": {
            "source_doc": "GTM.pdf",
            "page_number": 5,
            "languages": [
                "eng"
            ],
            "coordinates": [
                305.64923095703125,
                429.7445068359375,
                320.0352783203125,
                439.9556884765625
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "71454c2ae9d8c2a42ead0464913e3d3f",
        "text": "N\nX",
        "type": "Title",
        "metadata": {
            "source_doc": "GTM.pdf",
            "page_number": 5,
            "languages": [
                "eng"
            ],
            "coordinates": [
                258.0745544433594,
                429.7445983886719,
                272.4606018066406,
                439.9557800292969
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "97909ba0f9e92e2bbaebb17abfd1afe2",
        "text": "L(W, β) =",
        "type": "Title",
        "metadata": {
            "source_doc": "GTM.pdf",
            "page_number": 5,
            "languages": [
                "eng"
            ],
            "coordinates": [
                207.26980590820312,
                439.69610595703125,
                254.9984588623047,
                449.92193603515625
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "13be54a778bbc70b0e70b6dabdcdc628",
        "text": "n=1\nln",
        "type": "Title",
        "metadata": {
            "source_doc": "GTM.pdf",
            "page_number": 5,
            "languages": [
                "eng"
            ],
            "coordinates": [
                257.75970458984375,
                439.95928955078125,
                282.7410888671875,
                460.80242919921875
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "8307f4b7e7abb77d785473d261ac0227",
        "text": "For the particular noise model p(t|x, W, β) given by (1), the distribution p(t|W, β) corresponds\nto a constrained Gaussian mixture model (Hinton, Williams, and Revow 1992) since the centres\nof the Gaussians, given by y(xi; W), cannot move independently but are related through the\nfunction y(x; W). Note that, provided the mapping function y(x; W) is smooth and continuous,\nthe projected points y(xi; W) will necessarily have a topographic ordering in the sense that any\ntwo points xA and xB which are close in latent space will map to points y(xA; W) and y(xB; W)\nwhich are close in data space.",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "GTM.pdf",
            "page_number": 5,
            "languages": [
                "eng"
            ],
            "coordinates": [
                89.01025390625,
                470.8717956542969,
                514.2443237304688,
                552.8278198242188
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "7fd1c51266c6cb2db518ebd61a62ef77",
        "text": "2.1\nThe EM Algorithm",
        "type": "Title",
        "metadata": {
            "source_doc": "GTM.pdf",
            "page_number": 5,
            "languages": [
                "eng"
            ],
            "coordinates": [
                89.01260375976562,
                580.89208984375,
                233.66387939453125,
                592.84716796875
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "ab706e1da772dfa8e59db163d28bda4c",
        "text": "If we now choose a particular parametrized form for y(x; W) which is a diﬀerentiable function of\nW (for example, a feed-forward network with sigmoidal hidden units) then we can use standard\ntechniques for non-linear optimization, such as conjugate gradients or quasi-Newton methods, to\nﬁnd a weight matrix W∗, and an inverse variance β∗, which maximize L(W, β).",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "GTM.pdf",
            "page_number": 5,
            "languages": [
                "eng"
            ],
            "coordinates": [
                89.01260375976562,
                612.7930297851562,
                514.2244262695312,
                658.884033203125
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "6978974c86614d3c4d3d6564be7e7917",
        "text": "4",
        "type": "Title",
        "metadata": {
            "source_doc": "GTM.pdf",
            "page_number": 5,
            "languages": [
                "eng"
            ],
            "coordinates": [
                299.1186828613281,
                699.5280151367188,
                304.1000061035156,
                709.4906616210938
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "841ba2e82043691aa99544706c3d4d53",
        "text": "t2\nt3",
        "type": "Title",
        "metadata": {
            "source_doc": "GTM.pdf",
            "page_number": 5,
            "languages": [
                "eng"
            ],
            "coordinates": [
                318.1109924316406,
                127.99590301513672,
                446.8636779785156,
                155.012939453125
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "69577f1010c4c2c6914227bc48d8ff22",
        "text": ")",
        "type": "Title",
        "metadata": {
            "source_doc": "GTM.pdf",
            "page_number": 5,
            "languages": [
                "eng"
            ],
            "coordinates": [
                383.46331787109375,
                422.4239196777344,
                391.4931945800781,
                432.3865661621094
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "85b7865868e096a39c6e4a36076fb02b",
        "text": "i=1\np(tn|xi, W, β)",
        "type": "Title",
        "metadata": {
            "source_doc": "GTM.pdf",
            "page_number": 5,
            "languages": [
                "eng"
            ],
            "coordinates": [
                306.3961181640625,
                439.69598388671875,
                383.4676818847656,
                460.92852783203125
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "e811a70bf42948947f8566d916f0207e",
        "text": ".\n(6)",
        "type": "Title",
        "metadata": {
            "source_doc": "GTM.pdf",
            "page_number": 5,
            "languages": [
                "eng"
            ],
            "coordinates": [
                393.17425537109375,
                439.6981506347656,
                514.1948852539062,
                449.92181396484375
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "7e74fa30c4114c993261b1ddef575243",
        "text": "However, our model consists of a mixture distribution which suggests that we might seek an\nEM (expectation-maximization) algorithm (Dempster, Laird, and Rubin 1977; Bishop 1995). By\nmaking a suitable choice of model y(x; W) we will see that the M-step corresponds to the solution\nof a set of linear equations. In particular we shall choose y(x; W) to be given by a generalized\nlinear regression model of the form",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "GTM.pdf",
            "page_number": 6,
            "languages": [
                "eng"
            ],
            "coordinates": [
                89.00979614257812,
                16.707035064697266,
                514.2081909179688,
                74.48663330078125
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "f776fac256558556aad1130db81df040",
        "text": "y(x; W) = Wφ(x)\n(7)",
        "type": "Title",
        "metadata": {
            "source_doc": "GTM.pdf",
            "page_number": 6,
            "languages": [
                "eng"
            ],
            "coordinates": [
                260.2982482910156,
                84.12407684326172,
                514.1923828125,
                94.34991455078125
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "481dbba05cb463c3d079b16061e1a856",
        "text": "where the elements of φ(x) consist of M ﬁxed basis functions φj(x), and W is a D × M matrix.\nGeneralized linear regression models possess the same universal approximation capabilities as multi-\nlayer adaptive networks, provided the basis functions φj(x) are chosen appropriately. The usual\nlimitation of such models, however, is that the number of basis functions must typically grow\nexponentially with the dimensionality L of the input space (Bishop 1995). In the present context\nthis is not a signiﬁcant problem since the dimensionality is governed by the number of latent\nvariable variables which will typically be small.\nIn fact for data visualization applications we\ngenerally use L = 2.",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "GTM.pdf",
            "page_number": 6,
            "languages": [
                "eng"
            ],
            "coordinates": [
                89.0108642578125,
                103.99596405029297,
                514.22314453125,
                197.90411376953125
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "41c9e0818f0ff6dc44bc76449fafbf0f",
        "text": "The maximization of (6) can be regarded as a missing-data problem in which the identity i of the\ncomponent which generated each data point tn is unknown. We can formulate the EM algorithm\nfor this model as follows. First, suppose that, at some point in the algorithm, the current weight\nmatrix is given by Wold and the current inverse noise variance is given by βold. In the E-step\nwe use Wold and βold to evaluate the posterior probabilities, or responsibilities, of each Gaussian\ncomponent i for every data point tn using Bayes’ theorem in the form",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "GTM.pdf",
            "page_number": 6,
            "languages": [
                "eng"
            ],
            "coordinates": [
                89.01141357421875,
                211.5933380126953,
                514.2211303710938,
                283.0890197753906
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "7785327f2b6878ebcd91eabf77044beb",
        "text": "Rin(Wold, βold)\n=\np(xi|tn, Wold, βold)\n(8)",
        "type": "Title",
        "metadata": {
            "source_doc": "GTM.pdf",
            "page_number": 6,
            "languages": [
                "eng"
            ],
            "coordinates": [
                193.06985473632812,
                291.23236083984375,
                514.1974487304688,
                302.20513916015625
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "3fbf3c029339eaa8d6194f88af3f673c",
        "text": "=\np(tn|xi, Wold, βold)\nXK",
        "type": "Title",
        "metadata": {
            "source_doc": "GTM.pdf",
            "page_number": 6,
            "languages": [
                "eng"
            ],
            "coordinates": [
                270.73956298828125,
                305.1823425292969,
                389.5989074707031,
                325.0732727050781
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "78716e60f59188d9ce5ab05ea0cbb255",
        "text": "i′=1p(tn|xi′, Wold, βold)\n.\n(9)",
        "type": "Title",
        "metadata": {
            "source_doc": "GTM.pdf",
            "page_number": 6,
            "languages": [
                "eng"
            ],
            "coordinates": [
                304.0379943847656,
                311.9249267578125,
                514.1939697265625,
                339.0502624511719
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "6f1261e623e10501d7f60d6d168bc132",
        "text": "We now consider the expectation of the complete-data log likelihood in the form",
        "type": "Title",
        "metadata": {
            "source_doc": "GTM.pdf",
            "page_number": 6,
            "languages": [
                "eng"
            ],
            "coordinates": [
                89.00933837890625,
                345.65704345703125,
                440.32171630859375,
                355.61968994140625
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "fec5eb0502097266d540278b6ae30ed7",
        "text": "N\nX",
        "type": "Title",
        "metadata": {
            "source_doc": "GTM.pdf",
            "page_number": 6,
            "languages": [
                "eng"
            ],
            "coordinates": [
                246.4015350341797,
                364.503662109375,
                260.78759765625,
                374.7144470214844
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "75580bdd6c4b7a44eb86bc290cd56b0f",
        "text": "K\nX",
        "type": "Title",
        "metadata": {
            "source_doc": "GTM.pdf",
            "page_number": 6,
            "languages": [
                "eng"
            ],
            "coordinates": [
                262.76324462890625,
                364.503662109375,
                277.1492919921875,
                374.7144470214844
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "29d9b2ccf0f13e9e9c97cdf15c6acab8",
        "text": "i=1\nRin(Wold, βold) ln {p(tn|xi, W, β)} .\n(10)",
        "type": "Title",
        "metadata": {
            "source_doc": "GTM.pdf",
            "page_number": 6,
            "languages": [
                "eng"
            ],
            "coordinates": [
                263.50152587890625,
                374.4547424316406,
                514.1925048828125,
                395.6872863769531
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "f3deb9681d88dcbd2bd03b46a029145a",
        "text": "⟨Lcomp(W, β)⟩=",
        "type": "Title",
        "metadata": {
            "source_doc": "GTM.pdf",
            "page_number": 6,
            "languages": [
                "eng"
            ],
            "coordinates": [
                168.88433837890625,
                374.45477294921875,
                243.32395935058594,
                385.42230224609375
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "f07e6c1416d405333916e5098beadc0c",
        "text": "n=1",
        "type": "Title",
        "metadata": {
            "source_doc": "GTM.pdf",
            "page_number": 6,
            "languages": [
                "eng"
            ],
            "coordinates": [
                246.0863037109375,
                388.5914001464844,
                261.09716796875,
                395.57049560546875
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "1a636cfbe04903a0a1bba6597509073e",
        "text": "Maximizing (10) with respect to W, and using (1) and (7), we obtain",
        "type": "Title",
        "metadata": {
            "source_doc": "GTM.pdf",
            "page_number": 6,
            "languages": [
                "eng"
            ],
            "coordinates": [
                89.00982666015625,
                403.5875549316406,
                393.402587890625,
                413.8133850097656
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "7743c5e795122cbfb327c929dfb993c2",
        "text": "N\nX",
        "type": "Title",
        "metadata": {
            "source_doc": "GTM.pdf",
            "page_number": 6,
            "languages": [
                "eng"
            ],
            "coordinates": [
                183.16845703125,
                423.2556457519531,
                197.55450439453125,
                433.4664306640625
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "f2c2fa6ef349b15208b95da2e2600830",
        "text": "K\nX",
        "type": "Title",
        "metadata": {
            "source_doc": "GTM.pdf",
            "page_number": 6,
            "languages": [
                "eng"
            ],
            "coordinates": [
                199.53018188476562,
                423.2556457519531,
                213.91622924804688,
                433.4664306640625
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "4ca386945ff56bbb773dc1fda2886da8",
        "text": "i=1\nRin(Wold, βold) {Wnewφ(xi) −tn} φT(xi) = 0.\n(11)",
        "type": "Title",
        "metadata": {
            "source_doc": "GTM.pdf",
            "page_number": 6,
            "languages": [
                "eng"
            ],
            "coordinates": [
                200.27745056152344,
                431.2421875,
                514.1940307617188,
                454.4302673339844
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "0408d3e1a4be5c33340a688d33958fd6",
        "text": "n=1",
        "type": "Title",
        "metadata": {
            "source_doc": "GTM.pdf",
            "page_number": 6,
            "languages": [
                "eng"
            ],
            "coordinates": [
                182.86221313476562,
                447.3343811035156,
                197.87310791015625,
                454.3134765625
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "f8d2acbc8cb32da2aafa6a1c119b74ba",
        "text": "This can conveniently be written in matrix notation in the form",
        "type": "Title",
        "metadata": {
            "source_doc": "GTM.pdf",
            "page_number": 6,
            "languages": [
                "eng"
            ],
            "coordinates": [
                89.01034545898438,
                462.044921875,
                368.697509765625,
                472.007568359375
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "ff1a0abd8b56a9e1be39ea2ace6e951d",
        "text": "ΦTGoldΦWT\nnew = ΦTRoldT\n(12)",
        "type": "Title",
        "metadata": {
            "source_doc": "GTM.pdf",
            "page_number": 6,
            "languages": [
                "eng"
            ],
            "coordinates": [
                239.41835021972656,
                479.7703552246094,
                514.1948852539062,
                494.3365173339844
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "8bd35625ff16aab0210654cbecc971ae",
        "text": "where Φ is a K × M matrix with elements Φij = φj(xi), T is a N × D matrix with elements tnk,\nR is a K × N matrix with elements Rin, and G is a K × K diagonal matrix with elements",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "GTM.pdf",
            "page_number": 6,
            "languages": [
                "eng"
            ],
            "coordinates": [
                89.01019287109375,
                501.5169677734375,
                514.2039184570312,
                524.4413452148438
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "b3c8323f041f1a49616647a032e1acf6",
        "text": "N\nX",
        "type": "Title",
        "metadata": {
            "source_doc": "GTM.pdf",
            "page_number": 6,
            "languages": [
                "eng"
            ],
            "coordinates": [
                282.75335693359375,
                532.5783081054688,
                297.139404296875,
                542.78955078125
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "4e2190285cd4e90f2f57a86d0d6ab0a0",
        "text": "n=1\nRin(W, β).\n(13)",
        "type": "Title",
        "metadata": {
            "source_doc": "GTM.pdf",
            "page_number": 6,
            "languages": [
                "eng"
            ],
            "coordinates": [
                282.4385070800781,
                542.5298461914062,
                514.1940307617188,
                563.6455688476562
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "bfcccdc54d0f1995c31831cfae229912",
        "text": "Gii =",
        "type": "Title",
        "metadata": {
            "source_doc": "GTM.pdf",
            "page_number": 6,
            "languages": [
                "eng"
            ],
            "coordinates": [
                255.18661499023438,
                542.531982421875,
                279.6773986816406,
                554.2494506835938
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "27005d92293133149996e1e2f98fb65d",
        "text": "We can now solve (12) for Wnew using standard matrix inversion techniques, based on singular\nvalue decomposition to allow for possible ill-conditioning. Note that the matrix Φ is constant\nthroughout the algorithm, and so need only be evaluated once at the start.",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "GTM.pdf",
            "page_number": 6,
            "languages": [
                "eng"
            ],
            "coordinates": [
                89.01107788085938,
                571.536865234375,
                514.242431640625,
                605.6755981445312
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "6143f0385e249593ef441d5f1b227836",
        "text": "Similarly, maximizing (10) with respect to β we obtain the following re-estimation formula",
        "type": "Title",
        "metadata": {
            "source_doc": "GTM.pdf",
            "page_number": 6,
            "languages": [
                "eng"
            ],
            "coordinates": [
                89.01107788085938,
                619.3648071289062,
                484.7713928222656,
                629.5885009765625
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "67f1e54fe1e0f366659b1291dc418b5f",
        "text": "N\nX",
        "type": "Title",
        "metadata": {
            "source_doc": "GTM.pdf",
            "page_number": 6,
            "languages": [
                "eng"
            ],
            "coordinates": [
                233.87391662597656,
                639.0308837890625,
                248.2599639892578,
                649.2417602539062
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "245ad906a0a0305ed58808cc72e978e0",
        "text": "K\nX",
        "type": "Title",
        "metadata": {
            "source_doc": "GTM.pdf",
            "page_number": 6,
            "languages": [
                "eng"
            ],
            "coordinates": [
                250.2360076904297,
                639.0308837890625,
                264.6220703125,
                649.24169921875
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "113e4d78b0ff424505ca246d608487c8",
        "text": "1\nβnew\n=\n1\nND",
        "type": "Title",
        "metadata": {
            "source_doc": "GTM.pdf",
            "page_number": 6,
            "languages": [
                "eng"
            ],
            "coordinates": [
                177.54299926757812,
                642.4949340820312,
                230.42686462402344,
                666.7803344726562
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "43574b73f0297a0ef238f475353531f7",
        "text": "i=1\nRin(Wold, βold) ∥Wnewφ(xi) −tn∥2 .\n(14)",
        "type": "Title",
        "metadata": {
            "source_doc": "GTM.pdf",
            "page_number": 6,
            "languages": [
                "eng"
            ],
            "coordinates": [
                250.97389221191406,
                643.9712524414062,
                514.1940307617188,
                670.20556640625
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "0f4d94f7626064e3495788456c04262c",
        "text": "n=1",
        "type": "Title",
        "metadata": {
            "source_doc": "GTM.pdf",
            "page_number": 6,
            "languages": [
                "eng"
            ],
            "coordinates": [
                233.55906677246094,
                663.1096801757812,
                248.5699462890625,
                670.0887451171875
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "384d35dc8ea659c6a19a00d2626d779f",
        "text": "5",
        "type": "Title",
        "metadata": {
            "source_doc": "GTM.pdf",
            "page_number": 6,
            "languages": [
                "eng"
            ],
            "coordinates": [
                299.1143493652344,
                699.5280151367188,
                304.0956726074219,
                709.4906616210938
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "29d03f892e118cb1498ca88e5d6b2954",
        "text": "The EM algorithm alternates between the E-step, corresponding to the evaluation of the posterior\nprobabilities in (9), and the M-step, given by the solution of (12) and (14). Jensen’s inequality\ncan be used to show that, at each iteration of the algorithm, the objective function will increase\nunless it is already at a (local) maximum, as discussed for example in Bishop (1995). Typically\nthe EM algorithm gives satisfactory convergence after a few tens of cycles, particularly since we\nare primarily interested in convergence of the distribution and this is often achieved much more\nrapidly than convergence of the parameters themselves.",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "GTM.pdf",
            "page_number": 7,
            "languages": [
                "eng"
            ],
            "coordinates": [
                89.00979614257812,
                16.707035064697266,
                514.2064819335938,
                98.39996337890625
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "eae814876cae2c100d22573441dab683",
        "text": "If desired, a regularization term can be added to the objective function to control the mapping\ny(x; W). This can be interpreted as a MAP (maximum a-posteriori) estimator corresponding to a\nchoice of prior over the weights W. In the case of a radially-symmetric Gaussian prior of the form",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "GTM.pdf",
            "page_number": 7,
            "languages": [
                "eng"
            ],
            "coordinates": [
                89.00979614257812,
                112.34125518798828,
                514.218994140625,
                146.216796875
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "1fa2bdbb0f63cdba89209b381d2c0acb",
        "text": "\u0013MD/2\nexp",
        "type": "Title",
        "metadata": {
            "source_doc": "GTM.pdf",
            "page_number": 7,
            "languages": [
                "eng"
            ],
            "coordinates": [
                268.9112854003906,
                153.72874450683594,
                316.7481994628906,
                178.23834228515625
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "007cb89f6c0e9f9c2cfc0eb61223d0ab",
        "text": "p(W|λ) =\n\u0012 λ",
        "type": "Title",
        "metadata": {
            "source_doc": "GTM.pdf",
            "page_number": 7,
            "languages": [
                "eng"
            ],
            "coordinates": [
                201.5460968017578,
                153.72911071777344,
                265.1075134277344,
                178.23870849609375
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "dc948c0be6ad545aea6915e39c87f8b9",
        "text": "2π",
        "type": "Title",
        "metadata": {
            "source_doc": "GTM.pdf",
            "page_number": 7,
            "languages": [
                "eng"
            ],
            "coordinates": [
                256.697998046875,
                174.84596252441406,
                267.3536682128906,
                185.06964111328125
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "e7da1d0fcae894a6425a077b279dc314",
        "text": "where λ is the regularization coeﬃcient, this leads to a modiﬁcation of the M-step (12) to give\n\u0012\nΦTGoldΦ + λ",
        "type": "Title",
        "metadata": {
            "source_doc": "GTM.pdf",
            "page_number": 7,
            "languages": [
                "eng"
            ],
            "coordinates": [
                89.00979614257812,
                200.58595275878906,
                501.0830078125,
                238.146240234375
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "8b3963271ce7e7a64b433729e3586259",
        "text": "β I\n\u0013\nWT\nnew = ΦTRoldT\n(16)",
        "type": "Title",
        "metadata": {
            "source_doc": "GTM.pdf",
            "page_number": 7,
            "languages": [
                "eng"
            ],
            "coordinates": [
                282.29400634765625,
                212.8948211669922,
                514.1947631835938,
                243.97462463378906
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "c30c5e86d654cda1bd7b6fc80b39b9ff",
        "text": "where I is the identity matrix.",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "GTM.pdf",
            "page_number": 7,
            "languages": [
                "eng"
            ],
            "coordinates": [
                89.01007080078125,
                253.22467041015625,
                221.3220977783203,
                263.45050048828125
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "5d549ba08bd3ff898d20471ae21aa0a7",
        "text": "2.2\nData Visualization",
        "type": "Title",
        "metadata": {
            "source_doc": "GTM.pdf",
            "page_number": 7,
            "languages": [
                "eng"
            ],
            "coordinates": [
                89.01006317138672,
                291.2897644042969,
                229.13958740234375,
                303.244873046875
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "b56b730b18bc6b6fbb803aebebab32fc",
        "text": "One application for GTM is in data visualization, in which Bayes’ theorem is used to invert the\ntransformation from latent space to data space. For the particular choice of prior distribution\ngiven by (4), the posterior distribution is again a sum of delta functions centred at the lattice\npoints, with coeﬃcients given by the responsibilities Rin. These coeﬃcients can be used to provide\na visualization of the posterior responsibility map for individual data points in the two-dimensional\nlatent space. If it is desired to visualize a set of data points then a complete posterior distribution\nfor each data point may provide too much information and it is often convenient to summarize the\nposterior by its mean, given for each data point tn by",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "GTM.pdf",
            "page_number": 7,
            "languages": [
                "eng"
            ],
            "coordinates": [
                89.00927734375,
                323.4449768066406,
                514.2225341796875,
                418.5928649902344
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "ff2b48fa0b26aa4d5103805bc63694ef",
        "text": "⟨x|tn, W∗, β∗⟩\n=\nZ\np(x|tn, W∗, β∗)x dx\n(17)",
        "type": "Title",
        "metadata": {
            "source_doc": "GTM.pdf",
            "page_number": 7,
            "languages": [
                "eng"
            ],
            "coordinates": [
                207.35928344726562,
                418.229736328125,
                514.193115234375,
                443.0003662109375
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "8527352e8af9de27b53385d3ebd54f4d",
        "text": "K\nX",
        "type": "Title",
        "metadata": {
            "source_doc": "GTM.pdf",
            "page_number": 7,
            "languages": [
                "eng"
            ],
            "coordinates": [
                297.6561584472656,
                452.8565673828125,
                312.0422058105469,
                463.0673522949219
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "d6c4e4ebb04ee5cd0e3c680026fc7dc1",
        "text": "i=1\nRinxi.\n(18)",
        "type": "Title",
        "metadata": {
            "source_doc": "GTM.pdf",
            "page_number": 7,
            "languages": [
                "eng"
            ],
            "coordinates": [
                298.3944396972656,
                462.80804443359375,
                514.1941528320312,
                484.04058837890625
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "606765bffa0e790b5396272ae072aa23",
        "text": "=",
        "type": "Title",
        "metadata": {
            "source_doc": "GTM.pdf",
            "page_number": 7,
            "languages": [
                "eng"
            ],
            "coordinates": [
                279.9444580078125,
                463.0712585449219,
                287.6954040527344,
                473.0339050292969
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "e31edd75acc801c764a10cb73b951fef",
        "text": "It should be borne in mind, however, that the posterior distribution can be multi-modal in which\ncase the posterior mean can give a very misleading summary of the true distribution. An alternative\napproach is therefore to evaluate the mode of the distribution, given by",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "GTM.pdf",
            "page_number": 7,
            "languages": [
                "eng"
            ],
            "coordinates": [
                89.00949096679688,
                492.4021301269531,
                514.2015380859375,
                526.2687377929688
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "937344af584061e8dea608a08575e743",
        "text": "imax = arg max\n{i} Rin.\n(19)",
        "type": "Title",
        "metadata": {
            "source_doc": "GTM.pdf",
            "page_number": 7,
            "languages": [
                "eng"
            ],
            "coordinates": [
                258.42547607421875,
                532.8119506835938,
                514.1943359375,
                553.5205688476562
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "ce98e35544753d3f7eac7ce25d6407c8",
        "text": "In practice it is often convenient to plot both the mean and the mode for each data point, as\nsigniﬁcant diﬀerences between them can be indicative of a multi-modal distribution.",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "GTM.pdf",
            "page_number": 7,
            "languages": [
                "eng"
            ],
            "coordinates": [
                89.0096435546875,
                563.1329956054688,
                514.202880859375,
                585.0476684570312
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "0967fb4cd40d3ef41c6066105e0276ac",
        "text": "2.3\nChoice of Model Parameters",
        "type": "Title",
        "metadata": {
            "source_doc": "GTM.pdf",
            "page_number": 7,
            "languages": [
                "eng"
            ],
            "coordinates": [
                89.0096435546875,
                612.8958740234375,
                287.8101806640625,
                624.8509521484375
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "578f8efb85ff44d0d974869c3556282c",
        "text": "The problem of density estimation from a ﬁnite data set is fundamentally ill-posed, since there exist\ninﬁnitely many distributions which could have given rise to the observed data. An algorithm for",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "GTM.pdf",
            "page_number": 7,
            "languages": [
                "eng"
            ],
            "coordinates": [
                89.0096435546875,
                645.0510864257812,
                514.21484375,
                666.9746704101562
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "7e7c4a25945898334b7859decbeadb19",
        "text": "6",
        "type": "Title",
        "metadata": {
            "source_doc": "GTM.pdf",
            "page_number": 7,
            "languages": [
                "eng"
            ],
            "coordinates": [
                299.1156311035156,
                699.5280151367188,
                304.0969543457031,
                709.4906616210938
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "fbed40f934a0b6d4410335937125567a",
        "text": "\n",
        "type": "Title",
        "metadata": {
            "source_doc": "GTM.pdf",
            "page_number": 7,
            "languages": [
                "eng"
            ],
            "coordinates": [
                318.4113464355469,
                147.3568572998047,
                327.26812744140625,
                166.28317260742188
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "7850ed40bdf7e28000fe522bc383ee6c",
        "text": "\n",
        "type": "Title",
        "metadata": {
            "source_doc": "GTM.pdf",
            "page_number": 7,
            "languages": [
                "eng"
            ],
            "coordinates": [
                392.8138122558594,
                147.35704040527344,
                401.67059326171875,
                166.28335571289062
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "ba893066feba2f2fc5c1eecc9d9b67a5",
        "text": "M\nX",
        "type": "Title",
        "metadata": {
            "source_doc": "GTM.pdf",
            "page_number": 7,
            "languages": [
                "eng"
            ],
            "coordinates": [
                344.8797912597656,
                158.0614776611328,
                359.2658386230469,
                168.27230834960938
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "72ff9d42ec163aea576aed20d0612010",
        "text": "D\nX",
        "type": "Title",
        "metadata": {
            "source_doc": "GTM.pdf",
            "page_number": 7,
            "languages": [
                "eng"
            ],
            "coordinates": [
                360.98101806640625,
                158.0614776611328,
                375.3670654296875,
                168.27230834960938
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "2215e85d6fd134c44f2c2307f625e24e",
        "text": "−λ",
        "type": "Title",
        "metadata": {
            "source_doc": "GTM.pdf",
            "page_number": 7,
            "languages": [
                "eng"
            ],
            "coordinates": [
                318.4113464355469,
                161.2736358642578,
                342.0215148925781,
                184.21127319335938
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "6b7348d10576ae159674d37a5f008619",
        "text": "k=1\nw2\njk",
        "type": "Title",
        "metadata": {
            "source_doc": "GTM.pdf",
            "page_number": 7,
            "languages": [
                "eng"
            ],
            "coordinates": [
                360.9271240234375,
                166.39926147460938,
                392.1434326171875,
                189.4705810546875
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "b20562e6bb9730ba40577077dcb1fde5",
        "text": "\n(15)",
        "type": "Title",
        "metadata": {
            "source_doc": "GTM.pdf",
            "page_number": 7,
            "languages": [
                "eng"
            ],
            "coordinates": [
                392.8138122558594,
                168.27587890625,
                514.1944580078125,
                184.21145629882812
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "b599f8c05ac8b715d6cc7cfec8ef71d9",
        "text": "2",
        "type": "Title",
        "metadata": {
            "source_doc": "GTM.pdf",
            "page_number": 7,
            "languages": [
                "eng"
            ],
            "coordinates": [
                336.62701416015625,
                175.10699462890625,
                341.60833740234375,
                185.06964111328125
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "9a4a5b6f0e0389e680611c38178a751a",
        "text": "j=1",
        "type": "Title",
        "metadata": {
            "source_doc": "GTM.pdf",
            "page_number": 7,
            "languages": [
                "eng"
            ],
            "coordinates": [
                345.17706298828125,
                182.26644897460938,
                358.96368408203125,
                189.24554443359375
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "4e5d07a6c5502e89bb86ba1a4d75c6ad",
        "text": "Figure 3: Examples of manifolds generated by sampling from the prior distribution over W\ngiven by (15), showing the eﬀect of the choice of basis functions on the smoothness\nof the manifold. Here the basis functions are Gaussian with width σ = 4s in the\nleft-hand plot (where s is the spacing of the basis function centres), and σ = 2s\nin the right-hand plot. Diﬀerent values of λ simply aﬀect the linear scaling of the\nembedded manifold.",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "GTM.pdf",
            "page_number": 8,
            "languages": [
                "eng"
            ],
            "coordinates": [
                110.26799774169922,
                200.20306396484375,
                492.9444274902344,
                264.1939697265625
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "1a6095945e871e8adbec231900095f67",
        "text": "density modelling therefore requires some form of ‘prior knowledge’ in addition to the data set. The\nassumption that the distribution can be described in terms of a reduced number of latent variables\nis itself part of this prior. In the GTM algorithm, the prior distribution over mapping functions\ny(x; W) is governed by the prior over weights W, given for example by (15), as well as by the\nbasis functions. We typically choose the basis functions φj(x) to be radially symmetric Gaussians\nwhose centres are distributed on a uniform grid in x-space, with a common width parameter σ,\nwhose value, along with the number and spacing of the basis functions, determines the smoothness\nof the manifold. Examples of surfaces generated by sampling the prior are shown in Figure 3.",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "GTM.pdf",
            "page_number": 8,
            "languages": [
                "eng"
            ],
            "coordinates": [
                89.00975036621094,
                284.3758239746094,
                514.211181640625,
                378.02056884765625
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "c4b847de68d06e64e83b25b57d498260",
        "text": "In addition to the basis functions φi(x), it is also necessary to select the latent-space sample points\n{xi}. Note that, if there are too few sample points in relation to the number of basis functions,\nthen the Gaussian mixture centres in data space become relatively independent and the desired\nsmoothness properties can be lost. Having a large number of sample points, however, causes no\ndiﬃculty beyond increased computational cost. In particular, there is no ‘over-ﬁtting’ if the number\nof sample points is increased since the number of degrees of freedom in the model is controlled by\nthe mapping function y(x; W). One way to view the role of the latent space samples {xi} is as\na Monte Carlo approximation to the integral over x in (2) (MacKay 1995; Bishop, Svens´en, and\nWilliams 1996). The choice of the number K and location of the sample points xi in latent space\nis not critical, and we typically choose Gaussian basis functions and set K so that, in the case\nof a two-dimensional latent space, O(100) sample points lie within 2σ of the centre of each basis\nfunction.",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "GTM.pdf",
            "page_number": 8,
            "languages": [
                "eng"
            ],
            "coordinates": [
                89.00985717773438,
                391.7080383300781,
                514.2219848632812,
                533.4418334960938
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "97cdb1b136ffe703febe0d177e0ed35f",
        "text": "Note that we have considered the basis function parameters (widths and locations) to be ﬁxed, with\na Gaussian prior on the weight matrix W. In principle, priors over the basis function parameters\ncould also be introduced, and these could again be treated by MAP estimation or by Bayesian\nintegration.",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "GTM.pdf",
            "page_number": 8,
            "languages": [
                "eng"
            ],
            "coordinates": [
                89.01028442382812,
                547.3831176757812,
                514.2262573242188,
                593.2109985351562
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "c4d2a75545f61ebc22183f5988c9d8a3",
        "text": "We initialize the parameters W so that the GTM model initially approximates principal component\nanalysis. To do this, we ﬁrst evaluate the data covariance matrix and obtain the ﬁrst and second",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "GTM.pdf",
            "page_number": 8,
            "languages": [
                "eng"
            ],
            "coordinates": [
                89.0098876953125,
                606.8980102539062,
                514.2333984375,
                629.0758666992188
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "683f57d50b59bfd54c9633e1e5f64901",
        "text": "7",
        "type": "Title",
        "metadata": {
            "source_doc": "GTM.pdf",
            "page_number": 8,
            "languages": [
                "eng"
            ],
            "coordinates": [
                299.1148681640625,
                699.5280151367188,
                304.09619140625,
                709.4906616210938
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "c4e1532628618ae29c27bec355d09a81",
        "text": "i\n∥Wφ(xi) −Uxi∥\n(20)",
        "type": "Title",
        "metadata": {
            "source_doc": "GTM.pdf",
            "page_number": 9,
            "languages": [
                "eng"
            ],
            "coordinates": [
                276.227783203125,
                42.49901580810547,
                514.1946411132812,
                63.73155975341797
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "a60c2892900dce0d9718463236721022",
        "text": "where the columns of U are given by the eigenvectors. This represents the sum-of-squares error\nbetween the projections of the latent points into data space by the GTM model and the corre-\nsponding projections obtained from PCA. The value of β−1 is initialized to be the larger of either\nthe L + 1 eigenvalue from PCA (representing the variance of the data away from the PCA plane)\nor the square of half of the grid spacing of the PCA-projected latent points in data space.",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "GTM.pdf",
            "page_number": 9,
            "languages": [
                "eng"
            ],
            "coordinates": [
                89.00987243652344,
                73.12602996826172,
                514.2114868164062,
                131.1688232421875
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "fa0824bbb24088bb8f9ec69a68876cca",
        "text": "Finally, we note that in a numerical implementation care must be taken over the evaluation of\nthe responsibilities since this involves computing the exponentials of the distances between the\nprojected latent points and the data points, which may span a signiﬁcant range of values.",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "GTM.pdf",
            "page_number": 9,
            "languages": [
                "eng"
            ],
            "coordinates": [
                89.01007080078125,
                145.11907958984375,
                514.207275390625,
                178.994873046875
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "df52ab71d84b1e83893437e0e0881e75",
        "text": "2.4\nSummary of the GTM Algorithm",
        "type": "Title",
        "metadata": {
            "source_doc": "GTM.pdf",
            "page_number": 9,
            "languages": [
                "eng"
            ],
            "coordinates": [
                89.01007080078125,
                207.05914306640625,
                316.9462890625,
                219.0142364501953
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "0355b01b38e352e301513f262acd117f",
        "text": "Although the foregoing discussion has been somewhat detailed, the underlying GTM algorithm\nitself is straightforward and is summarized here for convenience.",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "GTM.pdf",
            "page_number": 9,
            "languages": [
                "eng"
            ],
            "coordinates": [
                89.01007080078125,
                239.21435546875,
                514.1848754882812,
                261.13787841796875
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "9c54fa119b6c24b861f3cb04760fdf50",
        "text": "GTM consists of a constrained mixture of Gaussians in which the model parameters are determined\nby maximum likelihood using the EM algorithm. It is deﬁned by specifying a set of points {xi} in\nlatent space, together with a set of basis functions {φj(x)}. The adaptive parameters W and β\ndeﬁne a constrained mixture of Gaussians with centres Wφ(xi) and a common covariance matrix\ngiven by β−1I. After initializing W and β, training involves alternating between the E-step in\nwhich the posterior probabilities are evaluated using (9), and the M-step in which W and β are\nre-estimated using (12) and (14) respectively. Evaluation of the log likelihood using (6) at the end\nof each cycle can be used to monitor convergence.",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "GTM.pdf",
            "page_number": 9,
            "languages": [
                "eng"
            ],
            "coordinates": [
                89.00762939453125,
                275.0791320800781,
                514.2247314453125,
                368.7328796386719
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "20b9576a7ac3cbe59d4f7b49b85ad0a9",
        "text": "3\nExperimental Results",
        "type": "Title",
        "metadata": {
            "source_doc": "GTM.pdf",
            "page_number": 9,
            "languages": [
                "eng"
            ],
            "coordinates": [
                89.00762939453125,
                399.9976501464844,
                265.381103515625,
                414.3438720703125
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "459da6cb21f58437cef5648e82de9a7f",
        "text": "We now present results from the application of this algorithm ﬁrst to a toy problem involving\ndata in two dimensions, and then to a more realistic problem involving 12-dimensional data arising\nfrom diagnostic measurements of oil ﬂows along multi-phase pipelines. In both examples we choose\nthe basis functions φj(x) to be radially symmetric Gaussians whose centres are distributed on a\nuniform grid in x-space, with a common width parameter chosen equal to twice the separation of\nneighbouring basis function centres. Results from a toy problem for the case of a 2-dimensional\ndata space and a 1-dimensional latent space are shown in Figure 4.",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "GTM.pdf",
            "page_number": 9,
            "languages": [
                "eng"
            ],
            "coordinates": [
                89.00762939453125,
                437.4484558105469,
                514.2160034179688,
                519.1409301757812
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "cf64a5d58f7017c8632ad83328def88c",
        "text": "3.1\nOil Flow Data",
        "type": "Title",
        "metadata": {
            "source_doc": "GTM.pdf",
            "page_number": 9,
            "languages": [
                "eng"
            ],
            "coordinates": [
                89.00799560546875,
                547.20556640625,
                203.0931396484375,
                559.16064453125
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "f0def66d9bee63332af076c1a63de6fd",
        "text": "Our second example arises from the problem of determining the fraction of oil in a multi-phase\npipeline carrying a mixture of oil, water and gas (Bishop and James 1993). Each data point con-\nsists of 12 measurements taken from dual-energy gamma densitometers measuring the attenuation\nof gamma beams passing through the pipe. Synthetically generated data is used which models\naccurately the attenuation processes in the pipe, as well as the presence of noise (arising from\nphoton statistics). The three phases in the pipe (oil, water and gas) can belong to one of three\ndiﬀerent geometrical conﬁgurations, corresponding to laminar, homogeneous, and annular ﬂows,",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "GTM.pdf",
            "page_number": 9,
            "languages": [
                "eng"
            ],
            "coordinates": [
                89.00799560546875,
                579.3693237304688,
                514.2059326171875,
                661.0620727539062
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "f1ac19338084a1b143e48c1ca93ca50f",
        "text": "8",
        "type": "Title",
        "metadata": {
            "source_doc": "GTM.pdf",
            "page_number": 9,
            "languages": [
                "eng"
            ],
            "coordinates": [
                299.11297607421875,
                699.5283813476562,
                304.09429931640625,
                709.4910278320312
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "7a1b4a45b37e88dfd78eb3d0c32c3502",
        "text": "Figure 4: Results from a toy problem involving data (‘◦’) generated from a 1-dimensional curve\nembedded in 2 dimensions, together with the projected latent points (‘+’) and their\nGaussian noise distributions (ﬁlled circles). The initial conﬁguration, determined by\nprincipal component analysis, is shown on the left, and the converged conﬁguration,\nobtained after 15 iterations of EM, is shown on the right.",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "GTM.pdf",
            "page_number": 10,
            "languages": [
                "eng"
            ],
            "coordinates": [
                110.26799774169922,
                207.3806610107422,
                492.9452819824219,
                262.411865234375
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "eb7a0481fdf127622cdce97d0b70b966",
        "text": "and the data set consists of 1000 points drawn with equal probability from the 3 conﬁgurations.\nWe take the latent-variable space to be two-dimensional, since our goal is data visualization.",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "GTM.pdf",
            "page_number": 10,
            "languages": [
                "eng"
            ],
            "coordinates": [
                89.009765625,
                284.02490234375,
                514.1929321289062,
                305.9395446777344
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "9a8970f98f9b7791123eea8f55196a07",
        "text": "Figure 5 shows the oil data visualized in the latent-variable space in which, for each data point,\nwe have plotted the posterior mean vector. Each point has then been labelled according to its\nmulti-phase conﬁguration. For comparison, Figure 5 also shows the corresponding results obtained\nusing principal component analysis.",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "GTM.pdf",
            "page_number": 10,
            "languages": [
                "eng"
            ],
            "coordinates": [
                89.009765625,
                319.8898010253906,
                514.20068359375,
                365.7176513671875
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "766cbd541db2e1be454682acc47509f3",
        "text": "4\nRelation to the Self-Organizing Map",
        "type": "Title",
        "metadata": {
            "source_doc": "GTM.pdf",
            "page_number": 10,
            "languages": [
                "eng"
            ],
            "coordinates": [
                89.009765625,
                396.9190979003906,
                371.3113098144531,
                411.26531982421875
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "a80c8395428dfc4eef5be58126ff24c4",
        "text": "Since one motivation for GTM is to provide a principled alternative to the self-organizing map, it\nis useful to consider the precise relationship between GTM and SOM. We focus our attention on\nthe batch versions of both algorithms as this helps to make the relationship particularly clear.",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "GTM.pdf",
            "page_number": 10,
            "languages": [
                "eng"
            ],
            "coordinates": [
                89.009765625,
                434.3699035644531,
                514.2086791992188,
                468.2365417480469
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "2d4becb647446134c36cd47032a931a3",
        "text": "The batch version of the SOM algorithm (Kohonen 1995) can be described as follows. A set of K\nreference vectors zi is deﬁned in the data space, in which each vector is associated with a node on\na regular lattice in a (typically) two-dimensional ‘feature map’ (analogous to the latent space of\nGTM). The algorithm begins by initializing the reference vectors (for example by setting them to\nrandom values, by setting them equal to a random subset of the data points, or by using principal\ncomponent analysis). Each cycle of the algorithm then proceeds as follows. For every data vector\ntn the corresponding ‘winning node’ j(n) is identiﬁed, corresponding to the reference vector zj\nhaving the smallest Euclidean distance ∥zj −tn∥2 to tn. The reference vectors are then updated\nby setting them equal to weighted averages of the data points given by",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "GTM.pdf",
            "page_number": 10,
            "languages": [
                "eng"
            ],
            "coordinates": [
                89.00897216796875,
                481.92578125,
                514.20654296875,
                587.7927856445312
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "56f06963a775d4edcd9de802d1ab1dc8",
        "text": "zi =\nP",
        "type": "Title",
        "metadata": {
            "source_doc": "GTM.pdf",
            "page_number": 10,
            "languages": [
                "eng"
            ],
            "coordinates": [
                262.4839782714844,
                589.8328247070312,
                295.8916320800781,
                616.6915893554688
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "17e6107527c66960938c7cd6f4928196",
        "text": "n hij(n)tn\nP\nn hij(n)\n.\n(21)",
        "type": "Title",
        "metadata": {
            "source_doc": "GTM.pdf",
            "page_number": 10,
            "languages": [
                "eng"
            ],
            "coordinates": [
                290.31298828125,
                597.5466918945312,
                514.1947631835938,
                624.75537109375
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "372d522f69c004f84e803cb6f87d5d08",
        "text": "in which hij is a neighbourhood function associated with the ith node. This is generally chosen to\nbe a uni-modal function of the feature map coordinates centred on the winning node, for example\na Gaussian. The steps of identifying the winning nodes and updating the reference vectors are",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "GTM.pdf",
            "page_number": 10,
            "languages": [
                "eng"
            ],
            "coordinates": [
                89.01010131835938,
                632.8377075195312,
                514.2044677734375,
                666.9743041992188
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "ac25fd8c726ad0256a4f94e5907fc301",
        "text": "9",
        "type": "Title",
        "metadata": {
            "source_doc": "GTM.pdf",
            "page_number": 10,
            "languages": [
                "eng"
            ],
            "coordinates": [
                299.11517333984375,
                699.5276489257812,
                304.09649658203125,
                709.4902954101562
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "394c342707c8c7eac2f5098ae436718b",
        "text": "Figure 5: The left plot shows the posterior-mean projection of the oil ﬂow data in the la-\ntent space of the GTM model, while the plot on the right shows the same data set\nvisualized using principal component analysis.\nIn both plots, crosses, circles and\nplus-signs represent stratiﬁed, annular and homogeneous multi-phase conﬁgurations\nrespectively. Note how the non-linearity of GTM gives an improved separation of\nthe clusters.",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "GTM.pdf",
            "page_number": 11,
            "languages": [
                "eng"
            ],
            "coordinates": [
                110.26799774169922,
                200.52703857421875,
                492.9434814453125,
                264.50897216796875
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "ea54e8b517861d60f8eab56fe1f17282",
        "text": "repeated iteratively. A key ingredient in the algorithm is that the width of the neighbourhood\nfunction hij starts with a relatively large value and is gradually reduced after each iteration.",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "GTM.pdf",
            "page_number": 11,
            "languages": [
                "eng"
            ],
            "coordinates": [
                89.010009765625,
                284.69122314453125,
                514.215576171875,
                308.1000061035156
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "3653391181baac0129fed4aca95cb6c1",
        "text": "4.1\nKernel versus Linear Regression",
        "type": "Title",
        "metadata": {
            "source_doc": "GTM.pdf",
            "page_number": 11,
            "languages": [
                "eng"
            ],
            "coordinates": [
                89.01010131835938,
                334.67010498046875,
                309.5657653808594,
                346.6252136230469
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "2371806521673c03e768d27aaaca035f",
        "text": "As pointed out by Mulier and Cherkassky (1995), the value of the neighbourhood function hij(n)\ndepends only on the identity of the winning node j and not on the value of the corresponding data\nvector tn. We can therefore perform partial sums over the groups Gj of data vectors assigned to\neach node j, and hence re-write (21) in the form",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "GTM.pdf",
            "page_number": 11,
            "languages": [
                "eng"
            ],
            "coordinates": [
                89.009765625,
                366.57318115234375,
                514.2321166992188,
                412.6617431640625
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "06033659243f309951b52030139a596d",
        "text": "zi =\nX",
        "type": "Title",
        "metadata": {
            "source_doc": "GTM.pdf",
            "page_number": 11,
            "languages": [
                "eng"
            ],
            "coordinates": [
                268.11962890625,
                416.6459045410156,
                304.20489501953125,
                438.06878662109375
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "87524c0ce22f2e161b1cc5101b466b76",
        "text": "j\nKijmj\n(22)",
        "type": "Title",
        "metadata": {
            "source_doc": "GTM.pdf",
            "page_number": 11,
            "languages": [
                "eng"
            ],
            "coordinates": [
                295.16455078125,
                426.3488464355469,
                514.1953735351562,
                447.581787109375
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "8eeb6c5012dbe079160031286e9db116",
        "text": "in which mj is the mean of the vectors in group Gj and is given by",
        "type": "Title",
        "metadata": {
            "source_doc": "GTM.pdf",
            "page_number": 11,
            "languages": [
                "eng"
            ],
            "coordinates": [
                89.01068115234375,
                458.33514404296875,
                381.55499267578125,
                470.0547180175781
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "19b974746db6c44632a55510ca8b37c7",
        "text": "mj = 1",
        "type": "Title",
        "metadata": {
            "source_doc": "GTM.pdf",
            "page_number": 11,
            "languages": [
                "eng"
            ],
            "coordinates": [
                264.7900085449219,
                478.8213806152344,
                301.6045837402344,
                497.018798828125
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "c71bc7bf5d17326f153ca01056e90c55",
        "text": "Nj",
        "type": "Title",
        "metadata": {
            "source_doc": "GTM.pdf",
            "page_number": 11,
            "languages": [
                "eng"
            ],
            "coordinates": [
                293.01300048828125,
                492.1409912109375,
                304.31243896484375,
                503.1116027832031
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "75a7f8f8ff59151d06ff6287fbc952bc",
        "text": "where Nj is the number of data vectors in group Gj. The result (22) is analogous to the Nadaraya-\nWatson kernel regression formula (Nadaraya 1964; Watson 1964) with the kernel functions given\nby",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "GTM.pdf",
            "page_number": 11,
            "languages": [
                "eng"
            ],
            "coordinates": [
                89.009765625,
                518.6007080078125,
                514.203125,
                552.7376098632812
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "01ee97bde81816288b4c9d162da35e6b",
        "text": "Kij =\nhijNj\nP",
        "type": "Title",
        "metadata": {
            "source_doc": "GTM.pdf",
            "page_number": 11,
            "languages": [
                "eng"
            ],
            "coordinates": [
                259.9381103515625,
                552.3599853515625,
                326.18280029296875,
                570.8184204101562
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "53367fde157d9d78b5a92e276c87d31a",
        "text": "j′ hij′Nj′ .\n(24)",
        "type": "Title",
        "metadata": {
            "source_doc": "GTM.pdf",
            "page_number": 11,
            "languages": [
                "eng"
            ],
            "coordinates": [
                300.4111022949219,
                559.1006469726562,
                514.1946411132812,
                578.4052734375
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "c49c235e21f6fda938351e1730ba5cfd",
        "text": "Thus the batch SOM algorithm replaces the reference vectors at each cycle with a convex combi-\nnation of the node means mj, with coeﬃcients determined by the neighbourhood function. Note\nthat the kernel coeﬃcients satisfy P",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "GTM.pdf",
            "page_number": 11,
            "languages": [
                "eng"
            ],
            "coordinates": [
                89.00997924804688,
                584.4359130859375,
                514.2311401367188,
                618.3114624023438
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "8faff927f851e69b046f36a6abdd1932",
        "text": "j Kij = 1 for every i.",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "GTM.pdf",
            "page_number": 11,
            "languages": [
                "eng"
            ],
            "coordinates": [
                249.1561737060547,
                608.0877685546875,
                339.844970703125,
                621.0382690429688
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "3035f5cd501ad438b0ad2c7d71ef608c",
        "text": "In the GTM algorithm, the centres y(xi; W) of the Gaussian components can be regarded as\nanalogous to the reference vectors zi of the SOM. We can evaluate y(xi; W) by solving the M-step",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "GTM.pdf",
            "page_number": 11,
            "languages": [
                "eng"
            ],
            "coordinates": [
                89.01034545898438,
                631.989501953125,
                514.2152099609375,
                655.67041015625
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "5acaabbdcdb0df4efab2376cb006067c",
        "text": "10",
        "type": "Title",
        "metadata": {
            "source_doc": "GTM.pdf",
            "page_number": 11,
            "languages": [
                "eng"
            ],
            "coordinates": [
                296.623046875,
                699.5277099609375,
                306.58135986328125,
                709.4903564453125
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "967dca50f2d382e82da56ae9ef15304b",
        "text": "X",
        "type": "Title",
        "metadata": {
            "source_doc": "GTM.pdf",
            "page_number": 11,
            "languages": [
                "eng"
            ],
            "coordinates": [
                310.28411865234375,
                475.6046142578125,
                324.670166015625,
                485.5672607421875
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "f3d97778f75c19c6823925a2cc3d4dda",
        "text": "n∈Gj\ntn\n(23)",
        "type": "Title",
        "metadata": {
            "source_doc": "GTM.pdf",
            "page_number": 11,
            "languages": [
                "eng"
            ],
            "coordinates": [
                308.070068359375,
                485.298583984375,
                514.1944580078125,
                507.11102294921875
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "f8ee3accade16b74f9bba0fa2cf80627",
        "text": "Figure 6: Example of the eﬀective kernel Fij plotted as a function of the node j for a given\nnode i, for the oil ﬂow data set after 3 iterations of EM. This kernel function is\nanalogous to the (normalized) neighbourhood function in the SOM algorithm.",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "GTM.pdf",
            "page_number": 12,
            "languages": [
                "eng"
            ],
            "coordinates": [
                110.26799774169922,
                170.90802001953125,
                492.9259033203125,
                202.0126953125
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "889d2306b4222c9494ea65458c29f163",
        "text": "equation (12) to ﬁnd W and then using y(xi; W) = Wφ(xi). If we deﬁne the weighted means of\nthe data vectors by",
        "type": "Title",
        "metadata": {
            "source_doc": "GTM.pdf",
            "page_number": 12,
            "languages": [
                "eng"
            ],
            "coordinates": [
                89.00933837890625,
                224.17279052734375,
                514.1956176757812,
                246.3594970703125
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "8309362c3c1367b7e61d6dd302a57b22",
        "text": "µi =\nP\nn Rintn\nP\nn Rin\n(25)",
        "type": "Title",
        "metadata": {
            "source_doc": "GTM.pdf",
            "page_number": 12,
            "languages": [
                "eng"
            ],
            "coordinates": [
                266.93963623046875,
                238.83274841308594,
                514.1947631835938,
                273.1978454589844
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "c0abbae729f9678300976723e1fb0372",
        "text": "then we obtain\ny(xi; W) =\nX",
        "type": "Title",
        "metadata": {
            "source_doc": "GTM.pdf",
            "page_number": 12,
            "languages": [
                "eng"
            ],
            "coordinates": [
                89.01010131835938,
                277.3918762207031,
                322.14990234375,
                300.053466796875
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "c3b65ae90741779cdd9cc5227f9e2f2e",
        "text": "where we have introduced the eﬀective kernel Fij given by",
        "type": "Title",
        "metadata": {
            "source_doc": "GTM.pdf",
            "page_number": 12,
            "languages": [
                "eng"
            ],
            "coordinates": [
                89.0101318359375,
                317.0699768066406,
                344.6216125488281,
                328.7998962402344
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "c3622423a0ceabc73ca38e725fadfda9",
        "text": "Fij = φT(xi)\n\u0010\nΦTGΦ\n\u0011−1\nφ(xj)Gjj.\n(27)",
        "type": "Title",
        "metadata": {
            "source_doc": "GTM.pdf",
            "page_number": 12,
            "languages": [
                "eng"
            ],
            "coordinates": [
                222.43472290039062,
                333.0809631347656,
                514.1946411132812,
                356.0968017578125
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "08afdee6c8aff076a42f911422c7d738",
        "text": "Note that the eﬀective kernel satisﬁes P",
        "type": "Title",
        "metadata": {
            "source_doc": "GTM.pdf",
            "page_number": 12,
            "languages": [
                "eng"
            ],
            "coordinates": [
                89.00994873046875,
                361.5751037597656,
                272.7174987792969,
                379.50579833984375
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "c9a5e4f3abf6429882b18f0f7d6af916",
        "text": "j Fij = 1. To see this, we ﬁrst use (27) to show that\nP\nj Fijφl(xj) = φl(xi). Then if one of the basis functions l corresponds to a bias, so that φl(x) =\nconst., the result follows.",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "GTM.pdf",
            "page_number": 12,
            "languages": [
                "eng"
            ],
            "coordinates": [
                89.00958251953125,
                369.2821350097656,
                514.2083740234375,
                403.4187316894531
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "8a71c55af9213b6e1ef62bbc0fa3d7bd",
        "text": "The solution for y(xi; W) given by (26) and (27) can be interpreted as a weighted least-squares\nregression (Mardia, Kent, and Bibby 1979) in which the ‘target’ vectors are the µi, and the\nweighting coeﬃcients are given by Gjj.",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "GTM.pdf",
            "page_number": 12,
            "languages": [
                "eng"
            ],
            "coordinates": [
                89.00965881347656,
                417.1058044433594,
                514.2079467773438,
                451.99139404296875
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "41b397259594d02e392099a25fcdb37f",
        "text": "Figure 6 shows an example of the eﬀective kernel for GTM corresponding to the oil ﬂow problem\ndiscussed in Section 3.",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "GTM.pdf",
            "page_number": 12,
            "languages": [
                "eng"
            ],
            "coordinates": [
                89.0098876953125,
                465.18609619140625,
                514.1995849609375,
                487.1096496582031
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "2f966b57f21e25db4bb3e613dfbe5541",
        "text": "From (22) and (26) we see that both GTM and SOM can be regarded as forms of kernel smoothers.\nHowever, there are two key diﬀerences. The ﬁrst is that in SOM the vectors which are smoothed,\ndeﬁned by (23), correspond to hard assignments of data points to nodes, whereas the corresponding\nvectors in GTM, given by (25), involve soft assignments, weighted by the posterior probabilities.\nThis is analogous to the distinction between K-means clustering (hard assignments) and ﬁtting a\nstandard Gaussian mixture model using EM (soft assignments).",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "GTM.pdf",
            "page_number": 12,
            "languages": [
                "eng"
            ],
            "coordinates": [
                89.00959777832031,
                501.0509033203125,
                514.2162475585938,
                570.7916870117188
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "7db01f81fa9e38d8bfc0c73b3a64dd78",
        "text": "The second key diﬀerence is that the kernel function in SOM is made to shrink during the course of\nthe algorithm in an arbitrary, hand-crafted manner. In GTM the posterior probability distribution\nin latent space, for a given data point, forms a localised ‘bubble’ and the radius of this bubble\nshrinks automatically during training, as shown in Figure 7. This responsibility bubble governs\nthe extent to which individual data points contribute towards the vectors µi in (25) and hence\ntowards the updating of the Gaussian centres y(xi; W) via (26).",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "GTM.pdf",
            "page_number": 12,
            "languages": [
                "eng"
            ],
            "coordinates": [
                89.00958251953125,
                584.7418823242188,
                514.2672729492188,
                655.2296142578125
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "0d6599146e9d6c9c7defa77a4bbf5e40",
        "text": "11",
        "type": "Title",
        "metadata": {
            "source_doc": "GTM.pdf",
            "page_number": 12,
            "languages": [
                "eng"
            ],
            "coordinates": [
                296.6214599609375,
                699.52783203125,
                306.57977294921875,
                709.490478515625
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "dc6ccd3a0e694ef567953a93a07fccf1",
        "text": "0.04",
        "type": "Title",
        "metadata": {
            "source_doc": "GTM.pdf",
            "page_number": 12,
            "languages": [
                "eng"
            ],
            "coordinates": [
                375.4067077636719,
                72.02139282226562,
                392.32373046875,
                83.9659194946289
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "c8c250ea08d94e122b22350355ed68a3",
        "text": "0.02",
        "type": "Title",
        "metadata": {
            "source_doc": "GTM.pdf",
            "page_number": 12,
            "languages": [
                "eng"
            ],
            "coordinates": [
                375.4067077636719,
                96.14517211914062,
                392.32373046875,
                108.0896987915039
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "71d0bca42453a73fd601323e625e1926",
        "text": "0.00",
        "type": "Title",
        "metadata": {
            "source_doc": "GTM.pdf",
            "page_number": 12,
            "languages": [
                "eng"
            ],
            "coordinates": [
                375.4067077636719,
                120.26895141601562,
                392.32373046875,
                132.21348571777344
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "e05241d9c3925a7c6b2fa11b37c7441c",
        "text": "−0.02",
        "type": "Title",
        "metadata": {
            "source_doc": "GTM.pdf",
            "page_number": 12,
            "languages": [
                "eng"
            ],
            "coordinates": [
                370.33599853515625,
                144.39273071289062,
                392.3298645019531,
                156.33726501464844
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "4c017c283ec03ff70aaa38c57c68db73",
        "text": "j\nFijµj\n(26)",
        "type": "Title",
        "metadata": {
            "source_doc": "GTM.pdf",
            "page_number": 12,
            "languages": [
                "eng"
            ],
            "coordinates": [
                313.1099548339844,
                289.0828857421875,
                514.19482421875,
                310.31365966796875
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "1ec556b71eb19f3998829de20ef74682",
        "text": "Figure 7: Examples of the posterior probabilities (responsibilities) Rin of the latent space\npoints at an early stage (left), intermediate stage (centre) and late stage (right)\nduring the convergence of the GTM algorithm.\nThese have been evaluated for a\nsingle data point from the training set in the oil-ﬂow problem discussed in Section 3,\nand are plotted using a non-linear scaling of the form p(x|tn)0.1 to highlight the vari-\nation over the latent space. Notice how the responsibility ‘bubble’, which governs\nthe updating of the weight matrix, and hence the updating of the data-space vectors\ny(xi; W), shrinks automatically during the learning process.",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "GTM.pdf",
            "page_number": 13,
            "languages": [
                "eng"
            ],
            "coordinates": [
                110.26799774169922,
                155.1400146484375,
                492.9504699707031,
                241.16612243652344
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "f95b472e3810d0972b0a4c8b5613e9c4",
        "text": "4.2\nComparison of GTM with SOM",
        "type": "Title",
        "metadata": {
            "source_doc": "GTM.pdf",
            "page_number": 13,
            "languages": [
                "eng"
            ],
            "coordinates": [
                89.00923156738281,
                261.6524658203125,
                308.0174560546875,
                273.6075744628906
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "8bd88c7aad45a70b1c910f48ade03e6c",
        "text": "The most signiﬁcant diﬀerence between the GTM and SOM algorithms is that GTM deﬁnes an\nexplicit probability density given by the mixture distribution in (5). As a consequence there is\na well-deﬁned objective function given by the log likelihood (6), and convergence to a (local)\nmaximum of the objective function is guaranteed by the use of the EM algorithm (Dempster,\nLaird, and Rubin 1977). This also provides a direct means to compare diﬀerent choices of model\nparameters, and even to compare a GTM solution with another density model, by evaluating the\nlikelihood of a test set under the generative distributions of the respective models. For the SOM\nalgorithm, however, there is no probability density and no well-deﬁned objective function which\nis being minimized by the training process. Indeed it has been proven (Erwin, Obermayer, and\nSchulten 1992) that such an objective function cannot exist for the SOM.",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "GTM.pdf",
            "page_number": 13,
            "languages": [
                "eng"
            ],
            "coordinates": [
                89.00923156738281,
                293.80767822265625,
                514.2158203125,
                411.3742370605469
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "57429d13f0771dc67210c1233d933afb",
        "text": "A further limitation of the SOM, highlighted in Kohonen (1995, page 234), is that the conditions\nunder which so-called ‘self-organization’ of the SOM occurs have not been quantiﬁed, and so in\npractice it is necessary to conﬁrm empirically that the trained model does indeed have the desired\nspatial ordering. In contrast, the neighbourhood-preserving nature of the GTM mapping is an\nautomatic consequence of the choice of a continuous function y(x; W).",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "GTM.pdf",
            "page_number": 13,
            "languages": [
                "eng"
            ],
            "coordinates": [
                89.00924682617188,
                425.3158874511719,
                514.2097778320312,
                483.1043395996094
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "026c80eb2d05f1b338a6ac1b59616dfa",
        "text": "Similarly, the smoothness properties of the SOM are determined indirectly by the choice of neigh-\nbourhood function and by the way in which it is changed during the course of the algorithm, and\nis therefore diﬃcult to control. Thus, prior knowledge about the form of the map cannot easily\nbe speciﬁed. The prior distribution for GTM, however, can be controlled directly, and properties\nsuch as smoothness are governed explicitly by basis function parameters, as illustrated in Figure 3.",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "GTM.pdf",
            "page_number": 13,
            "languages": [
                "eng"
            ],
            "coordinates": [
                89.00848388671875,
                497.0459899902344,
                514.2135009765625,
                554.8344116210938
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "c6fb2ab37fdba66ee4558e43be46382f",
        "text": "Finally, we consider the relative computational costs of the GTM and SOM algorithms.\nFor\nproblems involving data in high-dimensional spaces the dominant computational cost of GTM\narises from the evaluation of the Euclidean distances from every data point to every Gaussian centre\ny(xi; W). Since exactly the same calculations must be done for SOM (involving the distances of\ndata points from the reference vectors µi) we expect one iteration of either algorithm to take\napproximately the same time. An empirical comparison of the computational cost of GTM and\nSOM was obtained by running each algorithm on the oil ﬂow data until ‘convergence’ (deﬁned\nas no discernible change in the appearance of the visualization map). The GTM algorithm took",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "GTM.pdf",
            "page_number": 13,
            "languages": [
                "eng"
            ],
            "coordinates": [
                89.00848388671875,
                568.7756958007812,
                514.2722778320312,
                662.4293823242188
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "a2eaeb492624fff49ea4c1b123442575",
        "text": "12",
        "type": "Title",
        "metadata": {
            "source_doc": "GTM.pdf",
            "page_number": 13,
            "languages": [
                "eng"
            ],
            "coordinates": [
                296.62091064453125,
                699.527587890625,
                306.5792236328125,
                709.490234375
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "36d55f3fc540964a4cf55b370942a99c",
        "text": "1058 sec. (40 iterations) while the batch SOM took 1011 sec. (25 iterations) using a Gaussian\nneighbourhood function. With a simple ‘top-hat’ neighbourhood function, in which each reference\nvector is updated at each iteration using only data points associated with nearby reference vectors,\nthe CPU time for the SOM algorithm is reduced to 305sec. (25 iterations). One potential advantage\nof GTM in practical applications arises from a reduction in the number of experimental training\nruns needed since both convergence and topographic ordering are guaranteed.",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "GTM.pdf",
            "page_number": 14,
            "languages": [
                "eng"
            ],
            "coordinates": [
                89.00979614257812,
                16.707035064697266,
                514.2080688476562,
                86.43865966796875
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "d3e2ca057c9f849db1638514c4b26e0f",
        "text": "5\nRelation to Other Algorithms",
        "type": "Title",
        "metadata": {
            "source_doc": "GTM.pdf",
            "page_number": 14,
            "languages": [
                "eng"
            ],
            "coordinates": [
                89.00979614257812,
                117.70341491699219,
                323.5680847167969,
                132.0496063232422
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "ac8a720fbfad7b6a998ec28c0337e143",
        "text": "There are several algorithms in the published literature which have close links with GTM. Here\nwe review brieﬂy the most signiﬁcant of these.",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "GTM.pdf",
            "page_number": 14,
            "languages": [
                "eng"
            ],
            "coordinates": [
                89.00979614257812,
                155.1541748046875,
                514.2060546875,
                177.07769775390625
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "66d3638b57397ecd2b786c0a22c83825",
        "text": "The elastic net algorithm of Durbin and Willshaw (1987) can be viewed as a Gaussian mixture\ndensity model, ﬁtted by penalized maximum likelihood. The penalty term encourages the centres\nof Gaussians corresponding to neighbouring points along the (typically one-dimensional) chain to\nbe close in data space. It diﬀers from GTM in that it does not deﬁne a continuous data space\nmanifold. Also, the training algorithm generally involves a hand-crafted annealing of the weight\npenalty coeﬃcient.",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "GTM.pdf",
            "page_number": 14,
            "languages": [
                "eng"
            ],
            "coordinates": [
                89.00979614257812,
                191.01898193359375,
                514.2146606445312,
                260.7598876953125
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "22f78bb9155fa443defe41c2399443c9",
        "text": "There are also similarities between GTM and principal curves and principal surfaces (Hastie and\nStuetzle 1989; LeBlanc and Tibshirani 1994) which again involve a two-stage algorithm consisting\nof projection followed by smoothing, although these are not generative models. It is interesting to\nnote that Hastie and Stuetzle (1989) propose reducing the spatial width of the smoothing function\nduring learning, in a manner analogous to the shrinking of the neighbourhood function in the\nSOM. A modiﬁed form of the principal curves algorithm (Tibshirani 1992) introduces a generative\ndistribution based on a mixture of Gaussians, with a well-deﬁned likelihood function, and is trained\nby the EM algorithm. However, the number of Gaussian components is equal to the number of\ndata points, and smoothing is imposed by penalizing the likelihood function with the addition of\na derivative-based regularization term.",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "GTM.pdf",
            "page_number": 14,
            "languages": [
                "eng"
            ],
            "coordinates": [
                89.00979614257812,
                274.71014404296875,
                514.2207641601562,
                392.2680969238281
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "db12975c212992739a75b8b87e926654",
        "text": "The technique of parametrized self-organizing maps (PSOMs) involves ﬁrst ﬁtting a standard SOM\nmodel to a data set and then ﬁnding a manifold in data space which interpolates the reference\nvectors (Ritter 1993).\nAlthough this deﬁnes a continuous manifold, the interpolating surface\ndoes not form part of the training algorithm, and the basic problems in using SOM, discussed\nin Section 4.2, remain.",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "GTM.pdf",
            "page_number": 14,
            "languages": [
                "eng"
            ],
            "coordinates": [
                89.00979614257812,
                406.2183532714844,
                514.2235107421875,
                463.9978942871094
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "0e813b2f5eb5f18eb0968d191cd13a63",
        "text": "The SOM has also been used for vector quantization.\nIn this context it has been shown how\na re-formulation of the vector quantization problem (Luttrell 1990; Buhmann and K¨uhnel 1993;\nLuttrell 1994) can avoid many of the problems with the SOM procedure discussed earlier.",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "GTM.pdf",
            "page_number": 14,
            "languages": [
                "eng"
            ],
            "coordinates": [
                89.00979614257812,
                477.9481506347656,
                514.2012329101562,
                511.8147888183594
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "6a9140d2d0c32fc726713ac0a4db7cf2",
        "text": "Finally, the ‘density network’ model of MacKay (1995) involves transforming a simple distribution\nin latent space to a complex distribution in data space by propagation through a non-linear network.\nA discrete distribution in latent space is again used, which is interpreted as an approximate Monte\nCarlo integration over the latent variables needed to deﬁne the data space distribution. GTM\ncan be seen as a particular instance of this framework in which the sampling of latent space is\nregular rather than stochastic, a speciﬁc form of non-linearity is used, and the model parameters\nare adapted using EM.",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "GTM.pdf",
            "page_number": 14,
            "languages": [
                "eng"
            ],
            "coordinates": [
                89.00979614257812,
                525.7650756835938,
                514.2086181640625,
                607.4578247070312
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "35ad4dafff78d811a7abd129001dfe73",
        "text": "13",
        "type": "Title",
        "metadata": {
            "source_doc": "GTM.pdf",
            "page_number": 14,
            "languages": [
                "eng"
            ],
            "coordinates": [
                296.6217956542969,
                699.5281372070312,
                306.5801086425781,
                709.4907836914062
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "e2168b0e5d656e8d3eb93f67dc07f520",
        "text": "In this paper we have introduced a form of non-linear latent variable model which can be trained\neﬃciently using the EM algorithm. Viewed as a topographic mapping algorithm, it has the key\nproperty that it deﬁnes a probability density model.",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "GTM.pdf",
            "page_number": 15,
            "languages": [
                "eng"
            ],
            "coordinates": [
                89.00979614257812,
                50.475040435791016,
                514.2008056640625,
                84.3505859375
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "c616e074ec4ab760eb39e4fb4578527a",
        "text": "As an example of the signiﬁcance of having a probability density, consider the important practical\nproblem of dealing with missing values in the data set (in which some components of the data\nvectors tn are unobserved). If the missing values are missing at random (Little and Rubin 1987)\nthen the likelihood function is obtained by integrating out the unobserved values. For the GTM\nmodel the integrations can be performed analytically, leading to a simple modiﬁcation of the EM\nalgorithm.",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "GTM.pdf",
            "page_number": 15,
            "languages": [
                "eng"
            ],
            "coordinates": [
                89.0096435546875,
                98.30084991455078,
                514.224853515625,
                168.041748046875
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "4f7456caaccd8b954058a28ee684e9fb",
        "text": "A further consequence of having a probabilistic approach is that it is straightforward to consider\na mixture of GTM models. In this case the overall density can be written as",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "GTM.pdf",
            "page_number": 15,
            "languages": [
                "eng"
            ],
            "coordinates": [
                89.0096435546875,
                181.98297119140625,
                514.2041625976562,
                203.906494140625
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "e789581cfe1ba41248ee0be07c9629b8",
        "text": "p(t) =\nX",
        "type": "Title",
        "metadata": {
            "source_doc": "GTM.pdf",
            "page_number": 15,
            "languages": [
                "eng"
            ],
            "coordinates": [
                255.80599975585938,
                207.33287048339844,
                300.6842346191406,
                227.2615966796875
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "ed231a9d309a81dbe3f166c09724154c",
        "text": "r\nP(r)p(t|r)\n(28)",
        "type": "Title",
        "metadata": {
            "source_doc": "GTM.pdf",
            "page_number": 15,
            "languages": [
                "eng"
            ],
            "coordinates": [
                291.5450744628906,
                217.03582763671875,
                514.192138671875,
                237.971435546875
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "d51bd56bcb91d0b884989fe9710dad8d",
        "text": "where p(t|r) represents the rth model, with its own set of independent parameters, and P(r) are\nmixing coeﬃcients satisfying 0 ≤P(r) ≤1 and P\nr P(r) = 1. Again, it is straightforward to\nextend the EM algorithm to maximize the corresponding likelihood function.",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "GTM.pdf",
            "page_number": 15,
            "languages": [
                "eng"
            ],
            "coordinates": [
                89.00912475585938,
                247.92413330078125,
                514.2348022460938,
                282.053955078125
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "6cf9a6ca33b71b9240f220efee638a33",
        "text": "The GTM algorithm can be extended in other ways, for instance by allowing independent mix-\ning coeﬃcients πi (prior probabilities) for each of the Gaussian components, which again can be\nestimated by a straightforward extension of the EM algorithm. Instead of being independent pa-\nrameters, the πi can be determined as smooth functions of the latent variables using a normalized\nexponential applied to a generalized linear regression model, although in this case the M-step of\nthe EM algorithm would involve non-linear optimization. Similarly, the inverse noise variance β\ncan be generalized to a function of x. An important property of GTM is the existence of a smooth\nmanifold in data space, which allows the local ‘magniﬁcation factor’ between latent and data space\nto be evaluated as a function of the latent space coordinates using the techniques of diﬀerential\ngeometry (Bishop, Svens´en, and Williams 1997a; Bishop, Svens´en, and Williams 1997b). Finally,\nsince there is a well-deﬁned likelihood function, it is straightforward in principle to introduce priors\nover the model parameters (as discussed in Section 2.1) and to use Bayesian techniques in place of\nmaximum likelihood.",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "GTM.pdf",
            "page_number": 15,
            "languages": [
                "eng"
            ],
            "coordinates": [
                89.00909423828125,
                296.00421142578125,
                514.2196044921875,
                449.42706298828125
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "8ff0998c4751bf3e22b6f5b91b869c6a",
        "text": "Throughout this paper we have focussed on the batch version of the GTM algorithm in which all\nof the training data are used together to update the model parameters. In some applications it will\nbe more convenient to consider sequential adaptation in which data points are presented one at a\ntime. Since we are minimizing a diﬀerentiable cost function, given by (6), a sequential algorithm\ncan be obtained by appealing to the Robbins-Monro procedure (Robbins and Monro 1951; Bishop\n1995) to ﬁnd a zero of the objective function gradient. Alternatively, a sequential form of the EM\nalgorithm can be used (Titterington, Smith, and Makov 1985).",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "GTM.pdf",
            "page_number": 15,
            "languages": [
                "eng"
            ],
            "coordinates": [
                89.00909423828125,
                463.3773193359375,
                514.2154541015625,
                545.0701293945312
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "02ec374a5546def2fe3928f340cebc1a",
        "text": "A web site for GTM is provided at:",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "GTM.pdf",
            "page_number": 15,
            "languages": [
                "eng"
            ],
            "coordinates": [
                89.00909423828125,
                559.0204467773438,
                243.66835021972656,
                568.9830932617188
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "5b40c12df8add8a6d05d8e0a157648d8",
        "text": "http://www.ncrg.aston.ac.uk/GTM/",
        "type": "Title",
        "metadata": {
            "source_doc": "GTM.pdf",
            "page_number": 15,
            "languages": [
                "eng"
            ],
            "coordinates": [
                217.9160919189453,
                590.879638671875,
                385.2448425292969,
                600.8422241210938
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "ce4ae3ddc0ffafa46e4dd5c7522d34ee",
        "text": "which includes postscript ﬁles of relevant papers, a software implementation in Matlab (a C im-\nplementation is under development), and example data sets used in the development of the GTM\nalgorithm.",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "GTM.pdf",
            "page_number": 15,
            "languages": [
                "eng"
            ],
            "coordinates": [
                89.00909423828125,
                622.7761840820312,
                514.1978149414062,
                656.6520385742188
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "bdf5cd9fde92eeb7ebe5c3640a0cc093",
        "text": "14",
        "type": "Title",
        "metadata": {
            "source_doc": "GTM.pdf",
            "page_number": 15,
            "languages": [
                "eng"
            ],
            "coordinates": [
                296.62109375,
                699.5281372070312,
                306.57940673828125,
                709.4907836914062
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "3e5053a731cd5b11f7f74682d2e472ea",
        "text": "This work was supported by EPSRC grant GR/K51808: Neural Networks for Visualization of\nHigh-Dimensional Data.\nWe would like to thank Geoﬀrey Hinton, Iain Strachan and Michael\nTipping for useful discussions. Markus Svens´en would like to thank the staﬀof the SANS group\nin Stockholm for their hospitality during part of this project.",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "GTM.pdf",
            "page_number": 16,
            "languages": [
                "eng"
            ],
            "coordinates": [
                89.0097885131836,
                46.773014068603516,
                514.2471313476562,
                92.87371826171875
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "3a33a75fe6b1fec4ae9b8afd7c5de1ad",
        "text": "References",
        "type": "Title",
        "metadata": {
            "source_doc": "GTM.pdf",
            "page_number": 16,
            "languages": [
                "eng"
            ],
            "coordinates": [
                89.00979614257812,
                124.10209655761719,
                164.5041046142578,
                138.4482879638672
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "c6c68143fc6336f5a0dd0bbe404e2446",
        "text": "Bishop, C. M. (1995). Neural Networks for Pattern Recognition. Oxford University Press.",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "GTM.pdf",
            "page_number": 16,
            "languages": [
                "eng"
            ],
            "coordinates": [
                99.52189636230469,
                151.40704345703125,
                489.063232421875,
                161.642822265625
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "491b869b49cebf068ab694a0cc7637de",
        "text": "Bishop, C. M. and G. D. James (1993). Analysis of multiphase ﬂows using dual-energy\ngamma densitometry and neural networks. Nuclear Instruments and Methods in Physics\nResearch A327, 580–593.",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "GTM.pdf",
            "page_number": 16,
            "languages": [
                "eng"
            ],
            "coordinates": [
                99.52182006835938,
                167.573974609375,
                514.2147827148438,
                201.449951171875
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "3a3e32bed952c874672fc5d364399ee7",
        "text": "Bishop, C. M., M. Svens´en, and C. K. I. Williams (1996). A fast EM algorithm for latent variable\ndensity models. In D. S. Touretzky, M. C. Mozer, and M. E. Hasselmo (Eds.), Advances in\nNeural Information Processing Systems, Volume 8, pp. 465–471. MIT Press.",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "GTM.pdf",
            "page_number": 16,
            "languages": [
                "eng"
            ],
            "coordinates": [
                99.52202606201172,
                207.381103515625,
                514.2151489257812,
                241.247802734375
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "002be10ace6bbac9b5f0bdb2550f2c44",
        "text": "Bishop, C. M., M. Svens´en, and C. K. I. Williams (1997a). Magniﬁcation factors for the GTM\nalgorithm. In Proceedings IEE Fifth International Conference on Artiﬁcial Neural Networks,\nCambridge, U.K., pp. 64–69.",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "GTM.pdf",
            "page_number": 16,
            "languages": [
                "eng"
            ],
            "coordinates": [
                99.52206420898438,
                247.17926025390625,
                514.2219848632812,
                281.0548095703125
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "8505643e2c1434c40355b55a110681bb",
        "text": "Bishop, C. M., M. Svens´en, and C. K. I. Williams (1997b). Magniﬁcation factors for the SOM\nand GTM algorithms. In Proceedings 1997 Workshop on Self-Organizing Maps, Helsinki,\nFinland.",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "GTM.pdf",
            "page_number": 16,
            "languages": [
                "eng"
            ],
            "coordinates": [
                99.52275848388672,
                286.97735595703125,
                514.216064453125,
                320.57977294921875
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "bda138756d5e5e3c770a2934a82a6df4",
        "text": "Buhmann, J. and K. K¨uhnel (1993). Vector quantization with complexity costs. IEEE Transac-\ntions on Information Theory 39(4), 1133–1145.",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "GTM.pdf",
            "page_number": 16,
            "languages": [
                "eng"
            ],
            "coordinates": [
                99.5229721069336,
                326.51123046875,
                514.2033081054688,
                348.6990051269531
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "8d37caebf247ff5c95e8783dd4347563",
        "text": "Dempster, A. P., N. M. Laird, and D. B. Rubin (1977). Maximum likelihood from incomplete\ndata via the EM algorithm. Journal of the Royal Statistical Society, B 39(1), 1–38.",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "GTM.pdf",
            "page_number": 16,
            "languages": [
                "eng"
            ],
            "coordinates": [
                99.52198791503906,
                354.6304626464844,
                514.1773681640625,
                376.54510498046875
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "cc29cfdb71978bb3067ccc6aee710a8e",
        "text": "Durbin, R. and D. Willshaw (1987). An analogue approach to the travelling salesman problem.\nNature 326, 689–691.",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "GTM.pdf",
            "page_number": 16,
            "languages": [
                "eng"
            ],
            "coordinates": [
                99.52203369140625,
                382.47625732421875,
                514.1884765625,
                404.3908996582031
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "79bb5233ae99bea779a877284a0c9904",
        "text": "Erwin, E., K. Obermayer, and K. Schulten (1992). Self-organizing maps: ordering, convergence\nproperties and energy functions. Biological Cybernetics 67, 47–55.",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "GTM.pdf",
            "page_number": 16,
            "languages": [
                "eng"
            ],
            "coordinates": [
                99.52223205566406,
                410.3223571777344,
                514.1868286132812,
                432.23699951171875
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "999a5c3172e2f2dd241cd4d8b41c729a",
        "text": "Hastie, T. and W. Stuetzle (1989). Principal curves. Journal of the American Statistical Asso-\nciation 84(406), 502–516.",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "GTM.pdf",
            "page_number": 16,
            "languages": [
                "eng"
            ],
            "coordinates": [
                99.52325439453125,
                437.89532470703125,
                514.2200317382812,
                460.0920104980469
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "c33b4ed480beb76af0434461b87a1c86",
        "text": "Hinton, G. E., C. K. I. Williams, and M. D. Revow (1992). Adaptive elastic models for hand-\nprinted character recognition. In J. E. Moody, S. J. Hanson, and R. P. Lippmann (Eds.),\nAdvances in Neural Information Processing Systems, Volume 4, pp. 512–519. Morgan Kauﬀ-\nmann.",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "GTM.pdf",
            "page_number": 16,
            "languages": [
                "eng"
            ],
            "coordinates": [
                99.52345275878906,
                466.0145568847656,
                514.2272338867188,
                511.84210205078125
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "a6f3e8ddae208883180f182effd75a6b",
        "text": "Kohonen, T. (1982). Self-organized formation of topologically correct feature maps. Biological\nCybernetics 43, 59–69.",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "GTM.pdf",
            "page_number": 16,
            "languages": [
                "eng"
            ],
            "coordinates": [
                99.52361297607422,
                517.5004272460938,
                514.19873046875,
                539.6881713867188
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "54ebaf465c4f760cf6779a3210ca3700",
        "text": "Kohonen, T. (1995). Self-Organizing Maps. Berlin: Springer-Verlag.",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "GTM.pdf",
            "page_number": 16,
            "languages": [
                "eng"
            ],
            "coordinates": [
                99.52334594726562,
                545.34619140625,
                394.60595703125,
                555.5819702148438
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "82a5d3f1b0b13c6d70ab259d2c33384c",
        "text": "LeBlanc, M. and R. Tibshirani (1994). Adaptive principal surfaces. Journal of the American\nStatistical Association 89(425), 53–64.",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "GTM.pdf",
            "page_number": 16,
            "languages": [
                "eng"
            ],
            "coordinates": [
                99.52334594726562,
                561.2403564453125,
                514.20654296875,
                583.4281005859375
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "18ec261ae7d884bb943f6ecd156ec160",
        "text": "Little, R. J. A. and D. B. Rubin (1987). Statistical Analysis with Missing Data. New York: John\nWiley.",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "GTM.pdf",
            "page_number": 16,
            "languages": [
                "eng"
            ],
            "coordinates": [
                99.52335357666016,
                589.08642578125,
                514.212158203125,
                611.2742309570312
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "3d3962412906af21e75e53382afbdaac",
        "text": "Luttrell, S. P. (1990). Derivation of a class of training algorithms. IEEE Transactions on Neural\nNetworks 1(2), 229–232.",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "GTM.pdf",
            "page_number": 16,
            "languages": [
                "eng"
            ],
            "coordinates": [
                99.52254486083984,
                616.9324951171875,
                514.2034301757812,
                639.1203002929688
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "7985ac940ffd9edf35fc3acd63c4723c",
        "text": "Luttrell, S. P. (1994). A Bayesian analysis of self-organizing maps. Neural Computation 6(5),\n767–794.",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "GTM.pdf",
            "page_number": 16,
            "languages": [
                "eng"
            ],
            "coordinates": [
                99.52164459228516,
                644.7783203125,
                514.1905517578125,
                666.9749755859375
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "58f4b2f5f00aa9a81000c9727ed56a80",
        "text": "15",
        "type": "Title",
        "metadata": {
            "source_doc": "GTM.pdf",
            "page_number": 16,
            "languages": [
                "eng"
            ],
            "coordinates": [
                296.6206359863281,
                699.5283813476562,
                306.5789489746094,
                709.4910278320312
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "5fb312946170b9cee00652e30c7898b3",
        "text": "Mulier, F. and V. Cherkassky (1995). Self-organization as an iterative kernel smoothing process.\nNeural Computation 7(6), 1165–1177.",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "GTM.pdf",
            "page_number": 17,
            "languages": [
                "eng"
            ],
            "coordinates": [
                99.52230834960938,
                60.537235260009766,
                514.2008056640625,
                82.46075439453125
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "7bef7a21c5a44333e76b7ea17658e67d",
        "text": "Nadaraya, ´E. A. (1964). On estimating regression. Theory of Probability and its Applica-\ntions 9(1), 141–142.",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "GTM.pdf",
            "page_number": 17,
            "languages": [
                "eng"
            ],
            "coordinates": [
                99.52272033691406,
                85.91687774658203,
                514.2283935546875,
                110.35186767578125
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "e01879f1be2833394cf88fbb8058d846",
        "text": "Ritter, H. (1993). Parametrized self-organizing maps. In Proceedings ICANN’93 International\nConference on Artiﬁcial Neural Networks, Amsterdam, pp. 568–575. Springer-Verlag.",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "GTM.pdf",
            "page_number": 17,
            "languages": [
                "eng"
            ],
            "coordinates": [
                99.52204132080078,
                116.0548095703125,
                514.2039184570312,
                138.25189208984375
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "c2c11c9a6d68f2dee2bd950e3457672f",
        "text": "Robbins, H. and S. Monro (1951). A stochastic approximation method. Annals of Mathematical\nStatistics 22, 400–407.",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "GTM.pdf",
            "page_number": 17,
            "languages": [
                "eng"
            ],
            "coordinates": [
                99.52204895019531,
                143.954833984375,
                514.201904296875,
                166.14288330078125
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "f602d216d81497486fd6709422c08193",
        "text": "Tibshirani, R. (1992). Principal curves revisited. Statistics and Computing 2, 183–190.",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "GTM.pdf",
            "page_number": 17,
            "languages": [
                "eng"
            ],
            "coordinates": [
                99.52220916748047,
                171.8458251953125,
                476.7158203125,
                182.08160400390625
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "f34d9d29b4fc9497291496d11ff6bb3b",
        "text": "Titterington, D. M., A. F. M. Smith, and U. E. Makov (1985). Statistical Analysis of Finite\nMixture Distributions. New York: John Wiley.",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "GTM.pdf",
            "page_number": 17,
            "languages": [
                "eng"
            ],
            "coordinates": [
                99.522216796875,
                187.784912109375,
                514.20849609375,
                209.9815673828125
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "0be83465b2f14f9f2d700ada3eaef05d",
        "text": "Watson, G. S. (1964). Smooth regression analysis. Sankhy¯a: The Indian Journal of Statistics.\nSeries A 26, 359–372.",
        "type": "NarrativeText",
        "metadata": {
            "source_doc": "GTM.pdf",
            "page_number": 17,
            "languages": [
                "eng"
            ],
            "coordinates": [
                99.52142333984375,
                215.68487548828125,
                514.2210693359375,
                237.8726806640625
            ],
            "is_full_width": false
        }
    },
    {
        "element_id": "dae6465ba9952c7e6fa6f82394059b0f",
        "text": "16",
        "type": "Title",
        "metadata": {
            "source_doc": "GTM.pdf",
            "page_number": 17,
            "languages": [
                "eng"
            ],
            "coordinates": [
                296.6209411621094,
                699.5280151367188,
                306.5792541503906,
                709.4906616210938
            ],
            "is_full_width": false
        }
    }
]